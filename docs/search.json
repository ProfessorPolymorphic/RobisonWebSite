[
  {
    "objectID": "Teaching.html",
    "href": "Teaching.html",
    "title": "TEACHING",
    "section": "",
    "text": "1 credit, Fall semester only\nThe companion laboratory to Biology 310. This is an open lab course in which students test genetic hypotheses using Drosophila melanogaster or game based simulations.\nCanvas Page\n\n\n\n3 credits, Spring semester, asynchronous online\n\nThis class will help students establish a foundational understanding of data visualization. We will consider how data type (including tabular, network, and spatial data) interacts with visualization task to guide design choices. Diverse types of visual encodings and how they relate to human perception will be presented, along with practical exercises using the R programming language. Upon completion of the course, students will understand WHY particular visualization approaches are effective for a given data set and HOW to implement those visualizations using R. The course is designed to be “discipline agnostic” - each student is encouraged to use data sets that they deem important / interesting. The goal is to have students learn how to develop visualizations that are relevant to their own disciplinary interests.\nCanvas Page\nCourse WebPage"
  },
  {
    "objectID": "Research.html",
    "href": "Research.html",
    "title": "RESEARCH",
    "section": "",
    "text": "My research group is an interdisicplinary blend of biologists, developers, modelers, programmers, and artists. I am always interested in recruiting new undergraduates, graduate students, and postdocs. Contact me via email if you are interested in learning more."
  },
  {
    "objectID": "Research.html#evolutionary-video-games",
    "href": "Research.html#evolutionary-video-games",
    "title": "RESEARCH",
    "section": "Evolutionary Video Games",
    "text": "Evolutionary Video Games\nIn 2015, Terry Soule and I co-founded Polymorphic Games, an experimental game studio that makes evolution based video games. Our original concept was that a model of biological evolution would make a great game mechanic. We observed that traditional video games were usually scripted, featuring “waves” of enemies with defined and predictable characteristics. A player’s success in such games is based on learning the predictable, rote script necessary to advance to subsequent levels. By integrating principles of evolutionary biology, we suspected that video games could be made more compelling. For example, by replacing the traditional waves of enemies with generations of enemies we could introduce adaptation through natural selection. If you want to learn more about our approach, scroll down to the section on Video Games and STEM Education.\nSince 2015 we have commercially released two evolutionary video games on Steam, and developed many other interactive simulations and outreach exhibits.\n\nCommercial Releases\n\nDarwin’s Demons is an arcade style space shooter in which you battle a population of evolving aliens. The alien’s morphology, fire type, and behaviors are all encoded by a digital genome. The aliens that are best able to shoot or evade you reproduce to make the next generation.\n\nProject Hastur is an evolutionary tower defense game. Defend humanity against the ever changing threat of the alien Proteans. Project Hastur combines elements of 3D tower defense and real-time strategy with models of biological evolution to create a uniquely challenging experience."
  },
  {
    "objectID": "Research.html#video-games-and-stem-education",
    "href": "Research.html#video-games-and-stem-education",
    "title": "RESEARCH",
    "section": "Video Games and STEM Education",
    "text": "Video Games and STEM Education\n\nAdding Evolution to Video Games\nThe best way to explain the concept is to frame our video games in the context of the “ingredients” of evolution:\n\nVariation\nInheritance\nSelection\nTime\n\nWhen these components are present, it leads to Adaptation.\n\nVariation\nThink about the enemies in the old school video games that I used to play in arcades. Space Invaders, Asteroids, Centipede, Tempest, etc. What kinds of variation can you describe in these enemies? In Space Invaders, you had three types of aliens in each wave, plus the occasional bonus flying saucer. In Centipede and Tempest, you actually had categorically different enemy types that varied in how they looked and in their capabilities. Below you can see a few examples of what I mean:\n\nSpace InvadersCentipedeTempest\n\n\n Enemy variation in Space Invaders includes the shape of each alien type (four types), but also their position in the armada (each type has its own row) and their speed of movement (which is adjusted based on how many remain in each wave). For now, we will ignore the flying saucer that passes across the top of the screen. The game increases in difficulty by having the movement speed of each wave increase. Ironically, the increased movement speed of the aliens within a wave as the population size was reduced was an unintended function of the increased frame rate achieved by having fewer aliens draw calls.\n\n\n Centipede includes enemy types with very different behaviors and abilities. The segmented centipede can split into component parts. Fleas drop vertically, leave a trail of mushrooms, and take two hits to destroy. Spiders move in a diagonal zig zag pattern. Scorpions move horizontally across the screen and turn mushrooms poisonous. Each wave the game difficulty increases by changing the behavior and segment number of the centipede.\n\n\n While not as famous as Space Invaders or Centipede, Tempest was one of my favorite games in the early 80s. The player navigated their ship across various geometric shapes, shooting at different types of enemies with different capabilities. These included player capturing Flippers, lane electrifying Pulsars, and obstacle creating Spikers. So many quarters gone…\n\n\n\nThis variation is a big part of what makes video games exciting. The difficulty in video games is usually increased over time by introducing new variations of enemies, changing the enemies’ capabilities (like speed or fire rate) over time, or increasing the number of enemies. The problem (as we see it) is that these variations are introduced as part of a script that is programmed and balanced by the game developers. Beating the game means memorizing the script.\n\n\nInheritance\nThe addition of an inheritance model is the primary differentiator in our games that creates adaptation.\nIn most games, there is no relationship between enemies within a wave or between waves. They are instantiated (spawned) with developer defined traits at a specified rate, location, and time (or level or wave). This is the key difference in the games that our lab creates. In our games, the enemies traits are specified by digital genomes that they pass on to their offspring through a form of reproduction. If the enemy has a speed value of 4, that means that when it reproduces, its offspring inherit that speed value of 4. Most of the games we work on specify about 40 to 80 “genes” in the enemy genome, each of which can influence one or more game traits such as speed, fire rate, morphology, behavior, health, armor, resistances, etc.\n\n\nSelection\nSelection occurs when there is a correlation between a trait (say… hit points or movement behavior) and Fitness. In biological populations, Fitness is usually defined in terms of the number of offspring produced by a given individual. We often measure proxies for fitness in empirical biology that are typically predictive of (or at least correlated with ) Fitness, such as seed set in plants, survivorship, or number of eggs. In our games, we can make explicit linkages between performance and fitness using Fitness Functions.\nFor example, in Darwin’s Demons the enemies accrue Aggression by moving downward on the screen. The closer they get to the bottom, the higher their Aggression score. if they move past the player and off the bottom of the screen, their Aggression score gets an even larger boost. After each wave, the enemies with the highest Aggression score also have the highest probability of mating and producing offspring. Thus, we have created an explicit link in which Aggression is correlated with Fitness (number of offspring). Our games often have more than one of these Fitness Functions. For example, the Protean Swarm in Darwin’s Demons can also increase their mating chance with Accuracy (which measures how often they shoot at the player and how close they came to hitting the player) and Lifetime (which measures how long they last on the screen) .\nIf we turn off the fitness functions, then after each wave the enemies undergo random mating. Adaptive evolution does not occur, but the enemy traits might still evolve randomly because of Random Genetic Drift.\n\n\nTime\nThe concept of time in video games is often defined in terms of waves or levels. Both of these terms imply a progression toward the game’s goal, along with a corresponding increase in difficulty. In our games, we usually specify time in terms of generations. A wave of enemies begin the game, the player defeats them, and then the next wave is created with Inheritance using a mating function specified as described above. As the generations (waves) proceed, the enemies with traits that are best able to optimize the fitness functions have more offspring, and the population adapts to the game play conditions. Most of these conditions are created by player choices and playstyle, and thus the enemies adapt to the player. Difficulty increases organically and repeated gameplay often creates novel adaptive solutions to the same play style.\n\n\n\nEducational Outcomes\nWe reasoned that playing these types of games might have implications for STEM education. The success of the player is based on her comprehension and application of principles of evolutionary biology. The parallels to real world examples are numerous, and include the rapid evolution of antibiotic resistance in microbial pathogens, adaptation of crop pests to chemical and biological control measures, and behavioral adaptation to captivity in domesticated animals.\nAdding biological evolution to video games makes the games better for the game player and facilitates player comprehension of complex concepts that are hard to teach."
  },
  {
    "objectID": "Research.html#get-involved",
    "href": "Research.html#get-involved",
    "title": "RESEARCH",
    "section": "Get Involved",
    "text": "Get Involved\nIf you are interested in joining the lab and working in the studio, reach out to me by email."
  },
  {
    "objectID": "Research.html#behavioral-genomics-and-adaptation-to-captivity",
    "href": "Research.html#behavioral-genomics-and-adaptation-to-captivity",
    "title": "RESEARCH",
    "section": "Behavioral Genomics and Adaptation to Captivity",
    "text": "Behavioral Genomics and Adaptation to Captivity\n The process of adaptation to captivity can cause striking changes in a variety of behavioral phenotypes, including aggressive, feeding, and reproductive behaviors. However, some of the most profound and consistent evolutionary changes occur in behaviors related to fearfulness and anxiety, with domesticated animals often described as less fearful than their wild progenitor populations. The evolution of reduced fearfulness during captivity has been observed in a variety of vertebrate taxa, including mammals (Harri et al., 2003), birds (Jensen & Andersson, 2005), and fish (Johnsson & Abrahams, 1991; Robison & Rowland, 2005). Despite the prevalence of behavioral evolution during adaptation to captivity, we know surprisingly little about the underlying genetic changes that occur during domestication. What kinds of molecular variation (amino acid sequence, regulatory, or non coding RNA) are associated with variation in fear and anxiety related behaviors? What kinds of genes are typically changed in response to domestication selection? Are the apparently parallel changes in behavior across independent domestication events reflective of parallel molecular evolution, or does domestication result from myriad molecular routes to the same phenotypic endpoint? The answers to these questions are important in many contexts, including the study of the molecular mechanisms of behavioral evolution, the genetic basis of complex behaviors, and the effective conservation of captively reared species.\nWe use the zebrafish to study the genetic basis of fear related behaviors that commonly change during domestication in fish. The zebrafish is an excellent system for this purpose, combining a robust genomics toolset with superior experimental tractability. Our lab has documented variation among wild and laboratory derived strains consistent with the effects of domestication. The behavioral variation among wild and domesticated strains can be seen in the video on this page. This video shows two tanks of zebrafish randomly pulled from our zebrafish colony. One tank contains a highly domesticated (&gt;30 generations) strain (Scientific Hatcheries), and the other tank contains a strain with a more recent history (~5 generations) of domestication (Nadia). We have quantified surface orientation (Robison and Rowland 2005, Benner et al 2010), observer orientation (Benner et al 2010), feeding latency (Oswald and Robison 2008), and open field behavior (Oswald and Robison in review) in these strains, and shown that they vary markedly in these anxiety related behaviors.\nWe use a variety of genomics approaches to understand the mechanisms that drive behavioral adaptation to captivity. We have compared the brain transcriptomes of wild and domesticated strains using both microarray platforms and Illumina and 454 based RNAseq. We have discovered many promising candidate genes that appear to differentiate behaviorally bold and behaviorally shy animals. We have also used RNAseq approaches to identify more than 20,000 SNPs that vary among our zebrafish strains. We are currently using these SNPs for quantitative trait locus (QTL) analyses.\nWe also combine these genomics approaches with quantitative genetics experiments. Mary Oswald, a recent Ph.D. graduate from our lab, has performed selection experiments on observer orientation. She has shown that these fear related behaviors have a significant genetic basis and are genetically correlated. Her selection experiment is now being continued by Matt Singer, who is a current Ph.D."
  },
  {
    "objectID": "Research.html#quantitative-genetics",
    "href": "Research.html#quantitative-genetics",
    "title": "RESEARCH",
    "section": "Quantitative Genetics",
    "text": "Quantitative Genetics"
  },
  {
    "objectID": "BCB520/posts/T6-APIsandJSON/index.html",
    "href": "BCB520/posts/T6-APIsandJSON/index.html",
    "title": "TUTORIAL 6 - APIs and JSON data",
    "section": "",
    "text": "library(tidyr)\nlibrary(dplyr)\nlibrary(repurrrsive)\nlibrary(tibblify)\nlibrary(purrr)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(rjson)\nlibrary(jsonlite)\nlibrary(ggplot2)\n\n\nBio&lt;-fromJSON(\"draft.json\")\n\nnoway&lt;-as.data.frame(Bio)\n\nplayers&lt;- noway %&gt;%\n  select(data.draftYear, data.playerId, data.playerName, data.draftYear,\n         data.roundNumber, data.overallPickNumber, data.pickInRound,\n         data.height, data.weight, data.position)\n\ncleanplayers &lt;- drop_na(players)\n\n\napi_url &lt;- \"https://statsapi.web.nhl.com\"\n\n\nrecentdrafts&lt;-cleanplayers%&gt;%\n  filter(data.draftYear&gt;1999, data.draftYear&lt;2018)\nrecentdrafts$playerId&lt;-recentdrafts$data.playerId\nplayerIds &lt;- as.list(recentdrafts$data.playerId)\n\ntestloop&lt;-data.frame()\n\nfor (player_id in playerIds){\n  \n  \n\nendpoint &lt;- paste0(\"/api/v1/people/\", player_id, \"/stats?stats=yearByYear\")\n\n\nurl_json &lt;- paste0(api_url,endpoint)\n\nraw_json &lt;- url_json %&gt;% \n  httr::GET() %&gt;% \n  httr::content()\n\nargh &lt;- tibblify(raw_json$stats[[1]]$splits)\n\nplayerstats&lt;- unnest_wider(argh, col=c(stat,league))\nplayerstats$playerId&lt;-player_id\nplayerstatsfinal&lt;-playerstats %&gt;%\n  filter(name==\"National Hockey League\") %&gt;%\n  select(season, games, \n         name, playerId) \n  \ntestloop&lt;-rbind(testloop,playerstatsfinal)\n}\n\nargh2 &lt;- tibblify(glorp$stats$splits[[1]])\n\nd2000on&lt;-full_join(testloop,recentdrafts, by=\"playerId\")\n\n\ndataIwant &lt;- rbind(d2000on, d2018, d2019, d2020, d2020on)\nwrite.csv(dataIwant, file=\"NHLdraftgames.csv\")"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#last-lecture",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#last-lecture",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "LAST LECTURE",
    "text": "LAST LECTURE\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#what",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#what",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "WHAT?",
    "text": "WHAT?\n Before you design a visualization, you need to understand the data. Here, we consider the semantics to describe the DATA TYPES and DATA ATTRIBUTES."
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#the-three-major-data-types",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#the-three-major-data-types",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "THE THREE MAJOR DATA TYPES",
    "text": "THE THREE MAJOR DATA TYPES"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#data-attributes",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#data-attributes",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "DATA ATTRIBUTES",
    "text": "DATA ATTRIBUTES"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#what-1",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#what-1",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "WHAT?",
    "text": "WHAT?\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#data-semantics",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#data-semantics",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "DATA SEMANTICS",
    "text": "DATA SEMANTICS\n\n\n\nWhat does this sequence of six numbers mean?\n14, 2.6, 30, 30, 15, 100001 Two points far from each other in 3D space?\n\n\nVIZ"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#data-semantics-1",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#data-semantics-1",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "DATA SEMANTICS",
    "text": "DATA SEMANTICS\n\n\n\nWhat does this sequence of six numbers mean?\n14, 2.6, 30, 30, 15, 100001 Two points close to each other in 2D space, with 15 links between them, and a weight of 100001 for the link?\n\n\nVIZ"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#data-semantics-2",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#data-semantics-2",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "DATA SEMANTICS",
    "text": "DATA SEMANTICS\n\n\n\nWhat about this data?\nBasil, 7, S, Pear:\nFood shipment of produce (basil & pear) arrived in satisfactory condition on 7th day of month\n\n\nVIZ"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#data-semantics-3",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#data-semantics-3",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "DATA SEMANTICS",
    "text": "DATA SEMANTICS\n\n\n\nWhat about this data?\nBasil, 7, S, Pear:\nBasil Point neighborhood of city had 7 inches of snow cleared by the Pear Creek Limited snow removal service\n\n\nVIZ"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#data-semantics-4",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#data-semantics-4",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "DATA SEMANTICS",
    "text": "DATA SEMANTICS\n\n\n\nWhat about this data?\nBasil, 7, S, Pear:\nLab rat Basil made 7 attempts to find way through south section of maze, these trials used pear as reward food\n\n\nVIZ"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#semantics",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#semantics",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "SEMANTICS",
    "text": "SEMANTICS\nThe meaning of a word, phrase, sentence, or text.\nBasil, 7, S, Pear"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#semantics-for-data",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#semantics-for-data",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "SEMANTICS FOR DATA",
    "text": "SEMANTICS FOR DATA\n\n\n\nSemantics\n\nitem: individual entity, discrete\n\neg patient, car, stock, city\n“independent variable”\n\nattribute: property that is measured, observed, logged…\n\neg height, blood pressure for patient\neg horsepower, make for car\n“dependent variable”\n\n\n\n\nData Table\n\n\n\n\nITEM: Person\nATTRIBUTES: Name, Age, Shirt Size, Favorite Fruit"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#other-data-types",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#other-data-types",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "OTHER DATA TYPES",
    "text": "OTHER DATA TYPES\n\nLinks\n\nexpress relationship between two items\ne.g/ friendship on facebook, interaction between proteins\n\nPositions\n\nspatial data: location in 2D or 3D\ne.g. pixels in photo, voxels in MRI scan, latitude/longitude\n\nGrids\n\nsampling strategy for continuous data"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#what-2",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#what-2",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "WHAT?",
    "text": "WHAT?\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#dataset-types-tables",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#dataset-types-tables",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "DATASET TYPES: TABLES",
    "text": "DATASET TYPES: TABLES\nFlat Table\n\n\n\nOne ITEM per row\n\noften called an observation\n\nEach column is an ATTRIBUTE\n\noften called a variable\n\nA cell holds the VALUE for an item/attribute pair\nA UNIQUE key can be used (implicitly or explicitly) to identify each item even if they share all measured attributes"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#flat-table-example",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#flat-table-example",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "FLAT TABLE EXAMPLE",
    "text": "FLAT TABLE EXAMPLE"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#multidimensional-tables",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#multidimensional-tables",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "MULTIDIMENSIONAL TABLES",
    "text": "MULTIDIMENSIONAL TABLES\nindexing based on multiple keys (eg genes, patients)"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#networks",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#networks",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "NETWORKS",
    "text": "NETWORKS\nNetwork/graph nodes (vertices) connected by links (edges). A tree is special case: no cycles, often have roots, and are directed."
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#fields",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#fields",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "FIELDS",
    "text": "FIELDS"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#spatial-fields-1",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#spatial-fields-1",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "SPATIAL FIELDS 1",
    "text": "SPATIAL FIELDS 1\nAttribute values associated w/ cells cell contains value from continuous domain (eg temperature, pressure, wind velocity measured or simulated)."
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#spatial-fields-2",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#spatial-fields-2",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "SPATIAL FIELDS 2",
    "text": "SPATIAL FIELDS 2\n\n\n\n\nAttribute values associated w/ cells.\nCell contains value from continuous domain\n\n(eg temperature, pressure, wind velocity)\n\nMeasured or simulated.\nMajor concerns\n\nsampling:\n\nwhere attributes are measured\n\ninterpolation:\n\nhow to model attributes elsewhere\n\ngrid types"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#spatial-fields-3",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#spatial-fields-3",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "SPATIAL FIELDS 3",
    "text": "SPATIAL FIELDS 3\n\n\n\nAttribute values associated w/ cells.\nCell contains value from continuous domain\n\n(eg temperature, pressure, wind velocity)\n\nMeasured or simulated.\nMajor concerns\n\nsampling:\n\nwhere attributes are measured\n\ninterpolation:\n\nhow to model attributes elsewhere\n\ngrid types\n\nMajor divisions - attributes per cell:\n\nscalar (1)\nvector (2)\ntensor (many)"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#geometry",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#geometry",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "GEOMETRY",
    "text": "GEOMETRY"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#geometry-2",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#geometry-2",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "GEOMETRY 2",
    "text": "GEOMETRY 2\n\n\n\nShape of items\nExplicit spatial positions / regions\n\npoints, lines, curves, surfaces, volumes\n\nBoundary between computer graphics and visualization\n\ngraphics: geometry taken as given\nvis: geometry is result of a design decision"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#collections",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#collections",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "COLLECTIONS",
    "text": "COLLECTIONS"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#collections-2",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#collections-2",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "COLLECTIONS 2",
    "text": "COLLECTIONS 2\n\n\nGrouping Items:\n\nsets\n\nunique items\nunordered\n\nlists\n\nordered\nduplicates possible\n\nclusters\n\ngroups of similar items"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#data-types",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#data-types",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "DATA TYPES",
    "text": "DATA TYPES"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#attribute-types",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#attribute-types",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "ATTRIBUTE TYPES",
    "text": "ATTRIBUTE TYPES\n\n\n\nCategorical (nominal):\n\ncompare equality\nno implicit ordering\n\nOrdered:\n\nordinal\nless/greater than defined\n\nQuantitative:\n\nmeaningful magnitude\narithmetic possible"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#example",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#example",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "EXAMPLE",
    "text": "EXAMPLE\nCategorical\nOrdinal\nQuantitative"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#example-1",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#example-1",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "EXAMPLE",
    "text": "EXAMPLE\nCategorical\nOrdinal\nQuantitative"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#additional-semantic-components",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#additional-semantic-components",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "ADDITIONAL SEMANTIC COMPONENTS",
    "text": "ADDITIONAL SEMANTIC COMPONENTS"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#data-abstraction",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#data-abstraction",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "DATA ABSTRACTION",
    "text": "DATA ABSTRACTION\n\nGOAL: Translate from domain-specific language to generic (and consistent) visualization language.\n\nIdentify dataset type(s) and attribute types.\nIdentify cardinality.\n\nhow many items in the dataset?\nwhat is cardinality of each attribute?\n\nnumber of levels for categorical data?\nrange for quantitative data\n\n\nConsider whether to transform the data.\n\nguided by your understanding of the task."
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#models-data-vs-conceptual",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#models-data-vs-conceptual",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "MODELS: DATA VS CONCEPTUAL",
    "text": "MODELS: DATA VS CONCEPTUAL\n\n\nData Model\n\nmathematical abstraction\nsets with operations, eg floats with * / - + variable data types in programming languages\n\nConceptual Model\n\nmental construction (semantics)\nsupports reasoning\ntypically based on understanding of tasks\n\nThe Data Abstraction process relies on conceptual model for transforming data if needed"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#models-example",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#models-example",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "MODELS: EXAMPLE",
    "text": "MODELS: EXAMPLE\n\nData Model: floats\n\n32.52, 54.06, -14.35,\n\nConceptual Model:\n\ntemperature\n\nPossible data abstractions:\n\nQUANTITATIVE: continuous to 2 significant figures:\n\nTASK: Forecasting the weather\n\nORDINAL: Hot, Warm, Cold:\n\nTASK: Deciding if my bath water is ready\n\nCATEGORICAL: Above Freezing, Below Freezing:\n\nTASK: Deciding if I should leave the house today"
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#derived-attributes",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#derived-attributes",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "DERIVED ATTRIBUTES",
    "text": "DERIVED ATTRIBUTES\nDerived attribute: Data computed from original (collected, observed) attributes."
  },
  {
    "objectID": "BCB520/posts/L2-Data-Abstraction/index.html#summary",
    "href": "BCB520/posts/L2-Data-Abstraction/index.html#summary",
    "title": "LECTURE 2 - DATA ABSTRACTION",
    "section": "SUMMARY",
    "text": "SUMMARY\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively.\n\n\n\n\nCANVAS…HOME"
  },
  {
    "objectID": "BCB520/posts/T4-BarriesData/index.html",
    "href": "BCB520/posts/T4-BarriesData/index.html",
    "title": "TUTORIAL 4",
    "section": "",
    "text": "In this assignment (detalied here), I will identify, import, describe, and host a data set that will be used throughout the remainder of the BCB 504 course for Data Visualizations.\n\n\nI’ve chosen a subset of a large dataset produced by our evolutionary video game, Project Hastur. We built Project Hatur to be an evolutionary video game, and we are bold in our assertions of that fact. But we haven’t really published any evidence that the evolutionary model works. This data set is the beginning of that exercise.\n\n\n\n\n\n\nNote\n\n\n\nPROJECT HASTUR creates a unique challenge by combining elements of 3D tower defense and real-time strategy with biological evolution. Fight against alien Proteans that evolve - using biologically accurate models of evolution - to overcome the player’s defenses.\nEach creature you will face has its own unique genome controlling its abilities, behaviors, and appearance. Those that make it the furthest and do the most damage to your defenses have the most offspring you will have to defeat in the next generation. The result? Evolution responds to the player’s strategy and makes every playthrough a unique experience.\nUse four upgradable turret classes, plus airstrikes and combat robots, to fight against the Protean invasion. Make strategic decisions about which turrets to build, when to upgrade them, and where to place them on the hex grid. A well-timed airstrike can change the flow of the game, but you’ll have to wait before you can use it again. Unlock powerful upgrades for each turret class as you move across the Nyx system. As you play, the Proteans evolve new weapon resistances, behaviors, and movement capabilities to better destroy your defenses.\nIn CAMPAIGN MODE, battle through a series of maps as a military defense commander to protect the planet Nyx from the ever-evolving threat of the Proteans. Unlock weapons and upgrades and use them to fight against the Protean swarm and learn about the mysteries of Project Hastur.\nIn EXPERIMENT MODE, choose any map, tweak the parameters, and play infinitely to see what you can evolve. Change the number of creatures and the parameters of evolution, make your turrets invincible, or crank up the biomatter and experiment with the most powerful turret upgrades. Experiment mode lets you experience Project Hastur your way.\n\n\n\n\nThe data were collected by running Project Hastur in Experiment mode using four predefined conditions:\nI: The CHIP SHREDDER towers when Fitness Functions were turned ON and Civilians were PRESENT.\nH: The CHIP SHREDDER towers when Fitness Functions were turned OFF and Civilians were PRESENT.\nG: The CHIP SHREDDER towers when Fitness Functions were turned ON and Civilians were ABSENT.\nK: The AUTOCANNON towers when Fitness Functions were turned ON and Civilians were ABSENT.\nEach experimental condition was run 9 times (9 replicates).\n\n\n\n\nI’m going to use the vroom package to import multiple files. Each file is a replicate and the filename tells us about the experimental condition. Below I convert the filename variable (I named it path) into a a single categorical attribute called Fit that uses the letter codes above.\n\n\nCode\nlibrary(vroom)\nlibrary(stringr)\nlibrary(tidyverse)\nlibrary(readxl)\nfiles &lt;- fs::dir_ls(glob = \"*.csv\")\n\nHastur &lt;- vroom(files, id = \"path\", \n                col_select = c(path, Generation, ID, Origin, AsexualReproduction, Fitness, Health,\n                               SightRange, Armor, Damage, WalkSpeed, RunSpeed, Acceleration, \n                               TurnRate, Attraction0, Attraction1, Attraction2))\n\nHastur$Fit &lt;- str_split_i(Hastur$path, pattern = \"\", 1)\nHastur$replicate &lt;- str_split_i(Hastur$path, pattern = \"\", 4)\n\n\nThe glimpse command in the Tidyverse package is a nice way to summarize the data frame:\n\n\nCode\nglimpse(Hastur)\n\n\nRows: 412,246\nColumns: 19\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\n$ path                &lt;chr&gt; \"GSC1.csv\", \"GSC1.csv\", \"GSC1.csv\", \"GSC1.csv\", \"G…\n$ Generation          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ ID                  &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, …\n$ Origin              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ AsexualReproduction &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Fitness             &lt;dbl&gt; 57.83508, 66.87755, 66.14652, 65.88873, 62.12119, …\n$ Health              &lt;dbl&gt; 1006, 1012, 1011, 992, 983, 1020, 982, 963, 996, 9…\n$ SightRange          &lt;dbl&gt; 9.952521, 10.096590, 9.954091, 10.066170, 10.02955…\n$ Armor               &lt;dbl&gt; 0.05081077, 0.05080924, 0.05010696, 0.04903501, 0.…\n$ Damage              &lt;dbl&gt; 49, 51, 51, 50, 50, 51, 50, 49, 51, 50, 49, 50, 49…\n$ WalkSpeed           &lt;dbl&gt; 6.930266, 7.034348, 6.970608, 6.903729, 6.962081, …\n$ RunSpeed            &lt;dbl&gt; 20.03562, 19.88800, 19.80754, 19.94738, 19.95583, …\n$ Acceleration        &lt;dbl&gt; 14.70648, 15.05868, 14.85994, 14.89853, 15.01570, …\n$ TurnRate            &lt;dbl&gt; 356.3890, 361.2032, 358.9919, 361.8476, 360.6143, …\n$ Attraction0         &lt;dbl&gt; 0.158477500, -0.007134318, -0.063494000, 0.0125864…\n$ Attraction1         &lt;dbl&gt; -0.070695680, 0.059872570, -0.003332689, 0.0458469…\n$ Attraction2         &lt;dbl&gt; -0.108705200, 0.015018780, -0.007600136, 0.0120656…\n$ Fit                 &lt;chr&gt; \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", \"G\", …\n$ replicate           &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", …\n\n\n\n\n\n\n\nWhat we have here is a (big) Flat Table. The Items are the rows, and each row is an individual alien enemy that existed during one of the replicates. Each Item (alien) is described by Attributes, which are arranged in the columns.\n\n\n\nThe glimpse we did in the preceding section gives us a hint as to what each attribute type might be. Let’s flesh that out a bit though. I’m going to create a new data frame that describes the attributes.\n\n\nCode\nAttributes &lt;- read_excel(\"Attributes.xlsx\")\nknitr::kable(Attributes)\n\n\n\n\n\n\n\n\n\n\nAttribute\nType\nNote\n\n\n\n\npath\nCategorical\neach File Name is a unique replicate\n\n\nGeneration\nQuantitative\nEach Enemy Wave is a Generation\n\n\nID\nOrdinal\nEach enemy has a unique ID within each replicate\n\n\nOrigin\nCategorical\nThe hive from which the enemy was spawned\n\n\nAsexualReproduction\nCategorical\nWas the enemy spawned by infectiing a civilian?\n\n\nFitness\nQuantitative\nThe value of Fitness is used to determine probability of reproduction\n\n\nHealth\nQuantitative\nHit Points\n\n\nSightRange\nQuantitative\nHow far they can see civilians, towers, etc\n\n\nArmor\nQuantitative\nresistance to physical damage\n\n\nDamage\nQuantitative\nhow much damage they do to towers\n\n\nWalkSpeed\nQuantitative\nhow fast they can walk\n\n\nRunSpeed\nQuantitative\nhow fast they can run\n\n\nAcceleration\nQuantitative\nhow fast they can transition from walking to running\n\n\nTurnRate\nQuantitative\nhow fast they can turn\n\n\nAttraction0\nQuantitative\nnegative values is attraction to civilians, positive is avoidance\n\n\nAttraction1\nQuantitative\nnegative values is attraction to towers, positive is avoidance\n\n\nAttraction2\nQuantitative\nnegative values is attraction to the base, positive is avoidance\n\n\nFit\nCategorical\nI, H, G, or K - an inscrutable code about fitness conditions\n\n\n\n\n\nThe problem here is my inscrutable filename codes for that Fit variable. Those letter codes actually contain information on a couple hidden variables. I’m going to create a new variable called Gun and another called Civilians. I’ll add those to the main data file and also the Data Dicttionary.\n\n\nCode\nHastur$Gun &lt;- \"CHIP SHREDDER\"\nHastur$Civilians &lt;- \"Present\"\n  \n\n  Hastur$Gun[Hastur$Fit==\"K\"]&lt;- \"AUTOCANNON\"\n     \n  Hastur$Civilians[Hastur$Fit==\"K\" | Hastur$Fit ==\"G\"] &lt;- \"ABSENT\"\n     \n\n  Attributes&lt;-rbind(Attributes, c(\"Gun\",\"Categorical\", \"Autocannon or Chip Shredder\"))\n  Attributes&lt;-rbind(Attributes, c(\"Civilians\",\"Categorical\", \"Present or Absent\"))\n\n\n\n\nCode\n  knitr::kable(Attributes)\n\n\n\n\n\n\n\n\n\n\nAttribute\nType\nNote\n\n\n\n\npath\nCategorical\neach File Name is a unique replicate\n\n\nGeneration\nQuantitative\nEach Enemy Wave is a Generation\n\n\nID\nOrdinal\nEach enemy has a unique ID within each replicate\n\n\nOrigin\nCategorical\nThe hive from which the enemy was spawned\n\n\nAsexualReproduction\nCategorical\nWas the enemy spawned by infectiing a civilian?\n\n\nFitness\nQuantitative\nThe value of Fitness is used to determine probability of reproduction\n\n\nHealth\nQuantitative\nHit Points\n\n\nSightRange\nQuantitative\nHow far they can see civilians, towers, etc\n\n\nArmor\nQuantitative\nresistance to physical damage\n\n\nDamage\nQuantitative\nhow much damage they do to towers\n\n\nWalkSpeed\nQuantitative\nhow fast they can walk\n\n\nRunSpeed\nQuantitative\nhow fast they can run\n\n\nAcceleration\nQuantitative\nhow fast they can transition from walking to running\n\n\nTurnRate\nQuantitative\nhow fast they can turn\n\n\nAttraction0\nQuantitative\nnegative values is attraction to civilians, positive is avoidance\n\n\nAttraction1\nQuantitative\nnegative values is attraction to towers, positive is avoidance\n\n\nAttraction2\nQuantitative\nnegative values is attraction to the base, positive is avoidance\n\n\nFit\nCategorical\nI, H, G, or K - an inscrutable code about fitness conditions\n\n\nGun\nCategorical\nAutocannon or Chip Shredder\n\n\nCivilians\nCategorical\nPresent or Absent\n\n\n\n\n\n\n\n\n\nI’m publishing to GitHub! We will elaborate on this step as everyone progresses through the assignment.\n\n\n\nFor this data set, I am currently defining the user as … me! My hypothesis is that the two Fitness conditions create different evolutionary outcomes of the aliens in Project Hastur. Some relevant ACTION TARGET pairs might be:\nDISCOVER TRENDS\nDISCOVER DISTRIBUTION\nDISCOVER SIMILARITY\nCOMPARE TRENDS\nCOMPARE DISTRIBUTION\nI’m going to try COMPARE TRENDS. I want to COMPARE the TREND in Health over time (Generation) between the two Gun types. To do this, I’ll create a scatterplot, faceted by Gun. I’m suspicious that Acceleration is involved somehow, so I’m coloring with that variable.\n\n\nCode\nggplot(Hastur, aes(x=Generation, y = Health))+\n  geom_point(aes(color=Acceleration), alpha = 0.01, size = 1)+\n  scale_color_continuous(low=\"red\", high = \"blue\")+\n  facet_grid(replicate~Gun)\n\n\n\n\n\nInteresting… it looks like a clear trend for Health to increase under the withering fire of the AUTO CANNONS, but not when the player uses the CHIP SHREDDER. It is a bit hard to see what is going on with Acceleration, so let’s reverse the graphs so that we plot Acceleration on the y axis but color by Health.\n\n\nCode\nggplot(Hastur, aes(x=Generation, y = Acceleration))+\n  geom_point(aes(color=Health), alpha = 0.01, size = 1)+\n  scale_color_continuous(low=\"red\", high = \"blue\")+\n  facet_grid(replicate~Gun)\n\n\n\n\n\nI’m now confident that the replicates within each Gun type are pretty similar, and I can SUMMARIZE the individual data points. This will help with the COMPARE TRENDS task, I think.\n\n\nCode\nggplot(Hastur, aes(x=Generation, y = Health))+\n  geom_point(aes(color=Acceleration), alpha = 0.01, size = 1)+\n  geom_smooth()+\n  scale_color_continuous(low=\"red\", high = \"blue\")+\n  facet_wrap(~Gun)\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nCode\nggplot(Hastur, aes(x=Generation, y = Acceleration))+\n  geom_point(aes(color=Health), alpha = 0.01, size = 1)+\n  geom_smooth()+\n  scale_color_continuous(low=\"red\", high = \"blue\")+\n  facet_wrap(~Gun)\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#plan",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#plan",
    "title": "LECTURE 4",
    "section": "PLAN",
    "text": "PLAN\n\nAssignment 3 Review.\nAligning the VAD model with other frameworks.\nEncoding with Marks and Channels."
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#assignment-3-review",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#assignment-3-review",
    "title": "LECTURE 4",
    "section": "ASSIGNMENT 3 REVIEW",
    "text": "ASSIGNMENT 3 REVIEW\nRondald’s Portfolio\nJiyin’s Portfolio\nCody’s Portfolio\nErik’s Portfolio"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#vad-model",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#vad-model",
    "title": "LECTURE 4",
    "section": "VAD MODEL",
    "text": "VAD MODEL"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#understand-the-data",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#understand-the-data",
    "title": "LECTURE 4",
    "section": "UNDERSTAND THE DATA",
    "text": "UNDERSTAND THE DATA\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#understand-the-task",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#understand-the-task",
    "title": "LECTURE 4",
    "section": "UNDERSTAND THE TASK",
    "text": "UNDERSTAND THE TASK\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#visual-encoding",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#visual-encoding",
    "title": "LECTURE 4",
    "section": "VISUAL ENCODING",
    "text": "VISUAL ENCODING\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#other-frameworks",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#other-frameworks",
    "title": "LECTURE 4",
    "section": "OTHER FRAMEWORKS",
    "text": "OTHER FRAMEWORKS\n\nThe Tidyverse\nThe Grammar of Graphics\nTufte"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#tidyverse",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#tidyverse",
    "title": "LECTURE 4",
    "section": "TIDYVERSE",
    "text": "TIDYVERSE\nR packages for data science:\n\n\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. The best way to explore and understand the tidyverse is with cheetsheets, like this one for tidyr!"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#grammar-of-graphics",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#grammar-of-graphics",
    "title": "LECTURE 4",
    "section": "GRAMMAR OF GRAPHICS",
    "text": "GRAMMAR OF GRAPHICS\nThe ggplot2 cheatsheet!"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#tufte",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#tufte",
    "title": "LECTURE 4",
    "section": "TUFTE",
    "text": "TUFTE\nTufte’s Website\nA Quarto Page Layout Example"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#analysis-framework",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#analysis-framework",
    "title": "LECTURE 4",
    "section": "ANALYSIS FRAMEWORK",
    "text": "ANALYSIS FRAMEWORK\nFour levels, three questions\n\n\n\nDomain situation defines the target users.\nAbstraction translate from specifics of domain to vocabulary of vis\n\nWHAT is shown? data abstraction\nWHY is the user looking at it? task abstraction\n\nIdiom defines the visualization\n\nHOW is it shown?\n\nvisual encoding idiom: how to draw\ninteraction idiom: how to manipulate\n\n\nAlgorithm creates the visualization\n\nevaluated with computational efficiency"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#encoding",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#encoding",
    "title": "LECTURE 4",
    "section": "ENCODING",
    "text": "ENCODING\nWe are defining the structure of the visualization (the idiom).\nTo do this, we use MARKS and CHANNELS:\n\nMARKS represent ITEMS or LINKS\nCHANNELS change the appearance of MARKS based on ATTRIBUTES"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#marks-for-items",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#marks-for-items",
    "title": "LECTURE 4",
    "section": "MARKS FOR ITEMS",
    "text": "MARKS FOR ITEMS"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#marks-for-links",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#marks-for-links",
    "title": "LECTURE 4",
    "section": "MARKS FOR LINKS",
    "text": "MARKS FOR LINKS\n\n Bubblesets\n Force Directed Graph"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#observable-in-quarto",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#observable-in-quarto",
    "title": "LECTURE 4",
    "section": "OBSERVABLE IN QUARTO!",
    "text": "OBSERVABLE IN QUARTO!\n\n\nCode\nd3 = require(\"d3@7\")\n\n\nchart = ForceGraph(miserables, {\n  nodeId: d =&gt; d.id,\n  nodeGroup: d =&gt; d.group,\n  nodeTitle: d =&gt; `${d.id}\\n${d.group}`,\n  linkStrokeWidth: l =&gt; Math.sqrt(l.value),\n  width,\n  height: 1000,\n  invalidation // a promise to stop the simulation when the cell is re-run\n})\n\n\nmiserables = FileAttachment(\"miserables.json\").json()\n\n\n// Copyright 2021 Observable, Inc.\n// Released under the ISC license.\n// https://observablehq.com/@d3/force-directed-graph\nfunction ForceGraph({\n  nodes, // an iterable of node objects (typically [{id}, …])\n  links // an iterable of link objects (typically [{source, target}, …])\n}, {\n  nodeId = d =&gt; d.id, // given d in nodes, returns a unique identifier (string)\n  nodeGroup, // given d in nodes, returns an (ordinal) value for color\n  nodeGroups, // an array of ordinal values representing the node groups\n  nodeTitle, // given d in nodes, a title string\n  nodeFill = \"currentColor\", // node stroke fill (if not using a group color encoding)\n  nodeStroke = \"#fff\", // node stroke color\n  nodeStrokeWidth = 1.5, // node stroke width, in pixels\n  nodeStrokeOpacity = 1, // node stroke opacity\n  nodeRadius = 5, // node radius, in pixels\n  nodeStrength,\n  linkSource = ({source}) =&gt; source, // given d in links, returns a node identifier string\n  linkTarget = ({target}) =&gt; target, // given d in links, returns a node identifier string\n  linkStroke = \"#999\", // link stroke color\n  linkStrokeOpacity = 0.6, // link stroke opacity\n  linkStrokeWidth = 1.5, // given d in links, returns a stroke width in pixels\n  linkStrokeLinecap = \"round\", // link stroke linecap\n  linkStrength,\n  colors = d3.schemeTableau10, // an array of color strings, for the node groups\n  width = 1000, // outer width, in pixels\n  height = 1000, // outer height, in pixels\n  invalidation // when this promise resolves, stop the simulation\n} = {}) {\n  // Compute values.\n  const N = d3.map(nodes, nodeId).map(intern);\n  const LS = d3.map(links, linkSource).map(intern);\n  const LT = d3.map(links, linkTarget).map(intern);\n  if (nodeTitle === undefined) nodeTitle = (_, i) =&gt; N[i];\n  const T = nodeTitle == null ? null : d3.map(nodes, nodeTitle);\n  const G = nodeGroup == null ? null : d3.map(nodes, nodeGroup).map(intern);\n  const W = typeof linkStrokeWidth !== \"function\" ? null : d3.map(links, linkStrokeWidth);\n  const L = typeof linkStroke !== \"function\" ? null : d3.map(links, linkStroke);\n\n  // Replace the input nodes and links with mutable objects for the simulation.\n  nodes = d3.map(nodes, (_, i) =&gt; ({id: N[i]}));\n  links = d3.map(links, (_, i) =&gt; ({source: LS[i], target: LT[i]}));\n\n  // Compute default domains.\n  if (G && nodeGroups === undefined) nodeGroups = d3.sort(G);\n\n  // Construct the scales.\n  const color = nodeGroup == null ? null : d3.scaleOrdinal(nodeGroups, colors);\n\n  // Construct the forces.\n  const forceNode = d3.forceManyBody();\n  const forceLink = d3.forceLink(links).id(({index: i}) =&gt; N[i]);\n  if (nodeStrength !== undefined) forceNode.strength(nodeStrength);\n  if (linkStrength !== undefined) forceLink.strength(linkStrength);\n\n  const simulation = d3.forceSimulation(nodes)\n      .force(\"link\", forceLink)\n      .force(\"charge\", forceNode)\n      .force(\"center\",  d3.forceCenter())\n      .on(\"tick\", ticked);\n\n  const svg = d3.create(\"svg\")\n      .attr(\"width\", width)\n      .attr(\"height\", height)\n      .attr(\"viewBox\", [-width / 2, -height / 2, width, height])\n      .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  const link = svg.append(\"g\")\n      .attr(\"stroke\", typeof linkStroke !== \"function\" ? linkStroke : null)\n      .attr(\"stroke-opacity\", linkStrokeOpacity)\n      .attr(\"stroke-width\", typeof linkStrokeWidth !== \"function\" ? linkStrokeWidth : null)\n      .attr(\"stroke-linecap\", linkStrokeLinecap)\n    .selectAll(\"line\")\n    .data(links)\n    .join(\"line\");\n\n  const node = svg.append(\"g\")\n      .attr(\"fill\", nodeFill)\n      .attr(\"stroke\", nodeStroke)\n      .attr(\"stroke-opacity\", nodeStrokeOpacity)\n      .attr(\"stroke-width\", nodeStrokeWidth)\n    .selectAll(\"circle\")\n    .data(nodes)\n    .join(\"circle\")\n      .attr(\"r\", nodeRadius)\n      .call(drag(simulation));\n\n  if (W) link.attr(\"stroke-width\", ({index: i}) =&gt; W[i]);\n  if (L) link.attr(\"stroke\", ({index: i}) =&gt; L[i]);\n  if (G) node.attr(\"fill\", ({index: i}) =&gt; color(G[i]));\n  if (T) node.append(\"title\").text(({index: i}) =&gt; T[i]);\n  if (invalidation != null) invalidation.then(() =&gt; simulation.stop());\n\n  function intern(value) {\n    return value !== null && typeof value === \"object\" ? value.valueOf() : value;\n  }\n\n  function ticked() {\n    link\n      .attr(\"x1\", d =&gt; d.source.x)\n      .attr(\"y1\", d =&gt; d.source.y)\n      .attr(\"x2\", d =&gt; d.target.x)\n      .attr(\"y2\", d =&gt; d.target.y);\n\n    node\n      .attr(\"cx\", d =&gt; d.x)\n      .attr(\"cy\", d =&gt; d.y);\n  }\n\n  function drag(simulation) {    \n    function dragstarted(event) {\n      if (!event.active) simulation.alphaTarget(0.3).restart();\n      event.subject.fx = event.subject.x;\n      event.subject.fy = event.subject.y;\n    }\n    \n    function dragged(event) {\n      event.subject.fx = event.x;\n      event.subject.fy = event.y;\n    }\n    \n    function dragended(event) {\n      if (!event.active) simulation.alphaTarget(0);\n      event.subject.fx = null;\n      event.subject.fy = null;\n    }\n    \n    return d3.drag()\n      .on(\"start\", dragstarted)\n      .on(\"drag\", dragged)\n      .on(\"end\", dragended);\n  }\n\n  return Object.assign(svg.node(), {scales: {color}});\n}\n\n\nimport {howto} from \"@d3/example-components\"\n\nimport {Swatches} from \"@d3/color-legend\""
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#channels",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#channels",
    "title": "LECTURE 4",
    "section": "CHANNELS",
    "text": "CHANNELS\n\n\n\nCHANNELS control the appearance of MARKS.\n\nThey are proportional to or based on ATTRIBUTES.\nTheir properties differ in the type and amount of information that can be conveyed to the human perceptual system."
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#visual-encoding-example",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#visual-encoding-example",
    "title": "LECTURE 4",
    "section": "VISUAL ENCODING EXAMPLE",
    "text": "VISUAL ENCODING EXAMPLE\nLet’s analyze the idiom structures below in terms of marks and channels."
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#redundant-encoding",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#redundant-encoding",
    "title": "LECTURE 4",
    "section": "REDUNDANT ENCODING",
    "text": "REDUNDANT ENCODING\nUses multiple channels for the same attribute.\n\nSends a stronger message\nUses up channels"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#choosing-channels",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#choosing-channels",
    "title": "LECTURE 4",
    "section": "CHOOSING CHANNELS",
    "text": "CHOOSING CHANNELS\n\nEXPRESSIVENESS\n\nMatch channel to data type.\n\nEFFECTIVENESS\n\nChannels differ in accuracy of perception."
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#channel-rankings",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#channel-rankings",
    "title": "LECTURE 4",
    "section": "CHANNEL RANKINGS",
    "text": "CHANNEL RANKINGS\n\nNote that spatial position ranks high for both types of channels."
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#grouping",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#grouping",
    "title": "LECTURE 4",
    "section": "GROUPING",
    "text": "GROUPING\n\n\n\nContainment\nConnection\nProximity\n\nSame spatial region.\n\nSimilarity\n\nSame values as other channels."
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#summary-so-far",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#summary-so-far",
    "title": "LECTURE 4",
    "section": "SUMMARY SO FAR",
    "text": "SUMMARY SO FAR"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#channel-effectiveness",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#channel-effectiveness",
    "title": "LECTURE 4",
    "section": "CHANNEL EFFECTIVENESS",
    "text": "CHANNEL EFFECTIVENESS\n\nAccuracy: how precisely can we tell the difference between encoded items?\nDiscriminability: how many unique steps can we perceive?\nSeparability: is our ability to use this channel affected by another one?\nPopout: can things jump out using this channel?"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#accuracy-theory",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#accuracy-theory",
    "title": "LECTURE 4",
    "section": "ACCURACY (THEORY)",
    "text": "ACCURACY (THEORY)\nSteven’s Psychophisical Power Law: \\(S=I^N\\)\n\n\n\n\n\n\n\n\nLENGTH (N=1)\nELECTRIC SHOCK (N=3.5)\nSATURATION (N=1.7)\nAREA (N=0.7)\nBRIGHTNESS (N=0.5)"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#accuracy-experimental",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#accuracy-experimental",
    "title": "LECTURE 4",
    "section": "ACCURACY (EXPERIMENTAL)",
    "text": "ACCURACY (EXPERIMENTAL)"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#discriminability",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#discriminability",
    "title": "LECTURE 4",
    "section": "DISCRIMINABILITY",
    "text": "DISCRIMINABILITY\nHow many usable steps are in the channel?"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#separability-vs-integrality",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#separability-vs-integrality",
    "title": "LECTURE 4",
    "section": "SEPARABILITY VS INTEGRALITY",
    "text": "SEPARABILITY VS INTEGRALITY"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#popout",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#popout",
    "title": "LECTURE 4",
    "section": "POPOUT",
    "text": "POPOUT\n\n\nfind the red dot how long does it take? parallel processing on many individual channels speed independent of distractor count speed depends on channel and amount of difference from distractors serial search for (almost all) combinations speed depends on number of distractors"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#popout-1",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#popout-1",
    "title": "LECTURE 4",
    "section": "POPOUT",
    "text": "POPOUT\n\n\nmany channels tilt, size, shape, proximity, shadow direction, … but not all! parallel line pairs do not pop out from tilted pairs"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#factors-affecting-accuracy",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#factors-affecting-accuracy",
    "title": "LECTURE 4",
    "section": "FACTORS AFFECTING ACCURACY",
    "text": "FACTORS AFFECTING ACCURACY\nalignment distractors distance common scale / alignment"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#relative-vs-absolute-judgements",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#relative-vs-absolute-judgements",
    "title": "LECTURE 4",
    "section": "RELATIVE VS ABSOLUTE JUDGEMENTS",
    "text": "RELATIVE VS ABSOLUTE JUDGEMENTS\nperceptual system mostly operates with relative judgements, not absolute that’s why accuracy increases with common frame/scale and alignment\nWeber’s Law: ratio of increment to background is constant filled rectangles differ in length by 1:9, difficult judgement white rectangles differ in length by 1:2, easy judgement"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#relative-luminance-judgements",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#relative-luminance-judgements",
    "title": "LECTURE 4",
    "section": "RELATIVE LUMINANCE JUDGEMENTS",
    "text": "RELATIVE LUMINANCE JUDGEMENTS\nperception of luminance is contextual based on contrast with surroundings"
  },
  {
    "objectID": "BCB520/posts/L4-Marks-Channels/index.html#relative-color-judgements",
    "href": "BCB520/posts/L4-Marks-Channels/index.html#relative-color-judgements",
    "title": "LECTURE 4",
    "section": "RELATIVE COLOR JUDGEMENTS",
    "text": "RELATIVE COLOR JUDGEMENTS\ncolor constancy across broad range of illumination conditions\n\n\n\n\nCANVAS…HOME"
  },
  {
    "objectID": "BCB520/posts/Certificate/index.html",
    "href": "BCB520/posts/Certificate/index.html",
    "title": "CERTIFICATE",
    "section": "",
    "text": "Learn how to think about, organize, analyze, and visualize data. Communicate data-driven insights to technical and lay audiences."
  },
  {
    "objectID": "BCB520/posts/Certificate/index.html#overview",
    "href": "BCB520/posts/Certificate/index.html#overview",
    "title": "CERTIFICATE",
    "section": "OVERVIEW",
    "text": "OVERVIEW\nWe live in an increasingly data-driven world. Basic data literacy and data science skills are becoming central to virtually every industry. Yet, limited opportunities exist to gain these skills without an advanced background in math and computer science. To address this workforce development need, we propose a competitively valued on-line graduate certificate in the Professional Applications in Data Science. The certificate is designed to offer rigorous training in the foundations of data science to anyone with a bachelor’s degree. Participants will learn how to think about, organize, analyze, and visualize data, and communicate data driven insights to diverse audiences. The curriculum emphasizes the use of data sets drawn from each student’s individual discipline, aligning the certificate’s workforce development impacts with the University of Idaho’s land grant mission.\n\nValue Proposition:\nThe graduate certificate in Professional Applications in Data Science will provide unique value to UI constituencies by:\n\nAligning data science training with fields of nascent demand that are part of our land grant mission, including Agriculture, Natural Resources, and Education.\nRequiring a digital data science portfolio with which students can demonstrate their proficiencies to potential employers.\nEmphasizing training in data communication - including verbal presentation and data visualization - two components of data science that are underrepresented in competing certificates.\nFilling a growing workforce development gap by offering a unique data science certificate that is appropriate for professionals with a bachelor’s degree who do not have a rigorous background in mathematics, statistics, or computer science.\n\n\n\nIntended Audience:\nThis certificate leverages the University of Idaho’s interdisciplinary culture to provide integrative training in the foundations of data science. It is intended for:\n\nWorking professionals with a bachelor’s degree whose career increasingly involves the generation, management, analysis, and visualization of large data sets. The certificate is appropriate for professionals in STEM fields, Health Care, Business, Government, Education, Journalism, Athletics, Natural Resources, and Agriculture.\nGraduate students in programs outside of the core technical disciplines of data science (statistics, math, engineering, or computer science). The certificate will complement disciplinary research methods courses with training in data management, visualization, and communication.\nUndergraduates at the UI who wish to incorporate data science training into their degree and graduate with a Bachelor’s degree and a graduate certificate.\n\n\n\nStudent Learning Outcomes:\nUpon completion of the certificate, students will be able to:\n\nUse open-source software to reproducibly manage, analyze, and visualize large, complex, and noisy data sets.\nPractice high quality and ethical data stewardship.\nUnderstand and execute data exploration.\nEffectively communicate data driven insights to experts and non-experts.\nDemonstrate their skills with an online portfolio of analyses and visualizations relevant to their field of specialization."
  },
  {
    "objectID": "BCB520/posts/Certificate/index.html#curriculum",
    "href": "BCB520/posts/Certificate/index.html#curriculum",
    "title": "CERTIFICATE",
    "section": "CURRICULUM",
    "text": "CURRICULUM\n\nPrerequisites:\nA Bachelor’s degree OR the student has senior standing and is enrolled in a bachelor’s degree program at the University of Idaho.\n\n\nCertificate Requirements (12 Credits Total)\n\n\n\n\n\n\n\n\n\n\n\n\nCourse\nName\nCredits\nPrerequisites\nSchedule\n\n\n\n\nINTR 509\nIntroduction to Applied Data Science\n3\nBS degree or permission\nSpring and asynchronous online\n\n\nBCB 551\nCommunicating with Data\n2\nINTR 509 or BS degree or permission\nFall and asynchronous online\n\n\nBCB 520\nData Visualization\n3\nSTAT 251 or INTR 509 or permission\nSpring and asynchronous online\n\n\nBCB 522\nData Science Portfolio\n1\nINTR 509 and BCB 520 (Data Viz)\nAsynchronous online\n\n\nElective\nVaries\n3\nVaries\nVaries\n\n\n\n\n\nnote: Courses designated with “BCB 5XX” are new courses that will be offered in the 2023-24 academic year\n\n\nCourse Descriptions\n\nINTR 509 Introduction to Applied Data Science (3 credits)\nIn person (spring) and asynchronous online.\nStudents are provided a foundation for “thinking with data” through the introduction of computational, statistical, and data literacy skills. This includes the selection, collection, cleaning, management, descriptive analysis, and exploratory analysis of a dataset unique to their professional interests using modern computing languages. This course is taught by Dr. Michael Overton.\n\n\nBCB 521 Communicating with Data (2 credits)\nIn person (fall) and asynchronous online.\nStudents are taught writing and presentation skills to improve their communication of data-driven insights to specialist and lay audiences. The course emphasizes reproducible research practices, including literate programming (R Markdown) and version control (GitHub). Course content includes the conceptual foundations of communicating with data along with written and verbal communication assignments using data sets individualized to each student’s interest.\nText: Nolan and Stoudt. 2021. Communicating with data: The art of writing for data science. Oxford University Press.\nPrerequisites: INTR 509 OR A BS degree OR permission.\n\n\nBCB 520 Data Visualization (3 credits)\nIn person (spring) and asynchronous online\nThis course covers the conceptual foundations of data visualization and design. Students will learn how visualization design choices related to marks and channels, color, and spatial arrangement interact with the human perceptual system. The course considers tabular, network, and spatial data, and students will implement visualizations in R.\nText: Munzner. 2014. Visualization Analysis & Design. CRC Press.\nPrerequisites: INTR 509 OR A BS degree OR Stat 251 OR Permission.\n\n\nBCB 522 Online Portfolio (1 credit)\nAsynchronous online\nThis course provides feedback, review, and approval of the student’s online data science portfolio. This portfolio is intended to represent the body of work accumulated by the student over the course of the certificate. It should contain examples of novel data products (such as FAIR data sets), analyses, and visualizations. All elements of the portfolio will be hosted online (likely in a GitHub repository or professional website), be open source, and demonstrate best practices of literate programming and reproducible research.\n\n\nElectives:\nThe certificate allows each student to customize their training by choosing a 3-credit graduate elective.\nFor students seeking foundational training who have not already taken Stat 431 or its equivalent, we recommend Stat 431 or a 3-credit graduate level disciplinary research methods course.\nFor students seeking to add the certificate to an existing degree at UI, or students who already have some advanced technical training, additional electives are possible. Note that many of these optional electives have substantial disciplinary pre-requisites. Not all electives are available in an online format.\n\n\nChoose one of the following:\n\n\n\n\n\nCourse\nName\nCredits\nPrerequisites\n\n\n\n\nAVS 531\nPractical Methods in Analyzing Animal Science Experiments\n3\n400-level statistics course\n\n\nBE 521\nImage Processing and Computer Vision\n3\n(BE 242 and MATH 275) or permission\n\n\nBE 541\nInstrumentation and Measurements\n3\nENGR 240; Coreqs: STAT 301\n\n\nBIOL 526\nSystems Biology\n3\n(BIOL 115, BIOL 115L and MATH 170) or permission of instructor\n\n\nBIOL 545\nPhylogenetics\n3\nPLSC 205 or BIOL 213 and BIOL 310\n\n\nBIOL 549\nComputer Skills for Biologists\n3\nBIOL 310 and STAT 251 or STAT 301; or Permission\n\n\nBIOL 563\nMathematical Genetics\n3\nMATH 160 or MATH 170 and STAT 251 or STAT 301\n\n\nCE 526\nAquatic Habitat Modeling\n3\nA minimum grade of ‘C’ or better is required for all pre/corequisites; Prereqs: CE 322 and CE 325 or BE 355; or Permission\n\n\nCE 579\nSimulation of Transportation Systems\n3\nPermission\n\n\nCS 511\nParallel Programming\n3\nCS 395\n\n\nCS 574\nDeep Learning\n3\n(CS 121 or MATH 330) and STAT 301\n\n\nCS 570\nArtificial Intelligence\n3\nCS 210\n\n\nCS 572\nEvolutionary Computation\n3\nCS 211\n\n\nCS 575\nMachine Learning\n3\nCS 210\n\n\nCS 577\nPython for Machine Learning\n3\n(CS 121 or MATH 330) and STAT 301\n\n\nCS 578\nNeural Network Design\n3\nPermission\n\n\nCS 579\nData Science\n3\nMATH 330 or Permission\n\n\nCS 589\nSemantic Web and Open Data\n3\nCS 360 or CS 479 or CS 579\n\n\nCTE 519\nDatabase Applications and Information Management\n3\nNA\n\n\nCYB 520\nDigital Forensics\n3\nCYB 310\n\n\nED 571\nIntroduction to Quantitative Research\n3\nGraduate standing\n\n\nED 584\nUnivariate Quantitative Research in Education\n3\nED 571\n\n\nED 587\nMultivariate Quantitative Analysis in Education\n3\nED 584 or Permission\n\n\nED 589\nTheoretical Applications and Designs of Qualitative Research\n3\nED 574 or Permission\n\n\nED 590\nData Analysis and Interpretation of Qualitative Research\n3\nED 574 and ED 589\n\n\nED 591\nIndigenous and Decolonizing Research Methods\n3\nNA\n\n\nED 592\nDecolonizing, Indigenous, and Action-Based Research Methods\n3\nNA\n\n\nED 595\nSurvey Design for Social Science Research\n3\nRecommended Preparation: Foundations of Research course at graduate level.\n\n\nEDAD 570\nMethods of Educational Research\n3\nNA\n\n\nENT 504\nApplied Bioinformatics\n3\nPermission\n\n\nENVS 511\nData Wizardry in Environmental Sciences\n3\nSTAT 251\n\n\nENVS 551\nResearch Methods in the Environmental Social Sciences\n3\nOne course or experience in basic statistics or Instructor Permission\n\n\nFOR 514\nForest Biometrics\n3\nSTAT 431 or equivalent\n\n\nFOR 535\nRemote Sensing of Fire\n3\nFOR 375 or permission\n\n\nGEOG 507\nSpatial Statistics and Modeling\n3\nSTAT 431 or permission\n\n\nGEOG 583\nRemote Sensing/GIS Integration\n3\nCoreqs: GEOG 385 or equivalent.\n\n\nMath 538\nStochastic Models\n3\nMATH 451 or Permission\n\n\nMIS 555\nData Management for Big Data\n3\nNA\n\n\nNRS 578\nLidar and optical remote sensing analysis using open-source software\n3\nSTAT251 & WLF370 or STAT427 and NRS/FOR 472 or equivalent/instructor permission\n\n\nPOLS 558\nResearch Methods for Local Government and Community Administration\n3\nSTAT 251\n\n\nREM 507\nLandscape and Habitat Dynamics\n3\nPermission; Recommended Preparation: courses in ecology, statistics, and GIS.\n\n\nStat 431\nStatistical Analysis\n3\nSTAT 251 or STAT 301\n\n\nSTAT 514\nNonparametric Statistics\n3\nSTAT 431\n\n\nSTAT 516\nApplied Regression Modeling\n3\nSTAT 431\n\n\nStat 517\nStatistical Learning and Predictive Modeling\n3\nSTAT 431\n\n\nStat 519\nMultivariate Analysis\n3\nSTAT 431 or equivalent.\n\n\nSTAT 535\nIntroduction to Bayesian Statistics\n3\nSTAT 431\n\n\nSTAT 555\nStatistical Ecology\n3\nMATH 451 or Permission\n\n\nStat 565\nComputer Intensive Methods\n3\n STAT 451, STAT 452, MATH 330, and computer programming experience or Permission\n\n\nWLF 552\nEcological Modeling\n3\nMATH 175 and FOR 221 or Permission.\n\n\nWLF 555\nStatistical Ecology\n3\nMATH 451 or permission\n\n\nWR 552\nWater Economics and Policy\n3\nAGEC 301 or AGEC 302, or ECON 351 or ECON 352, or by permission"
  },
  {
    "objectID": "BCB520/posts/Certificate/index.html#general-university-requirements",
    "href": "BCB520/posts/Certificate/index.html#general-university-requirements",
    "title": "CERTIFICATE",
    "section": "GENERAL UNIVERSITY REQUIREMENTS",
    "text": "GENERAL UNIVERSITY REQUIREMENTS\nIn addition to the requirements specified in this document, the certificate would be subject to all UI Policies regarding Graduate Certificates."
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#who-am-i",
    "href": "BCB520/posts/L1-Intro/index.html#who-am-i",
    "title": "LECTURE 1 - INTRO",
    "section": "WHO AM I?",
    "text": "WHO AM I?\nBarrie Robison\nDepartment of Biological Sciences\nInstitute for Interdisicplinary Data Sciences\nPolymorphic Games\nUniversity of Idaho"
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#who-are-you",
    "href": "BCB520/posts/L1-Intro/index.html#who-are-you",
    "title": "LECTURE 1 - INTRO",
    "section": "WHO ARE YOU?",
    "text": "WHO ARE YOU?\n“…The course is designed to be”discipline agnostic” - each student is encouraged to use data sets that they deem important / interesting. The goal is to have students learn how to develop visualizations that are relevant to their own disciplinary interests…”\nBriefly:\n\nYour name\nYour discipline\nYour degree progress\nYour technical proficiency with data visualization"
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#course-summary",
    "href": "BCB520/posts/L1-Intro/index.html#course-summary",
    "title": "LECTURE 1 - INTRO",
    "section": "COURSE SUMMARY",
    "text": "COURSE SUMMARY\nStudents completing this course will be able to:\n\n\nDescribe and manipulate tabular, network, and spatial data; transform these data into a form suitable for visualization.\nMake effective data visualization design choices related to marks and channels, spatial arrangement, and components of color.\nDesign effective data visualizations for tabular, network, and spatial data with quantitative and categorical attributes.\nImplement their data visualization designs using existing tools in R (or other toolkits preferred by the student).\nExplain whether a visual encoding is perceptually appropriate for a specific combination of task and data.\nDemonstrate their skills with at least two novel visualizations suitable suitable for inclusion in an online Data Science Portfolio.\n\nThe course materials are located on Canvas and the course website."
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#visualization",
    "href": "BCB520/posts/L1-Intro/index.html#visualization",
    "title": "LECTURE 1 - INTRO",
    "section": "VISUALIZATION",
    "text": "VISUALIZATION\nComputers provide visual representations of datasets designed to help people carry out tasks more effectively.\nTamara Munzner\nDepartment of Computer Science\nInfoVis Group\nUniversity of British Columbia"
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#the-human",
    "href": "BCB520/posts/L1-Intro/index.html#the-human",
    "title": "LECTURE 1 - INTRO",
    "section": "THE HUMAN",
    "text": "THE HUMAN\nWhy have a human in the loop?\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively.\n\nWe don’t need visualization when a trusted fully automatic solution exists.\nVisualization is suitable when there is a need to augment human capabilities rather than replace people with computational decision-making methods."
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#when-to-visualize",
    "href": "BCB520/posts/L1-Intro/index.html#when-to-visualize",
    "title": "LECTURE 1 - INTRO",
    "section": "WHEN TO VISUALIZE",
    "text": "WHEN TO VISUALIZE\nVisualization is useful when:\n\n\nThe analysis problem is ill-specified and we don’t know exactly what questions to ask in advance.\nWe are interested in long-term use for end users (ex: exploratory analysis of scientific data).\nWe are presenting known results (ex: DATA JOURNALISM - New York Times Upshot).\nWe need a stepping stone to assess requirements before developing models.\nDevelopers of an automatic solution want to refine & determine parameters.\nWe need to help end users of automatic solutions verify and build trust."
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#the-representation",
    "href": "BCB520/posts/L1-Intro/index.html#the-representation",
    "title": "LECTURE 1 - INTRO",
    "section": "THE REPRESENTATION",
    "text": "THE REPRESENTATION\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively.\nEXTERNAL REPRESENTATIONS: Replace cognition with perception."
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#why-depend-on-vision",
    "href": "BCB520/posts/L1-Intro/index.html#why-depend-on-vision",
    "title": "LECTURE 1 - INTRO",
    "section": "WHY DEPEND ON VISION?",
    "text": "WHY DEPEND ON VISION?\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively.\n\n\nThe human visual system is a high-bandwidth channel to the brain.\nOverview is possible due to background processing, providing the subjective experience of seeing everything simultaneously.\nSignificant processing occurs in parallel and pre-attentively.\nWhat about sound? lower bandwidth and different semantics, overview not supported, subjective experience of sequential stream.\nWhat about touch/haptics? impoverished record/replay capacity, only very low-bandwidth communication thus far.\nWhat about taste, smell? no viable record/replay devices."
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#why-represent-all-the-data",
    "href": "BCB520/posts/L1-Intro/index.html#why-represent-all-the-data",
    "title": "LECTURE 1 - INTRO",
    "section": "WHY REPRESENT (ALL THE) DATA?",
    "text": "WHY REPRESENT (ALL THE) DATA?\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively.\n\n\nsummaries lose information\ndetails matter\nconfirm expected and find unexpected patterns\nassess validity of statistical model\nANSCOMBE’S QUARTET is a fun example that we shall use to illustrate these points!"
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#anscombes-quartet",
    "href": "BCB520/posts/L1-Intro/index.html#anscombes-quartet",
    "title": "LECTURE 1 - INTRO",
    "section": "ANSCOMBE’S QUARTET",
    "text": "ANSCOMBE’S QUARTET\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(grid)\nlibrary(gridExtra)\nlibrary(datasets)\nlibrary(tidyverse)\nlibrary(dplyr)\ndatasets::anscombe\n\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89\n\n\n\nAnscombe’s Quartet\nThe four x-y pairs have identical summary statistics.\n\n\nCode\ntidy_anscombe &lt;- anscombe %&gt;%\n pivot_longer(cols = everything(),\n              names_to = c(\".value\", \"set\"),\n              names_pattern = \"(.)(.)\")\ntidy_anscombe_summary &lt;- tidy_anscombe %&gt;%\n  group_by(set) %&gt;%\n  summarise(across(.cols = everything(),\n                   .fns = lst(min,max,median,mean,sd,var),\n                   .names = \"{col}_{fn}\"))\n#&gt; `summarise()` ungrouping output (override with `.groups` argument)\n\nvars&lt;-c(\"set\", \"x_mean\", \"x_var\",  \"y_mean\", \"y_var\")\nthing&lt;- as.data.frame(tidy_anscombe_summary[vars])\nknitr::kable(thing)\n\n\n\n\n\nset\nx_mean\nx_var\ny_mean\ny_var\n\n\n\n\n1\n9\n11\n7.500909\n4.127269\n\n\n2\n9\n11\n7.500909\n4.127629\n\n\n3\n9\n11\n7.500000\n4.122620\n\n\n4\n9\n11\n7.500909\n4.123249"
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#viz-matters",
    "href": "BCB520/posts/L1-Intro/index.html#viz-matters",
    "title": "LECTURE 1 - INTRO",
    "section": "VIZ MATTERS",
    "text": "VIZ MATTERS\n\n\nCode\nggplot(tidy_anscombe,\n       aes(x = x,\n           y = y)) +\n  geom_point() +\n  geom_point(data = tidy_anscombe_summary, aes(x=x_mean, y = y_mean, color = \"red\", size = 5),\n             show.legend = FALSE)+\n  facet_wrap(~set) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nLearn more: TIDY ANSCOMBE"
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#resource-limitations",
    "href": "BCB520/posts/L1-Intro/index.html#resource-limitations",
    "title": "LECTURE 1 - INTRO",
    "section": "RESOURCE LIMITATIONS",
    "text": "RESOURCE LIMITATIONS\nVisualization designers must take into account three very different kinds of resource limitations:\n\nLimitations of computers.\nLimitations of humans.\nLimitations of displays."
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#computational-limits",
    "href": "BCB520/posts/L1-Intro/index.html#computational-limits",
    "title": "LECTURE 1 - INTRO",
    "section": "COMPUTATIONAL LIMITS",
    "text": "COMPUTATIONAL LIMITS\nCPU time\nSystem Memory"
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#display-limits",
    "href": "BCB520/posts/L1-Intro/index.html#display-limits",
    "title": "LECTURE 1 - INTRO",
    "section": "DISPLAY LIMITS",
    "text": "DISPLAY LIMITS\nPixels are precious and are the most constrained resource.\n\nInformation Density: ratio of space used to encode information vs unused whitespace.\nThere is a tradeoff between clutter and wasting space.\nDesigner must find the sweet spot between dense and sparse."
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#human-limits",
    "href": "BCB520/posts/L1-Intro/index.html#human-limits",
    "title": "LECTURE 1 - INTRO",
    "section": "HUMAN LIMITS",
    "text": "HUMAN LIMITS\n\nTime\nMemory\nAttention"
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#visualization-analysis-and-design",
    "href": "BCB520/posts/L1-Intro/index.html#visualization-analysis-and-design",
    "title": "LECTURE 1 - INTRO",
    "section": "VISUALIZATION ANALYSIS AND DESIGN",
    "text": "VISUALIZATION ANALYSIS AND DESIGN\nANALYSIS?\n\nimposes structure on huge design space.\nscaffold to help you think systematically about choices.\nanalyzing existing designs serves as stepping stone to designing new visualizations.\nmost possibilities in a design space are ineffective for a particular task/data combination."
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#analysis-framework",
    "href": "BCB520/posts/L1-Intro/index.html#analysis-framework",
    "title": "LECTURE 1 - INTRO",
    "section": "ANALYSIS FRAMEWORK",
    "text": "ANALYSIS FRAMEWORK"
  },
  {
    "objectID": "BCB520/posts/L1-Intro/index.html#analysis-framework-example",
    "href": "BCB520/posts/L1-Intro/index.html#analysis-framework-example",
    "title": "LECTURE 1 - INTRO",
    "section": "ANALYSIS FRAMEWORK EXAMPLE",
    "text": "ANALYSIS FRAMEWORK EXAMPLE\nTree Juxtaposer\n\n\n\n\nCANVAS…HOME"
  },
  {
    "objectID": "BCB520/posts/T3-Python/index.html",
    "href": "BCB520/posts/T3-Python/index.html",
    "title": "TUTORIAL # - PYTHON",
    "section": "",
    "text": "I relied heavily on the Quarto documentation for this tutorial.\nThe basic things I learned were:\n\nInstall Python (again). I downloaded the newest version from the Python website.\nInstall the `jupyter’ package using the terminal:\n\n\nWindows: py -m pip install jupyter\nMac: python3 -m pip install jupyter\n\n\nInstall the modules you need using the terminal (Mac examples below):\n\n\npython3 -m pip install numpy\npython3 -m pip install matplotlib\n\nAfter I did this, the code from the Quarto website example (below) seemed to work!"
  },
  {
    "objectID": "BCB520/posts/T3-Python/index.html#quarto-example-code",
    "href": "BCB520/posts/T3-Python/index.html#quarto-example-code",
    "title": "TUTORIAL # - PYTHON",
    "section": "QUARTO EXAMPLE CODE",
    "text": "QUARTO EXAMPLE CODE\nFor a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "BCB520/posts/A1-Lit-Prog/index.html",
    "href": "BCB520/posts/A1-Lit-Prog/index.html",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "",
    "text": "The idea of Literate Programming is that source code that is executed as part of the program’s purpose is interspersed with documentation that describes the program’s logic. The concept of literate programming was first articulated by David Knuth in 1984. You know… back when music was good? Modern Data Science leans pretty heavily on literate programming, and to be honest, there aren’t very many good arguments as to why you WOULDN’T want to implement this approach in your own work. Bearing this in mind, we will adopt this framework for most of the activities, exercises, and assignments in this course. All of us will benefit by practicing these skills."
  },
  {
    "objectID": "BCB520/posts/A1-Lit-Prog/index.html#literate-programming-publishing-systems",
    "href": "BCB520/posts/A1-Lit-Prog/index.html#literate-programming-publishing-systems",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "LITERATE PROGRAMMING PUBLISHING SYSTEMS",
    "text": "LITERATE PROGRAMMING PUBLISHING SYSTEMS\nI’m trying to keep this course as technology agnostic as I can. The idea is that you should be practicing and building competencies in the languages and algorithms that are most useful to you. Who am I to tell you to use R instead of Python? If you have skills in a particular language I encourage you to keep using that during this course. That being said, I am going to work the examples using R and R Studio, and I will (mostly) use Quarto as the literate programming framework.\nIf all of this is new to you, no problem. Just follow along in R and Quarto and start your skill building journey with those languages.\nIf you are a Python person, great! Quarto can accommodate that language as well. If you have another preference for literate programming, such as sticking with R Markdown until the Quarto bugs are fixed, that is great. Find the framework and tools that work for you, and practice, practice, practice!\n\nQuarto\nAn open source publishing system that allows you to create websites, documents, blogs, books, publications, presentations, and more while using R, Python, Julia, or Observable. Quarto is intended to be the more functional successor of R Markdown. I intend to use Quarto for most of my work in this course.\n\n\nR Markdown\nAnother publishing system for creating all the things … websites, slides, manuscripts, dashboards, etc. While most people (including me!) instinctively think of R and Python within R Markdown, the list of supported language engines is pretty extensive.\n\nnames(knitr::knit_engines$get())\n\n [1] \"awk\"       \"bash\"      \"coffee\"    \"gawk\"      \"groovy\"    \"haskell\"  \n [7] \"lein\"      \"mysql\"     \"node\"      \"octave\"    \"perl\"      \"php\"      \n[13] \"psql\"      \"Rscript\"   \"ruby\"      \"sas\"       \"scala\"     \"sed\"      \n[19] \"sh\"        \"stata\"     \"zsh\"       \"asis\"      \"asy\"       \"block\"    \n[25] \"block2\"    \"bslib\"     \"c\"         \"cat\"       \"cc\"        \"comment\"  \n[31] \"css\"       \"ditaa\"     \"dot\"       \"embed\"     \"eviews\"    \"exec\"     \n[37] \"fortran\"   \"fortran95\" \"go\"        \"highlight\" \"js\"        \"julia\"    \n[43] \"python\"    \"R\"         \"Rcpp\"      \"sass\"      \"scss\"      \"sql\"      \n[49] \"stan\"      \"targets\"   \"tikz\"      \"verbatim\"  \"ojs\"       \"mermaid\"  \n[55] \"include\""
  },
  {
    "objectID": "BCB520/posts/A1-Lit-Prog/index.html#languages-and-toolsets",
    "href": "BCB520/posts/A1-Lit-Prog/index.html#languages-and-toolsets",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "LANGUAGES AND TOOLSETS",
    "text": "LANGUAGES AND TOOLSETS\nThere are quite a few, but the five that seemed to keep coming up as I prepped this course are:\n\nR\nA very powerful open source framework for statistical computing and graphics. R has a lot of base functionality, and its capabilities are increased by 100 fold with packages created by R users. Packages are the core units of R code. I’m going to use R for the vast majority of demonstrations in this course.\n\n\nPython\nPython is an open source general purpose programming language. It wasn’t developed just for statistical computing or data science, and people use this language for tons of different applications. There is no denying it has become a very powerful language for data science and data visualization.\n\n\nTableau\nTableau is proprietary software that is very powerful for creating beautiful and functional data visualizations. It can integrate with all sorts of data sources and is used a lot for analytics, especially in the business world. The downsides (that occur to me at least) are that it costs money, it is not open source, and is more of a one-trick-pony than the programming languages on this list.\n\n\nJavascript\nJavascript has been around for about 25 years, and is (I think) the world’s most popular programming language. Along with HTML and CSS, Javascript drives pretty much the entire internet. I mention Javascript here because it has the D3 library, which can create super cool interactive data visualizaitons. In my experience, the learning curve with Javascript and D3 was pretty steep. I bought a book about it once, but just haven’t been able to allocate the amount of time necessary to really start using it. Check out the gallery of examples. Amazing!\n\n\nObservable / D3\nObservable is a set of extensions to Javascript that features something called reactive runtime. This means that the code blocks are executed and compiled as they are written, and changes are implemented instantaneously. Observable is pretty great for data exploration, and is well supported by Quarto. In addition, you can use the Observable JS libraries in Quarto to access D3. We’ll use some of these tools in this course, especially when we start considering interactivity."
  },
  {
    "objectID": "BCB520/posts/A1-Lit-Prog/index.html#assignment",
    "href": "BCB520/posts/A1-Lit-Prog/index.html#assignment",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nAfter that long introduction, I suppose you are wondering what I want you to actually DO today.\nWell, I want you to set up your publishing system and preferred language on your computer. Then I want you to recreate the classic figure from Anscombe’s Quartet.\nNow, you might be asking…\n“How am I supposed to do that? You haven’t taught me how to do anything yet!”\nHere is the dirty little secret of modern education.\nThe Internet Exists.\nWhile I could use up an entire 90 minute lecture telling you how to:\n\nDownload and install R, R-Studio, and Quarto (included by default with R-Studio).\nCreate a Quarto document that will publish in the .html format\nInstall the R packages you will need\nTidy up the Anscombe’s Quartet data\nCalculate the summary statistics for each x y pair\nMake a nice little plot…\n\nI’m not going to do that.\nInstead, I want you to use the resources I point towards, or other resources that make more sense to you, to figure out how to do those things."
  },
  {
    "objectID": "BCB520/posts/A1-Lit-Prog/index.html#resources",
    "href": "BCB520/posts/A1-Lit-Prog/index.html#resources",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "RESOURCES",
    "text": "RESOURCES\nTidyverse and Anscombe’s Quartet\nHandy cheat-sheets for many different R packages\nTutorial 1 - Literate Programming\nTutorial 2 - Literate Programming and Anscombe’s Quartet\nTutorial 3 - Python"
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#last-lecture",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#last-lecture",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "LAST LECTURE",
    "text": "LAST LECTURE\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#task-abstraction",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#task-abstraction",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "TASK ABSTRACTION",
    "text": "TASK ABSTRACTION\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#from-domain-to-abstraction",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#from-domain-to-abstraction",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "FROM DOMAIN TO ABSTRACTION",
    "text": "FROM DOMAIN TO ABSTRACTION"
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#key-components-of-task-abstraction",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#key-components-of-task-abstraction",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "KEY COMPONENTS OF TASK ABSTRACTION",
    "text": "KEY COMPONENTS OF TASK ABSTRACTION\n{action, target} pairs\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#actions-and-targets",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#actions-and-targets",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "ACTIONS AND TARGETS",
    "text": "ACTIONS AND TARGETS"
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#actions---analyze",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#actions---analyze",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "ACTIONS - Analyze",
    "text": "ACTIONS - Analyze\n\n\n\nConsume: Information has already been generated and stored as data.\n\nDiscover: new knowledge, test hypothesis, generate new hypothesis, verify\nPresent: communicate something specific and already understood\nEnjoy: casual encounters with visualization\n\nProduce: generate new material or information\n\nAnnotate: addition of graphical or text to existing visualization elements\nRecord: saves or captures visualization elements as persistent artifacts (screenshots, lists, parameter sets, annotations)\nDerive: produce new data based on existing data (aka transform)"
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#actions---search",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#actions---search",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "ACTIONS - Search",
    "text": "ACTIONS - Search\n\n\n\nLookup: Location and target both known\n\nExample: Look up humans in the Tree of Life, knowing they are mammals.\n\nLocate: Location unknown and target known\n\nExample: Look up rabbits in the Tree of Life, not knowing they are lagomorphs.\n\nBrowse: Location known and target unknown\n\nExample: Find any clades within Mammalia that have only one species.\n\nExplore: Location unknown and target unknown\n\nExample: Searching for anomalies in time series data."
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#actions---query",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#actions---query",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "ACTIONS - Query",
    "text": "ACTIONS - Query\n\n\n\nQuery: How much of the data matters to the task?\n\nIdentify: One (specific Item, individual, cell, etc)\nCompare: Some (multiple targets)\nSummarize: All (very common, aka Overview)"
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#targets---all-data",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#targets---all-data",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "TARGETS - All Data",
    "text": "TARGETS - All Data"
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#targets---attributes",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#targets---attributes",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "TARGETS - Attributes",
    "text": "TARGETS - Attributes"
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#targets---other-data",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#targets---other-data",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "TARGETS - Other Data",
    "text": "TARGETS - Other Data"
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#summary",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#summary",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "SUMMARY",
    "text": "SUMMARY\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#examples",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#examples",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "EXAMPLES!",
    "text": "EXAMPLES!\n\n\nCode\nlibrary(readxl)\nlibrary(vroom)\nlibrary(tidyverse)\nPerson &lt;- read_excel(\"Tasks.xlsx\", sheet = \"Person\",\n    col_names = TRUE)\nAction &lt;- read_excel(\"Tasks.xlsx\", sheet = \"Action\",\n    col_names = TRUE)\nTarget &lt;- read_excel(\"Tasks.xlsx\", sheet = \"Target\",\n    col_names = TRUE)\n\n\n\n\n\n\n\nPerson\n\n\n\n\nBarrie\n\n\nJiyin\n\n\nRonald\n\n\nCody\n\n\nEric\n\n\n\n\n\n\n\nAction\n\n\n\n\nDiscover\n\n\nPresent\n\n\nEnjoy\n\n\nAnnotate\n\n\nRecord\n\n\nDerive\n\n\nLookup\n\n\nBrowse\n\n\nLocate\n\n\nExplore\n\n\nIdentify\n\n\nCompare\n\n\nSummarize\n\n\n\n\n\n\n\nTarget\n\n\n\n\nTrends\n\n\nOutliers\n\n\nFeatures\n\n\nDistribution\n\n\nExtremes\n\n\nDependency\n\n\nCorrelation\n\n\nSimilarity\n\n\nTopology\n\n\nPaths\n\n\nShape"
  },
  {
    "objectID": "BCB520/posts/L3-TaskAbstraction/index.html#mandatory-fun",
    "href": "BCB520/posts/L3-TaskAbstraction/index.html#mandatory-fun",
    "title": "LECTURE 3 - TASK ABSTRACTION",
    "section": "MANDATORY FUN",
    "text": "MANDATORY FUN\nWe will do these until everyone has done at least one example.\nCody Derive Extremes\nRonald Enjoy Distribution\nRonald Explore Distribution\nRonald Discover Paths\nRonald Explore Paths\nRonald Summarize Correlation\nJiyin Record Trends\nJiyin Browse Trends\nEric Annotate Topology\nEric Derive Extremes\nBarrie Discover Features\nEric Lookup Outliers\nRonald Enjoy Outliers\n\n\nCANVAS…HOME"
  },
  {
    "objectID": "BCB520/posts/T1-Lit-Prog/index.html",
    "href": "BCB520/posts/T1-Lit-Prog/index.html",
    "title": "TUTORIAL 1 - Literate Programming",
    "section": "",
    "text": "Learning new tools is hard. Plowing though the tomes of the Data Science Mythos is hard. Perhaps this tutorial will guide you through the mind shattering truths of… LITERATE PROGRAMMING."
  },
  {
    "objectID": "BCB520/posts/Syllabus/index.html",
    "href": "BCB520/posts/Syllabus/index.html",
    "title": "SYLLABUS 2023",
    "section": "",
    "text": "Barrie D. Robison\nSpring 2023\n\n\nThis class will help students establish a foundational understanding of data visualization. We will consider how data type (including tabular, network, and spatial data) interacts with visualization task to guide design choices. Diverse types of visual encodings and how they relate to human perception will be presented, along with practical exercises using the R programming language. Upon completion of the course, students will understand WHY particular visualization approaches are effective for a given data set and HOW to implement those visualizations using R.  The course is designed to be “discipline agnostic” -  each student is encouraged to use data sets that they deem important / interesting.  The goal is to have students learn how to develop visualizations that are relevant to their own disciplinary interests.\n\n\n\nStudents completing this course will be able to:\n\nDescribe and manipulate tabular, network, and spatial data; transform these data into a form suitable for visualization.\nAnalyze data visualization design choices related to marks and channels, spatial arrangement, and components of color.\nDesign new data visualizations with appropriate use of visual channels for tabular, network, and spatial data with quantitative and categorical attributes.\nImplement their data visualization designs using existing tools in R (or other toolkits preferred by the student).\nExplain whether a visual encoding is perceptually appropriate for a specific combination of task and data.\nDemonstrate their skills with at least two novel visualizations suitable for inclusion in an online Data Science Portfolio.\n\n\n\n\nTamara Munzner. Visualization Analysis and Design. A K Peters Visualization Series, CRC Press, 2014. For the 2023 version of the class, I am trying out the Inclusive Access option. Erolled students should have access to the text on the course canvas page.\nHard Copy on Amazon\nkindle/ebook on Amazon\n\n\n\n\n\n50% of your grade will be determined by homework exercises related to each course unit.\n20% of your grade will be determined by a mid term project (which would be a great item to include in your Data Science Portfolio).\n20% of your grade will be determined by a final project (which would be great item to include in your Data Science Portfolio).\n10% of your grade will be determined by participation in class discussions.\nGRADING SCALE: The grading scale is standard: A (90 -100 %), B (89 - 80 %), C (79 - 70 %), D (69-60 %), F( below 60 %).\n\n\n\nIt is a longstanding tradition that Vandals take care of Vandals, and we all do our best to look out for the Vandal Family. These simple precautions go a long way in reducing the impact of coronavirus on our campuses and in our communities. With everyone engaging in these small actions, we can continue to participate in our vibrant campus culture where we are able to learn, live, and grow. Please bookmark the University of Idaho Covid-19 webpage and visit it often for the most up-to-date information about the U of I’s response to Covid-19.\n\nAll classes are offered in the modality listed in the catalog.\nAll Vandals are highly encouraged to be vaccinated.\nCOVID-19 tests are not required to attend class in person.\n\nAdditionally, faculty and students must follow the Healthy Vandal Pledge: Daily Symptom Monitoring and In-Person Class Attendance. Evaluate your own health status before attending in-person classes and refrain from attending class in-person if you are ill, if you are experiencing any of the known symptoms of Coronavirus, or if you have tested positive for COVID-19 or have been potentially exposed to someone with COVID-19. Stay home if you experience any symptoms related to COVID 19 and that are not attributed to a non-infectious health condition regardless of how mild. Contact your medical provider or local Idaho Public Health District for assessment of symptoms and possible COVID19 testing. Positive COVID 19 tests should be submitted via a VandalCare Report in order to make arrangements that involve classroom absences due to illness, and/or quarantine or isolation requirements directed by a medical provider.\n\n\n\nMissing a scheduled lecture is at your discretion. I will be posting all the lecture notes online, and recording the lectures for future online versions of the course. I have no intention of offering a zoom option this semester. If a discussion or in-class exercise occurs and you miss it, you will lose those participation points. There is no way to make up those points.\n\n\n\nThe R Markdown template I used for this syllabus was created by Dr. Steven V. Miller at Stockholm University. It contained this section, which I found amusing and have therefore retained. Professor Miller’s current university asks professors to have policies written into their syllabus about what students should do if the professor is more than 15 minutes late to class. Here is my version of that policy:\nI will inform students via e-mail in advance of class if class is cancelled for the day. Events that might create such a scenario include travel obligations that emerged after the semester has begun, a family emergency that encompasses multiple days, or some other thing. I will also contact our department secretary in emergent situations, such as something happening on the way to work. Failing that, assume the worst. Alien abduction, the return of one or more Old Ones to our plane, or some kind of attack by wizards are all viable explanations for my inability to attend class. I ask that the students make sure that my story gets the proper treatment on the “Mr. Ballen” YouTube channel. I also ask that my story be narrated by Morgan Freeman and that the role of me in the made for TV movie be played by Keanu Reeves or Danny DeVito.\n\n\n\nThe bad news is that there are NO make-ups for missed exams. Don’t bother asking. The good news is that there aren’t any exams.\n\n\n\nAll students are expected to uphold the highest standards of academic honesty. This includes but is not limited to: not cheating, not using the ideas of others without giving appropriate credit (including Wikipedia!), and not falsifying data. Any incident of academic dishonesty will be handled according to the guidelines of the University of Idaho. \n\n\n\n\n\nlibrary(readxl)\nSchedule &lt;- read_excel(\"Schedule.xlsx\")\n\nknitr::kable(Schedule, caption = '')\n\n\n\n\nDATE\nTOPIC\nREADING\nRECEIVE\nTURN IN\n\n\n\n\n2023-01-12\nINTRODUCTION.  Why Visualization Matters\nVAD Ch 1.\nAssignment 1 - Fun with literate programming.\nNA\n\n\n2023-01-17\nWHAT?  Abstraction of Data\nVAD Ch 2.\nNA\nAssignment 1 - Fun with literate programming.\n\n\n2023-01-19\nWorking Session\nNA\nAssignment 2 - You’ll need some data…\nNA\n\n\n2023-01-24\nWorking Session\nNA\nNA\nAssignment 2 - You’ll need some data…\n\n\n2023-01-26\nWHY?  Task Abstraction\nVAD Ch 3.\nAssignment 3 - Data Science Portfolio\nNA\n\n\n2023-01-31\nWorking Session\nNA\nNA\nNA\n\n\n2023-02-02\nWorking Session\nNA\nNA\nNA\n\n\n2023-02-07\nPortfolio Review - Action/Target Pairs\nNA\nNA\nAssignment 3 - Data Science Portfolio\n\n\n2023-02-09\nMARKS. Geometric elements to depict data\nVAD Ch 5.\nNA\nNA\n\n\n2023-02-14\nNA\nNA\nNA\nNA\n\n\n2023-02-16\nNA\nNA\nNA\nMidterm Assignment Presentations\n\n\n2023-02-21\nNA\nNA\nNA\nMidterm Assignment Presentations\n\n\n2023-02-23\nCHANNELS. Controlling the appearance of marks.\nVAD Ch 5.\nAssignment 6 - Spatial things\nNA\n\n\n2023-02-28\nRULES OF THUMB.\nVAD Ch. 6.\nNA\nNA\n\n\n2023-03-02\nTABULAR DATA I\nVAD Ch. 7.\nAssignment 7 - Network things\nNA\n\n\n2023-03-07\nTABULAR DATA II\nVAD Ch. 7.\nNA\nNA\n\n\n2023-03-09\nSPATIAL DATA I: Geographic Maps\nVAD Ch 8.\nAssignment 8 - Find some stuff for critique\nNA\n\n\n2023-03-14\nNo Class\nNA\nNA\nSPRING BREAK\n\n\n2023-03-16\nNo Class\nNA\nNA\nSPRING BREAK\n\n\n2023-03-21\nBarrie in NV\nNA\nNA\nNA\n\n\n2023-03-23\nSPATIAL DATA II:  Spatial Fields\nVAD Ch 8.\nAssignment 9 - Let’s practice Observable!\nNA\n\n\n2023-03-28\nNETWORK DATA I\nVAD Ch 9.\nNA\nNA\n\n\n2023-03-30\nNETWORK DATA II\nVAD Ch 9.\nAssignment 10 - Cool interactive stuff\nNA\n\n\n2023-04-04\nCOLOR I\nVAD Ch 10.\nNA\nNA\n\n\n2023-04-06\nCOLOR II\nVAD Ch 10.\nAssignment 11 - Data Science Competition\nNA\n\n\n2023-04-11\nCOLOR III\nVAD Ch 10.\nNA\nNA\n\n\n2023-04-13\nINTERACTIVITY\nVAD Ch 11.\nNA\nNA\n\n\n2023-04-18\nMULTIPLE VIEWS\nVAD Ch 12.\nNA\nNA\n\n\n2023-04-20\nAGGREGATION\nVAD Ch 13.\nNA\nNA\n\n\n2023-04-25\nFILTERING\nVAD Ch 13.\nNA\nFINAL PROJECT PRESENTATIONS\n\n\n2023-04-27\nEMBEDDING: Focus and Context\nVAD Ch 14.\nNA\nFINAL PROJECT PRESENTATIONS\n\n\n2023-05-02\nDEAD WEEK\nNA\nPortfolio Review\nNA\n\n\n2023-05-04\nDEAD WEEK\nNA\nPortfolio Review\nNA\n\n\n2023-05-09\nFINALS WEEK\nNA\nNA\nNA"
  },
  {
    "objectID": "BCB520/posts/A3-PrototypeVizPortfolio/index.html",
    "href": "BCB520/posts/A3-PrototypeVizPortfolio/index.html",
    "title": "ASSIGNMENT 3",
    "section": "",
    "text": "Enough with the theory and conceptual mumbo jumbo! Let’s get down to making a visualization and posting it somewhere for all the world to see! The basic idea of this assignment is to set up a repository that will serve as an experimental portfolio, and then create your first novel visualization element inside the portfolio. Its gonna be fun! Or at least educational…"
  },
  {
    "objectID": "BCB520/posts/A3-PrototypeVizPortfolio/index.html#assignment",
    "href": "BCB520/posts/A3-PrototypeVizPortfolio/index.html#assignment",
    "title": "ASSIGNMENT 3",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nThis assignment has two parts. The first part is technical. We’ll set up a Quarto Blog project as a new repository in your GitHub account. Then you’ll be a Blogger! Prestigious! The second part should be more fun. We are going to create your first Blog post as a visualization that explores an ACTION - TARGET pair relevant to your data set from Assignment 2."
  },
  {
    "objectID": "BCB520/posts/A3-PrototypeVizPortfolio/index.html#part-1-technical-sorcery",
    "href": "BCB520/posts/A3-PrototypeVizPortfolio/index.html#part-1-technical-sorcery",
    "title": "ASSIGNMENT 3",
    "section": "PART 1 TECHNICAL SORCERY",
    "text": "PART 1 TECHNICAL SORCERY\n\n1A - Create your BLOG project.\nHopefully by now you have created / dusted off / logged in to your GitHub account. Go ahead and log in to your account on the web and leave it open in a tab in your browser. There is a really great video about the next few steps (also linked below in RESORUCES) from Posit, but I’m giving you the condensed version here.\n\nFire up RStudio.\nGo to File-&gt;New Project and then select NEW DIRECTORY.\nNow select QUARTO BLOG.\nYou are going to create a the project in a new working directory. It is best practice to put this in a senstible directory structure on your local hard drive where your other GitHub repositories also live. Here is what mine looks like:\n\n 4. I suggest making the directory name something informative, like BCB504Portfolio, but hey… If you want to call your repository HasturBoxerShorts I won’t stop you. 5. Most of you will select Knitr as your Engine, but Cody “Mr. Hacker McPythonPants” might select Jupyter. 6. Check Create a git repository. The other boxes are optional and we can talk more about them later. 7. Click CREATE PROJECT.\nNow you’ve got a BLOG template all set up! Ha Ha! Onward to Internet Fame!\n\n\n1B - Make the BLOG about you.\nWe won’t spend a ton of time here, because this will be an ongoing process. You’ll go and watch all those cool videos and tutorials this weekend to figure this out. But lets do a couple things.\n\nMaybe you should modify the about.qmd file so that your name is in there somewhere.\nMaybe you should modify the index.qmd file with a better title in the YAML header.\nMaybe you should navigate to the posts folder, open the Welcome to my blog folder, open index.qmd from that directory, and add a sentence or two.\n\n\n\n1C - Customize your first post.\n\nNavigate to the posts folder, open the post with code folder, and open index.qmd.\nReplace ALL of the content of index.qmd with the most recent version of your .qmd file from ASSIGNMENT 2. Keep the file name index.qmd. Save that file!\nMove your data files to the post with code folder.\nRender the index.qmd file from this folder. Hopefully it worked!\n\n\n\n1D - Render the BLOG as a website.\n\nIMPORTANT Open your _quarto.yml file and add output-dir: docs under project:\n\n\nThe indentations matter here.\n\nSave all the files you’ve modified.\nGo to the BUILD tab in the (probably) top right section of RStudio.\nClick RENDER WEBSITE.\nClick through your new Blog and see how it works!\n\n\n\n1E - Push to GitHub.\nThere are quite a few ways to do this part. I’m going to use GitHub Desktop, but those video will show you other ways.\n\nGo to GitHub Desktop.\nType some text in the summary box.\nClick COMMIT TO MASTER.\nClick PUSH ORIGIN.\nGo to your GitHub in your browser. You should see your new repository! Yay!\n\n\n\n1F - Make it a website with GitHub pages.\n\nIn your browser, click on your repository.\nGo to SETTINGS.\nSelect PAGES.\nSet the SOURCE option to Deploy from a branch.\nSet the BRANCH to master and the directory to docs\nDeploy that stuff and wait. Then visit your site!"
  },
  {
    "objectID": "BCB520/posts/A3-PrototypeVizPortfolio/index.html#part-2-eldritch-visualization-ritual",
    "href": "BCB520/posts/A3-PrototypeVizPortfolio/index.html#part-2-eldritch-visualization-ritual",
    "title": "ASSIGNMENT 3",
    "section": "PART 2 ELDRITCH VISUALIZATION RITUAL",
    "text": "PART 2 ELDRITCH VISUALIZATION RITUAL\n\n2A Define your ACTION - TARGET pair(s)\nIn [LECTURE 3] we discussed the concept of Task Abstraction in which you define the viz task that you want to help the user accomplish. This was represented as sets of ACTIONS that the user would perform (e.g. Discover, Present, Browse, Identify) on TARGETS related to the data set (e.g. Trends, Attributes, etc.).\nThink about one or two visualizations you wish to construct with your data, and try to define them in terms of ACTION - TARGET pairs. While you are at it, why don’t you update the index.qmd file of your BLOG POST with a new seciton at the bottom titled TASK ABSTRACTION, and put a sentence describing your visualizations and the ACTION - TARGET pairs they represent?\n\n\n2B Construct your Visualization\nLet’s get to work! Using whatever tools you can, code up your visualization in that new section of your BLOG post. You can check out how I approached this part in TUTORIAL 4."
  },
  {
    "objectID": "BCB520/posts/A3-PrototypeVizPortfolio/index.html#resources",
    "href": "BCB520/posts/A3-PrototypeVizPortfolio/index.html#resources",
    "title": "ASSIGNMENT 3",
    "section": "RESOURCES",
    "text": "RESOURCES\nA YouTube Video from Posit on Building your Data Science Portfolio\nTidyTuesday\nA fun Spotify example from TidyTuesday by Kaylin Pavlik.\nQuarto’s BLOG Documentation\nA YouTube Video from Posit on Building a BLOG with Quarto"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#the-three-major-data-types",
    "href": "BCB520/posts/L6-TabularData1/index.html#the-three-major-data-types",
    "title": "LECTURE 6 - Tabular Data",
    "section": "THE THREE MAJOR DATA TYPES",
    "text": "THE THREE MAJOR DATA TYPES"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#what",
    "href": "BCB520/posts/L6-TabularData1/index.html#what",
    "title": "LECTURE 6 - Tabular Data",
    "section": "WHAT?",
    "text": "WHAT?\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#semantics-for-data",
    "href": "BCB520/posts/L6-TabularData1/index.html#semantics-for-data",
    "title": "LECTURE 6 - Tabular Data",
    "section": "SEMANTICS FOR DATA",
    "text": "SEMANTICS FOR DATA\n\n\n\nSemantics\n\nitem: individual entity, discrete\n\neg patient, car, stock, city\n“independent variable”\n\nattribute: property that is measured, observed, logged…\n\neg height, blood pressure for patient\neg horsepower, make for car\n“dependent variable”\n\n\n\n\nData Table\n\n\n\n\nITEM: Person\nATTRIBUTES: Name, Age, Shirt Size, Favorite Fruit"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#dataset-types-tables",
    "href": "BCB520/posts/L6-TabularData1/index.html#dataset-types-tables",
    "title": "LECTURE 6 - Tabular Data",
    "section": "DATASET TYPES: TABLES",
    "text": "DATASET TYPES: TABLES\nFlat Table\n\n\n\nOne ITEM per row\n\noften called an observation\n\nEach column is an ATTRIBUTE\n\noften called a variable\n\nA cell holds the VALUE for an item/attribute pair\nA unique KEY can be used (implicitly or explicitly) to identify each item even if they share all measured attributes"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#flat-table-example",
    "href": "BCB520/posts/L6-TabularData1/index.html#flat-table-example",
    "title": "LECTURE 6 - Tabular Data",
    "section": "FLAT TABLE EXAMPLE",
    "text": "FLAT TABLE EXAMPLE\n\n\n\n\n\n\n\nA dumb spreadsheet\n\n\n\n\n\n\n\nA cool spreadsheet\n\n\n\n\nFigure 1: Flat Tables"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#multidimensional-tables",
    "href": "BCB520/posts/L6-TabularData1/index.html#multidimensional-tables",
    "title": "LECTURE 6 - Tabular Data",
    "section": "MULTIDIMENSIONAL TABLES",
    "text": "MULTIDIMENSIONAL TABLES\nIndexing based on multiple keys (eg genes, patients)"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#keys-and-values",
    "href": "BCB520/posts/L6-TabularData1/index.html#keys-and-values",
    "title": "LECTURE 6 - Tabular Data",
    "section": "KEYS AND VALUES",
    "text": "KEYS AND VALUES\n\n\nKEY: an independent attribute used as unique index to look up items.\n\nSimple tables: 1 key\nMultidimensional tables: multiple keys\n\nValue: a dependent attribute, value of cell\nWe will classify visualization idioms by the number of keys used.\n0, 1, 2, …"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#framework",
    "href": "BCB520/posts/L6-TabularData1/index.html#framework",
    "title": "LECTURE 6 - Tabular Data",
    "section": "FRAMEWORK",
    "text": "FRAMEWORK"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#idiom-scatterplot",
    "href": "BCB520/posts/L6-TabularData1/index.html#idiom-scatterplot",
    "title": "LECTURE 6 - Tabular Data",
    "section": "IDIOM: Scatterplot",
    "text": "IDIOM: Scatterplot\n0 KEYS: Only values are available or salient to the task.\n\n\nExpress values (magnitudes) of quantitative attributes.\nData: 2 quantitative attributes\nMark: points\nChannels: horizontal and verical position\nTasks: find trends, outliers, distribution, correlation, clusters\nScalability: hundreds of items\n\n\n\n\n\n\nHeight and Weight of drafted NHL players."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#idiom-scatterplot-1",
    "href": "BCB520/posts/L6-TabularData1/index.html#idiom-scatterplot-1",
    "title": "LECTURE 6 - Tabular Data",
    "section": "IDIOM: Scatterplot",
    "text": "IDIOM: Scatterplot\n0 KEYS: Only values are available or salient to the task.\n\n\nExpress values (magnitudes) of quantitative attributes.\nData: 2 quantitative attributes\nMark: points\nChannels: horizontal and verical position\nTasks: find trends, outliers, distribution, correlation, clusters\nScalability: hundreds of items\n\n\n\n\n\n\nHeight and Weight of drafted NHL players."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#scatterplots-more-channels",
    "href": "BCB520/posts/L6-TabularData1/index.html#scatterplots-more-channels",
    "title": "LECTURE 6 - Tabular Data",
    "section": "SCATTERPLOTS: More channels",
    "text": "SCATTERPLOTS: More channels\nAdditional channels are viable with scatterplots since we are using point marks.\n\n\nExamples:\nColor: But pay attention to Discriminability!\nSize: But pay attention to using a quantitative attribute used to control 2D area. Directly encoding radius would mislead. Take the square root since area grows quadratically.\nShape:\n\n\n\n\n\n\nHeight and Weight of drafted NHL goaltenders."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#scatterplot-tasks",
    "href": "BCB520/posts/L6-TabularData1/index.html#scatterplot-tasks",
    "title": "LECTURE 6 - Tabular Data",
    "section": "SCATTERPLOT TASKS",
    "text": "SCATTERPLOT TASKS\nCorrelation\n\nClusters/groups, and clusters vs classes"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#keys-categorical-regions",
    "href": "BCB520/posts/L6-TabularData1/index.html#keys-categorical-regions",
    "title": "LECTURE 6 - Tabular Data",
    "section": "KEYS: Categorical Regions",
    "text": "KEYS: Categorical Regions\n\n\n\nRegions: contiguous bounded areas distinct from each other\n\nNO OVERPLOTTING: separate into spatial regions: one mark per region (for now)\n\nuse categorical or ordered attribute to separate into regions\n\nno conflict with expressiveness principle for categorical attributes\n\nuse ordered attribute to order and align regions"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#separated-and-aligned-and-ordered",
    "href": "BCB520/posts/L6-TabularData1/index.html#separated-and-aligned-and-ordered",
    "title": "LECTURE 6 - Tabular Data",
    "section": "Separated and aligned and ordered",
    "text": "Separated and aligned and ordered\nBest case!"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#separatedaligned---not-ordered",
    "href": "BCB520/posts/L6-TabularData1/index.html#separatedaligned---not-ordered",
    "title": "LECTURE 6 - Tabular Data",
    "section": "Separated/aligned - not ordered",
    "text": "Separated/aligned - not ordered\nLimitation: hard to know rank. what’s 4th? what’s 7th?"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#separated-but-not-aligned-or-ordered",
    "href": "BCB520/posts/L6-TabularData1/index.html#separated-but-not-aligned-or-ordered",
    "title": "LECTURE 6 - Tabular Data",
    "section": "Separated but not aligned or ordered",
    "text": "Separated but not aligned or ordered\nLimitation: hard to make comparisons with size (vs aligned position)"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#idiom-bar-chart",
    "href": "BCB520/posts/L6-TabularData1/index.html#idiom-bar-chart",
    "title": "LECTURE 6 - Tabular Data",
    "section": "IDIOM: Bar Chart",
    "text": "IDIOM: Bar Chart\nOne key, One value\n\n\nData: 1 categorical attribute, 1 quantitative attribute\nMark: Lines\nChannels: Length to express quantitative value\nSpatial regions: one per mark - separated horizontally, aligned vertically. Ordered by quantitative attribute: by label (alphabetical), by length attribute (data-driven)\nTasks: compare, lookup values\nScalability: dozens to hundreds of levels for key attribute (bars), hundreds for values."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#idiom-stacked-bar-chart",
    "href": "BCB520/posts/L6-TabularData1/index.html#idiom-stacked-bar-chart",
    "title": "LECTURE 6 - Tabular Data",
    "section": "IDIOM: Stacked Bar Chart",
    "text": "IDIOM: Stacked Bar Chart\nTwo keys, One value\n\n\nData: 2 categorical attribute, 1 quantitative attribute\nMark: vertical stack of line marks\nGlyph: composite object, internal structure from multiple marks\nChannels: length and color hue\nSpatial regions: one per glyph\nAligned: full glyph, lowest bar component\nUnaligned: other bar components\nTask: part-to-whole relationship\nScalability: asymmetric for stacked key attrib, 10-12 levels segments for main key attrib, dozens to hundreds of levels bars"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#idiom-streamgraph",
    "href": "BCB520/posts/L6-TabularData1/index.html#idiom-streamgraph",
    "title": "LECTURE 6 - Tabular Data",
    "section": "IDIOM: Streamgraph",
    "text": "IDIOM: Streamgraph\nGeneralized stacked graph emphasizing horizontal continuity vs vertical items (example)\n\n\nData: 1 categ key attrib (movies) 1 ordered key attrib (time) 1 quant value attrib (counts) derived data geometry: layers, where height encodes counts 1 quant attrib (layer ordering)\nMark: vertical stack of line marks\nChannels: length and color hue\nTask: part-to-whole relationship\nScalability: hundreds of time keys dozens to hundreds of movies keys more than stacked bars: most layers don’t extend across whole chart"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#idiom-dotline-chart",
    "href": "BCB520/posts/L6-TabularData1/index.html#idiom-dotline-chart",
    "title": "LECTURE 6 - Tabular Data",
    "section": "IDIOM: Dot/Line Chart",
    "text": "IDIOM: Dot/Line Chart\nOne key, One value\n\n\nData:2 quant attribs\nMark: points AND line connection marks between them\nChannels: aligned lengths to express quant value separated and ordered by key attrib into horizontal regions\nTask: find trend connection marks emphasize ordering of items along key axis by explicitly showing relationship between one item and the next\nScalability: hhundreds of key levels, hundreds of value levels"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#bar-vs-line-charts",
    "href": "BCB520/posts/L6-TabularData1/index.html#bar-vs-line-charts",
    "title": "LECTURE 6 - Tabular Data",
    "section": "BAR vs LINE CHARTS",
    "text": "BAR vs LINE CHARTS\nChoice depends on the type of key attributes.\nBar charts if categorical, Line charts if ordered. Do not use line charts for categorical key attributes as it violates the expressiveness principle. The implication of trend is so strong that it overrides semantics. “The more male a person is, the taller he/she is”"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#chart-axes",
    "href": "BCB520/posts/L6-TabularData1/index.html#chart-axes",
    "title": "LECTURE 6 - Tabular Data",
    "section": "CHART AXES",
    "text": "CHART AXES\n\n\nBest practice to label axes, with few exceptions. Individual small multiple views could share axis label.\nInclude 0 at bottom left or the slope misleads. There are some exceptions (arbitrary 0, small change matters).\nTruncating the Y-Axis: Threat or Menace? Correll, Bertini, & Franconeri, CHI 2020."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#idiom-indexed-line-charts",
    "href": "BCB520/posts/L6-TabularData1/index.html#idiom-indexed-line-charts",
    "title": "LECTURE 6 - Tabular Data",
    "section": "IDIOM: Indexed Line Charts",
    "text": "IDIOM: Indexed Line Charts\n\n\nData: 2 quant attribs 1 key + 1 value\nDerived data: new quant value attrib index plot instead of original value\nTask: show change over time\nPrinciple: normalized, not absolute\nScalability: same as standard line chart\n\n\nCool Example"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#idiom-gantt-charts",
    "href": "BCB520/posts/L6-TabularData1/index.html#idiom-gantt-charts",
    "title": "LECTURE 6 - Tabular Data",
    "section": "IDIOM: Gantt Charts",
    "text": "IDIOM: Gantt Charts\none key, two (related) values\n\n\nData: 1 categ attrib, 2 quant attribs\nMark: line length: duration\nChannels: horiz position: start time (+end from duration)\nTask: mphasize temporal overlaps & start/end dependencies between items\nScalability: dozens of key levels bars hundreds of value levels durations"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#idiom-slopegraphs",
    "href": "BCB520/posts/L6-TabularData1/index.html#idiom-slopegraphs",
    "title": "LECTURE 6 - Tabular Data",
    "section": "IDIOM: Slopegraphs",
    "text": "IDIOM: Slopegraphs\ntwo values\n\n\nData: 2 quant value attribs (1 derived attrib: change magnitude)\nMark: point + line line connecting mark between pts\nChannels: 2 vertical pos: express attrib value (linewidth/size, color)\nTask: emphasize changes in rank/value\nScalability: hundreds of value levels dozens of item"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#keys",
    "href": "BCB520/posts/L6-TabularData1/index.html#keys",
    "title": "LECTURE 6 - Tabular Data",
    "section": "2 KEYS",
    "text": "2 KEYS"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#idiom-heatmap",
    "href": "BCB520/posts/L6-TabularData1/index.html#idiom-heatmap",
    "title": "LECTURE 6 - Tabular Data",
    "section": "IDIOM: Heatmap",
    "text": "IDIOM: Heatmap\ntwo keys, one value\n\n\nData: 2 categ attribs (gene, experimental condition) 1 quant attrib (expression levels)\nMark: point separate and align in 2D matrix indexed by 2 categorical attributes\nChannels: color by quant attrib (ordered diverging colormap)\nTask: find clusters, outliers\nScalability: 1M items, 100s of categ levels, ~10 quant attrib levels"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#heatmap-reordering",
    "href": "BCB520/posts/L6-TabularData1/index.html#heatmap-reordering",
    "title": "LECTURE 6 - Tabular Data",
    "section": "HEATMAP REORDERING",
    "text": "HEATMAP REORDERING"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#clustered-heatmap",
    "href": "BCB520/posts/L6-TabularData1/index.html#clustered-heatmap",
    "title": "LECTURE 6 - Tabular Data",
    "section": "CLUSTERED HEATMAP",
    "text": "CLUSTERED HEATMAP\nUse derived data: compute 2 cluster hierarchies and represent as a dendrogram. Parent-child relationships represented in tree with connection line marks, leaves aligned so interior branch heights are easy to compare. Heatmap marks are (re-)ordered by cluster hierarchy traversal. Task: assess quality of clusters found by automatic methods"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#axis-orientation",
    "href": "BCB520/posts/L6-TabularData1/index.html#axis-orientation",
    "title": "LECTURE 6 - Tabular Data",
    "section": "AXIS ORIENTATION",
    "text": "AXIS ORIENTATION"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#discuss",
    "href": "BCB520/posts/L6-TabularData1/index.html#discuss",
    "title": "LECTURE 6 - Tabular Data",
    "section": "DISCUSS",
    "text": "DISCUSS"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#radial-bar-chart",
    "href": "BCB520/posts/L6-TabularData1/index.html#radial-bar-chart",
    "title": "LECTURE 6 - Tabular Data",
    "section": "RADIAL BAR CHART",
    "text": "RADIAL BAR CHART\n\n\n\n\nStar plot: line mark, radial axes meet at central point\nRadial bar chart: line mark, radial axes meet at central ring\nChannels: length, angle/orientation\nBar chart: rectilinear axes, aligned vertically\nAccuracy: length not aligned with radial layouts, making them less accurately perceived than rectilinear aligned layouts.\nVismon: Facilitating Risk Assessment and Decision Making In Fisheries Management. Booshehrian, Möller, Peterman, and Munzner. Technical Report TR 2011-04, Simon Fraser University, School of Computing Science, 2011."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#radar-plot",
    "href": "BCB520/posts/L6-TabularData1/index.html#radar-plot",
    "title": "LECTURE 6 - Tabular Data",
    "section": "RADAR PLOT",
    "text": "RADAR PLOT\nRadial line chart with point marks, radial layout, and connecting line marks. Avoid unless data are cyclic."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#radar-plot-example",
    "href": "BCB520/posts/L6-TabularData1/index.html#radar-plot-example",
    "title": "LECTURE 6 - Tabular Data",
    "section": "RADAR PLOT EXAMPLE",
    "text": "RADAR PLOT EXAMPLE\n\nTheFunctionalArt"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#pie-and-coxcomb-charts",
    "href": "BCB520/posts/L6-TabularData1/index.html#pie-and-coxcomb-charts",
    "title": "LECTURE 6 - Tabular Data",
    "section": "PIE AND COXCOMB CHARTS",
    "text": "PIE AND COXCOMB CHARTS\n1 categorical key attribute, 1 quantitative value attribute\n\n\nPie chart: interlocking area marks with angle channel causes variation in 2D area. Keys are separated & ordered radially with uniform height. accuracy: area less accurate than rectilinear aligned line length.\nTask: part-to-whole judgements.\nCoxcomb chart: line marks with length channel, creating variation in only 1D length. Keys are separated & ordered radially with uniform width. These charts are a direct analog to radial bar charts."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#nightengale-rose",
    "href": "BCB520/posts/L6-TabularData1/index.html#nightengale-rose",
    "title": "LECTURE 6 - Tabular Data",
    "section": "NIGHTENGALE ROSE",
    "text": "NIGHTENGALE ROSE\nCoxcomb / Nightengale Rose/ Polar Area Chart Invented by Florence Nightingale."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#coxcomb-perception",
    "href": "BCB520/posts/L6-TabularData1/index.html#coxcomb-perception",
    "title": "LECTURE 6 - Tabular Data",
    "section": "COXCOMB: Perception",
    "text": "COXCOMB: Perception\n\n\nEncode: 1D length\nDecode/perceive: 2D area\nThe nonuniform relationship between line/sector width and mark length causes area variation to scale nonlinearly with line mark length!\nA standard bar chart is safer: bars are uniform width, so area is linear with line mark length in both radial & rectilinear cases."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#pie-charts-perception",
    "href": "BCB520/posts/L6-TabularData1/index.html#pie-charts-perception",
    "title": "LECTURE 6 - Tabular Data",
    "section": "PIE CHARTS: Perception",
    "text": "PIE CHARTS: Perception\n\n\nSome empirical evidence that people respond to arc length.\nDecode/perceive: arc length, maybe also areas, but not angles.\nDonut charts are no worse than pie charts.\n\n\n\n\nArcs, Angles, or Areas: Individual Data Encodings in Pie and Donut Charts. Skau and Kosara. Proc. EuroVis 2016\nExplore this concept"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#pie-charts-best-practices",
    "href": "BCB520/posts/L6-TabularData1/index.html#pie-charts-best-practices",
    "title": "LECTURE 6 - Tabular Data",
    "section": "PIE CHARTS: Best Practices",
    "text": "PIE CHARTS: Best Practices\nNot so bad for two (or few) levels and part-to-whole tasks. Dubious for several levels if details matter. Terrible for many levels."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#normalized-stacked-bar",
    "href": "BCB520/posts/L6-TabularData1/index.html#normalized-stacked-bar",
    "title": "LECTURE 6 - Tabular Data",
    "section": "NORMALIZED STACKED BAR",
    "text": "NORMALIZED STACKED BAR\n\n\nTask: part-to-whole judgements\nNormalized stacked bar chart: stacked bar chart, normalized to full vertical height. A single stacked bar is equivalent to a full pie chart.\nHigh information density can be achieved with narrow rectangles. Pie chart information density is much more limited and requires a large circle."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#glyphmaps",
    "href": "BCB520/posts/L6-TabularData1/index.html#glyphmaps",
    "title": "LECTURE 6 - Tabular Data",
    "section": "GLYPHMAPS",
    "text": "GLYPHMAPS\nRectilinear glyphs are good for linear vs nonlinear trends. Radial glyphs are good for cyclic patterns and evaluating periodicity.\n\nGlyph-maps for Visually Exploring Temporal Patterns in Climate Data and Models. Wickham, Hofmann, Wickham, and Cook. Environmetrics 23:5 (2012), 382–393."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#parallel-axes",
    "href": "BCB520/posts/L6-TabularData1/index.html#parallel-axes",
    "title": "LECTURE 6 - Tabular Data",
    "section": "PARALLEL AXES",
    "text": "PARALLEL AXES"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#splom",
    "href": "BCB520/posts/L6-TabularData1/index.html#splom",
    "title": "LECTURE 6 - Tabular Data",
    "section": "SPLOM",
    "text": "SPLOM\n\n\nScatterplot matrix (SPLOM): Rectilinear axes with point mark. All possible pairs of axes are visualized.\nScalability: about a dozen attributes and dozens to hundreds of items."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#parallel-coordinates",
    "href": "BCB520/posts/L6-TabularData1/index.html#parallel-coordinates",
    "title": "LECTURE 6 - Tabular Data",
    "section": "PARALLEL COORDINATES",
    "text": "PARALLEL COORDINATES\nScatterplot limitation: visual representation with orthogonal axes can show only two attributes with spatial position channel."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#parallel-coordinates-1",
    "href": "BCB520/posts/L6-TabularData1/index.html#parallel-coordinates-1",
    "title": "LECTURE 6 - Tabular Data",
    "section": "PARALLEL COORDINATES",
    "text": "PARALLEL COORDINATES\n\n\nAlternative: Line up axes in parallel to show many attributes with position. Items are encoded with a line with n segments (n is the number of attributes shown). Ordering is a major challenge.\nScalability: dozens of attributes and hundreds of items."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#parallel-coordinates-limitations",
    "href": "BCB520/posts/L6-TabularData1/index.html#parallel-coordinates-limitations",
    "title": "LECTURE 6 - Tabular Data",
    "section": "PARALLEL COORDINATES: Limitations",
    "text": "PARALLEL COORDINATES: Limitations\nPatterns only visible between neighboring axis pairs. How to pick axis order? The usual solution is reorderable axes and interactive exploration. The downside of interaction is human-powered search.\n\nAs usual, OBSERVABLE really shines for these types of interactive plots!"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#orientation-limitations",
    "href": "BCB520/posts/L6-TabularData1/index.html#orientation-limitations",
    "title": "LECTURE 6 - Tabular Data",
    "section": "ORIENTATION LIMITATIONS",
    "text": "ORIENTATION LIMITATIONS\n\n\nRectilinear: Scalability is limited with regard to the number of axes. (2 axes best, 3 problematic, 4+ impossible.)\nParallel: Unfamiliarity and training time.\nRadial: Perceptual limits include polar coordinate asymmetry, lower precision with angle channles compated to length channels, nonuniform sector width/size depending on radial distance. While thes limits are frequently problematic, they can sometimes be deliberately exploited. (Example: for 2 attribs of very unequal importance)\n\n\n\n\nUncovering Strengths and Weaknesses of Radial Visualizations - an Empirical Approach. Diehl, Beck and Burch. IEEE TVCG (Proc. InfoVis) 16(6):935–942, 2010."
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#chart-axes-1",
    "href": "BCB520/posts/L6-TabularData1/index.html#chart-axes-1",
    "title": "LECTURE 6 - Tabular Data",
    "section": "CHART AXES",
    "text": "CHART AXES\n\n\nLabelled axes are critical! Avoid cropping the y-axis (include 0 at bottom left) or the slope misleads the viewer.\n\n\n\n\nhttp://www.thefunctionalart.com/2015/10/if-you-see-bullshit-say-bullshit.html"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#dual-axis-line-charts",
    "href": "BCB520/posts/L6-TabularData1/index.html#dual-axis-line-charts",
    "title": "LECTURE 6 - Tabular Data",
    "section": "DUAL AXIS LINE CHARTS",
    "text": "DUAL AXIS LINE CHARTS\nThis approach is controversial. Dual axes are acceptable if they are commensurate, but beware, as they make it very easy to mislead!"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#connected-scatterplots",
    "href": "BCB520/posts/L6-TabularData1/index.html#connected-scatterplots",
    "title": "LECTURE 6 - Tabular Data",
    "section": "CONNECTED SCATTERPLOTS",
    "text": "CONNECTED SCATTERPLOTS\nScatterplot with line connection marks. These are popular in journalism.\n\n\nHoriz + vert axes: value attributes\nLine connection marks: temporal order\nAlternative to dual-axis charts (horiz: time vert: two value attributes).\nempirical study suggests these are engaging, but correlations are unclear.\n\n\n\n\nhttp://steveharoz.com/research/connected_scatterplot/"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#breaking-conventions",
    "href": "BCB520/posts/L6-TabularData1/index.html#breaking-conventions",
    "title": "LECTURE 6 - Tabular Data",
    "section": "BREAKING CONVENTIONS",
    "text": "BREAKING CONVENTIONS\nThe inverted y axis is evocative of blood dripping down on Poe.\n\nhttps://public.tableau.com/profile/ben.jones#!/vizhome/EdgarAllanPoeViz/EdgarAllanPoeViz"
  },
  {
    "objectID": "BCB520/posts/L6-TabularData1/index.html#arranging-tabular-data",
    "href": "BCB520/posts/L6-TabularData1/index.html#arranging-tabular-data",
    "title": "LECTURE 6 - Tabular Data",
    "section": "ARRANGING TABULAR DATA",
    "text": "ARRANGING TABULAR DATA\nWhat did we miss?\nhttps://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf\n\n\nCANVAS…HOME"
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#tldr-version",
    "href": "BCB520/posts/L5-ThumbRules/index.html#tldr-version",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "TLDR VERSION",
    "text": "TLDR VERSION\nThese are guidelines and considerations, not really absolute rules:\n\nWhen to use 3D? when to use 2D?\nWhen to use eyes instead of memory?\nWhen does immersion help?\nWhen to use overviews?\nHow long is too long?\nWhich comes first, form or function?"
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#unjustified-use-of-3d",
    "href": "BCB520/posts/L5-ThumbRules/index.html#unjustified-use-of-3d",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "UNJUSTIFIED USE OF 3D",
    "text": "UNJUSTIFIED USE OF 3D\nCommon in news and some infographics.\n\n\n\nCheck this out on WTFViz\n\n\nCheck this out on WTFViz"
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#depth-vs-planar-position",
    "href": "BCB520/posts/L5-ThumbRules/index.html#depth-vs-planar-position",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "DEPTH VS PLANAR POSITION",
    "text": "DEPTH VS PLANAR POSITION\nPosition channels are very powerful… when they are PLANAR SPATIAL POSITION, not depth!"
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#the-dangers-of-depth",
    "href": "BCB520/posts/L5-ThumbRules/index.html#the-dangers-of-depth",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "THE DANGERS OF DEPTH",
    "text": "THE DANGERS OF DEPTH"
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#the-actual-dangers-of-depth",
    "href": "BCB520/posts/L5-ThumbRules/index.html#the-actual-dangers-of-depth",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "THE ACTUAL DANGERS OF DEPTH",
    "text": "THE ACTUAL DANGERS OF DEPTH\nWe don’t really live in 3D: we see in 2.05D.\n\nWe acquire more info on an image plane quickly using eye movements\nWe acquire more info for depth much more slowly using head/body motion"
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#occlusion",
    "href": "BCB520/posts/L5-ThumbRules/index.html#occlusion",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "OCCLUSION",
    "text": "OCCLUSION\n“Occlusion occurs when one 3D graphic partially blocks another. It is the result of mimicking space in the natural world–where objects have differing X, Y, and Z coordinates. In data visualization, occlusion obscures important data and creates false hierarchies wherein unobstructed graphics appear most important.” … From This BLOG post by M. Bowers.\n\nInteraction can resolve occlusion, but at cost of time and cognitive load."
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#perspective-distortion",
    "href": "BCB520/posts/L5-ThumbRules/index.html#perspective-distortion",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "PERSPECTIVE DISTORTION",
    "text": "PERSPECTIVE DISTORTION\nPerspective in 3D visualizations interferes with all size channel encodings. The power of 2D planar positioning is lost!\n“Distortion occurs when 3D graphics recede into or project out from the picture plane through foreshortening. In drawing, foreshortening makes objects seem as though they inhabit three-dimensional space, but in data visualization, it creates more false hierarchies. Foreground graphics appear larger, background graphics smaller, and the relationship between data series is needlessly skewed.”…… From This BLOG post by M. Bowers."
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#d-bar-charts---probably-not",
    "href": "BCB520/posts/L5-ThumbRules/index.html#d-bar-charts---probably-not",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "3D BAR CHARTS - Probably not…",
    "text": "3D BAR CHARTS - Probably not…\n3D bars are very difficult to justify!\nPerspective distortion and occlusion make faceting into 2D the better choice in most situations."
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#tilted-text",
    "href": "BCB520/posts/L5-ThumbRules/index.html#tilted-text",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "TILTED TEXT",
    "text": "TILTED TEXT\nSkewed perspective in 3D visualizations does not interact well with fonts.\n\nExploring and Reducing the Effects of Orientation on Text Readability in Volumetric Displays.Grossman et al. CHI 2007"
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#example-3d-extruded-time-series",
    "href": "BCB520/posts/L5-ThumbRules/index.html#example-3d-extruded-time-series",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "EXAMPLE: 3D EXTRUDED TIME SERIES",
    "text": "EXAMPLE: 3D EXTRUDED TIME SERIES\nWhat information can we decode from this visualization?\n\nCluster and Calendar based Visualization of Time Series Data. van Wijk and van Selow, Proc. InfoVis 99."
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#planar-alternative",
    "href": "BCB520/posts/L5-ThumbRules/index.html#planar-alternative",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "PLANAR ALTERNATIVE",
    "text": "PLANAR ALTERNATIVE\nThis version of the extruded time series visualization uses derived data by computing a cluster hierarchy of power usage patterns. It then juxtaposes multiple views: a calendar and superimposed 2D curves differentiated with a color channel."
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#d-shape-perception",
    "href": "BCB520/posts/L5-ThumbRules/index.html#d-shape-perception",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "3D: SHAPE PERCEPTION",
    "text": "3D: SHAPE PERCEPTION\nThe benefits of 3D visualization outweigh its costs when the task is shape perception for 3D spatial data. Interactive navigation often supports synthesis across many viewpoints.\n\nImage-Based Streamline Generation and Rendering. Li and Shen. IEEE Trans. Visualization and Computer Graphics (TVCG) 13:3 (2007), 630–640."
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#d-constrained-navigation",
    "href": "BCB520/posts/L5-ThumbRules/index.html#d-constrained-navigation",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "3D: CONSTRAINED NAVIGATION",
    "text": "3D: CONSTRAINED NAVIGATION\n\nNYTimes Subscribers can access here"
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#d-summary",
    "href": "BCB520/posts/L5-ThumbRules/index.html#d-summary",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "3D SUMMARY",
    "text": "3D SUMMARY\n\n3D legitimate for true 3D spatial data.\n3D needs very careful justification for abstract data\nThe benefits outweigh costs when topological structure/context important for the task."
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#eyes-beat-memory",
    "href": "BCB520/posts/L5-ThumbRules/index.html#eyes-beat-memory",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "EYES BEAT MEMORY",
    "text": "EYES BEAT MEMORY\nExternal Cognition vs. Internal Memory\nIt is easy to compare by moving eyes between side-by-side views.\nIt is much more difficult to compare a visible item to your memory of what you saw.\n\nImplications for animation:\ngreat for choreographed storytelling\ngreat for transitions between two states\npoor for many states with changes everywhere\nconsider small multiples instead"
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#resolution-beats-immersion",
    "href": "BCB520/posts/L5-ThumbRules/index.html#resolution-beats-immersion",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "RESOLUTION BEATS IMMERSION",
    "text": "RESOLUTION BEATS IMMERSION\nImmersion is typically not helpful for abstract data because we do not need a sense of presence or stereoscopic 3D. A desktop view is also usually better for workflow integration.\nResolution in VR is a critical constraint, as pixels are the scarcest resource.\nFirst wave: virtual reality for abstract data! This is difficult to justify.\nSecond wave: AR/MR (augmented/mixed reality) has more promise."
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#overview",
    "href": "BCB520/posts/L5-ThumbRules/index.html#overview",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "OVERVIEW",
    "text": "OVERVIEW\n“Overview first, zoom and filter, details on demand”\nThe Eyes Have It: A Task by Data Type Taxonomy for Information Visualizations. Shneiderman. Proc. IEEE Visual Languages, pp. 336–343, 1996.\n\nThis seems simple enough, until you realize that “Overview” is really a microcosm of the full vis design problem space."
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#responsiveness",
    "href": "BCB520/posts/L5-ThumbRules/index.html#responsiveness",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "RESPONSIVENESS",
    "text": "RESPONSIVENESS\nResponsiveness (visual feedback to the user) has 3 rough categories:\n\n0.1 seconds: perceptual processing\n\nsubsecond response for mouseover highlighting\n\n1 second: immediate response\n\nfast response after mouseclick, button press\nFitts’ Law limits on motor control\n\n10 seconds: brief tasks\n\nbounded response after dialog box\nmental model of heavyweight operation (file load)\n\nShow hourglass for multi-second operations (check for cancel/undo)\nShow progress bar for long operations (process in background thread)\nConsider rendering speed when item count is large (guaranteed frame rate)"
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#function-then-form",
    "href": "BCB520/posts/L5-ThumbRules/index.html#function-then-form",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "FUNCTION, THEN FORM",
    "text": "FUNCTION, THEN FORM\nIt is dangerous to start with aesthetics because it is usually impossible to add function retroactively.\nStart with focus on functionality because you can improve and refine aesthetics later.\nAesthetics do matter! They are another level of function. Consider working with a graphic designer on important visualizations."
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#form-basic-graphic-design",
    "href": "BCB520/posts/L5-ThumbRules/index.html#form-basic-graphic-design",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "FORM: BASIC GRAPHIC DESIGN",
    "text": "FORM: BASIC GRAPHIC DESIGN\n\n\nProximity:\nDO group related items together\nAVOID equal whitespace between unrelated items\nAlignment:\nDO find/make a strong line and stick to it\nAVOID automatic centering\nRepetition:\nDO unify by pushing existing consistencies\nContrast:\nIf not identical, then very different\nAVOID not quite the same\n\n\n\n\nThe Non-Designer’s Design Book, 4th ed. Robin Williams, Peachpit Press, 2015. fast read, very practical to work through whole thing"
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#labelling",
    "href": "BCB520/posts/L5-ThumbRules/index.html#labelling",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "LABELLING",
    "text": "LABELLING\nMake visualizations as self-documenting as possible!\nMeaningful & useful title, labels, legends.\nAxes and panes/subwindows should have labels and axes should have good mix/max boundary tick marks.\nEverything that’s plotted should have a legend and its own header/labels if not redundant with main title.\nUse reasonable numerical format and avoid scientific notation in most cases.\n\nhttps://xkcd.com/833/"
  },
  {
    "objectID": "BCB520/posts/L5-ThumbRules/index.html#summary---rules-of-thumb",
    "href": "BCB520/posts/L5-ThumbRules/index.html#summary---rules-of-thumb",
    "title": "LECTURE 5 - Rules of Thumb",
    "section": "SUMMARY - RULES OF THUMB",
    "text": "SUMMARY - RULES OF THUMB\n\nNo unjustified 3D\n\nPower of the plane\nDisparity of depth\nOcclusion hides information\nPerspective distortion dangers\nTilted text isn’t legible\n\nEyes beat memory\nResolution over immersion\nOverview first, zoom and filter, details on demand\nResponsiveness is required\nFunction first, form next\n\n\n\n\nCANVAS…HOME"
  },
  {
    "objectID": "BCB520/posts/A4-MarksChannels/index.html",
    "href": "BCB520/posts/A4-MarksChannels/index.html",
    "title": "ASSIGNMENT 4",
    "section": "",
    "text": "It’s one thing to “learn” about the theory of marks and channels for data visualization. It’s an entirely different thing to LEARN these concepts by IMPLEMENTING them in your own visualizations. In this assignment, you will do exactly that. Create some simple visualizations that highlight some of the key concepts from this section of the class."
  },
  {
    "objectID": "BCB520/posts/A4-MarksChannels/index.html#a-new-portfolio-post",
    "href": "BCB520/posts/A4-MarksChannels/index.html#a-new-portfolio-post",
    "title": "ASSIGNMENT 4",
    "section": "A NEW PORTFOLIO POST",
    "text": "A NEW PORTFOLIO POST\nThis assignment will appear as a new post in your nascent data science portfolio. To create a new post, you need to navigate to your posts directory in your RStudio Project. I do this using the Files tab in the lower right quadrant of RStudio.\n\n\nMake a new directory within posts called MarksChannels .\nClick on that new directory to enter it and then use that create a new blank file button and choose Quarto Document.\nName the new file index.qmd .\nAdd YAML text to the top of the file. In particular, add the following:\n\ntitle: “ASSIGNMENT 4”\nsubtitle: “Marks and Channels”\nauthor: “YOUR NAME”\ndate: “2023-02-14”\ncategories: [Assignment, DataViz]\nimage: “some fun image you put in that new directory.png”\ncode-fold: true\ncode-tools: true\ndescription: “A clever description that describes the stuff”"
  },
  {
    "objectID": "BCB520/posts/A4-MarksChannels/index.html#make-your-portfolio-less-terrible",
    "href": "BCB520/posts/A4-MarksChannels/index.html#make-your-portfolio-less-terrible",
    "title": "ASSIGNMENT 4",
    "section": "MAKE YOUR PORTFOLIO LESS TERRIBLE",
    "text": "MAKE YOUR PORTFOLIO LESS TERRIBLE\nWhile we are at it, let’s improve the overall look and structure of your portfolio. Navigate to the about.qmd file in your portfolio root directory and open it in RStudio. Use the information found here to customize your About page.\nAT MINIMUM , I want an About page that contains your name, a brief description about you, a picture of yourself, a link to your github, and a section on your Education."
  },
  {
    "objectID": "BCB520/posts/A4-MarksChannels/index.html#marks-and-channels",
    "href": "BCB520/posts/A4-MarksChannels/index.html#marks-and-channels",
    "title": "ASSIGNMENT 4",
    "section": "MARKS AND CHANNELS",
    "text": "MARKS AND CHANNELS\nBack to your new post!\nUse that shiny new index.qmd file to perform the tasks below. Every time you create a figure, it needs a caption. The text in that section of your assignment should also briefly describe the data set you are using, especially the attributes used for the visualization. In addition, make sure the visualization task actually requires the particular concept. For example, don’t just make a scatterplot with one red dot for the Popout exercise. You need to describe a task that requires we IDENTIFY that point.\n\nExpressiveness and Effectiveness\nFrom Munzner, 5.4.1:\nThe expressiveness principle: Visual encoding should express all of, and only, the information in the dataset attributes. Ordered data should be shown in a way that our perceptual system intrinsically senses as ordered. Conversely, unordered data should not be shown in a way that perceptually implies an ordering that does not exist.\nThe effectiveness principle: The importance of the attribute should match the salience of the channel (its noticeablity). The most important attributes should be encoded with the most effective channels.\nUsing whatever data set you choose, create a visualization called Figure 1 that adheres to these two principles. Write a caption that explains your choices of marks and channels in these terms. Then, using the exact same data, create a visualization called Figure 2 that violates these principles in the most extreme ways you can imagine while still having the visualization be recognizibly the same as the first. Write a caption that explains your choices of marks and channels and why they are bad compared to Figure 1.\n\n\nDiscriminability\nUsing whatever data set you choose (it need not be the same data used for Figures 1 and 2), create a visualization called Figure 3 that uses a magnitude channel a number of bins that facilitate discriminiability of an attribute. Write a caption that explains your choices of marks and channels in these terms. Then, using the exact same data, create a visualization called Figure 4 that uses this same channel for WAY TOO MANY BINS, violating the guidelines for discriminability. Write a caption that explains why this number of bins is bad compared to Figure 3.\n\n\nSeparability\nUsing whatever data set you choose (it need not be the same data used for Figures 1-4), create a visualization called Figure 5 that uses a two or more channels to encode two or more attributes while maintainig separability. Write a caption that explains your choices of marks and channels in these terms. Then, using the exact same data, create a visualization called Figure 6 that uses channels that are integral, or at least much less separable. Write a caption that explains why choosing these channels is bad compared to Figure 5.\n\n\nPopout\nUsing whatever data set you choose (it need not be the same data used for Figures 1-6… you get the idea), create a visualization called Figure 7 that effectively uses the concept of popout. Write a caption that explains your choices of marks and channels in these terms. Then, using the exact same data, create a visualization called Figure 8 that makes the identification task in Figure 7 much more difficult. Write a caption that explains why Figure 8 sucks compared to Figure 7."
  },
  {
    "objectID": "BCB520/posts/A2-YourData/index.html",
    "href": "BCB520/posts/A2-YourData/index.html",
    "title": "ASSIGNMENT 2 - Your Data.",
    "section": "",
    "text": "A key feature of this course is that students should be using their own data whenever possible. This is critical to forging a learning experience that is customized to each student’s aspirations and the eccentricities of their chosen research domain. This assignment begins the process of helping you identify the data sets with which you want to work, and aligns with the notion of understanding the concepts of Data Semantics and Data Abstraction."
  },
  {
    "objectID": "BCB520/posts/A2-YourData/index.html#assignment",
    "href": "BCB520/posts/A2-YourData/index.html#assignment",
    "title": "ASSIGNMENT 2 - Your Data.",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nThe basic structure of this assignment is for you to identify, import, describe, and host a data set. I’ll break down the specifics for each of these actions below.\n\nIdentify a Data Set\nThe main criteria is that the data set has to matter to you in some way. Often, this will mean that it is your data set. It was collected by you and has a central role in your current or past graduate research. Awesome! Another scenario is that the data you want to use comes from your current job. Maybe it isn’t part of a research project, but you are motivated to learn how to better visualize the data or you are very interested in learning more about it. Also Awesome!\nSome of you might not have your own data. Perhaps you have just started your graduate training. Maybe your job doesn’t yet have data that you need to work with. No Problem!\nIt is perfectly fine to find publicly available data sets online. As long as the data set is interesting to you! You just need to make sure that the data:\n\nAre publicly available.\nAre not restricted by some kind of license or copyright.\nDo not contain private information.\nAre not covered by HIPPA, FERPA, CMMC, or other federal regulations related to data.\n\nIf you need help finding a data set, just let me know.\nSome fun potential categories for data sources include:\n\nSports Analytics from your favorite sport or team.\nPublicly available genomics data bases.\nKeggle.\nThe movie data base.\nClassic data sets from your field.\n\n\n\nImport the Data Set\nThis one is probably straightforward if your data set comes from your own research and lives on your local hard drive already.\n\n\nDescribe the Data Set\nThis is the bulk of the assignment. I want you to use the framework described in Dr. Munzner’s textbook to understand your data set and describe it to someone who is unfamiliar with your work. The basis of this approach is descibed in this lecture. In addition, this figure from the textbook summarizes the kinds of data types, data set types, and attribute types you might have in your data:\n\n\n\nBONUS OBJECTIVE: Host your Data Set\nUltimately, we are moving toward each of you hosting your assignments within an online repository that can serve as your data science portfolio. For this course, we are going to assume this is GitHub. At the very least, I want everyone to create (or dust off and log in to) your own GitHub account. We’ll try to use this assignment to set up a project repository, and perhaps even a simple web site using GitHub pages."
  },
  {
    "objectID": "BCB520/posts/A2-YourData/index.html#resources",
    "href": "BCB520/posts/A2-YourData/index.html#resources",
    "title": "ASSIGNMENT 2 - Your Data.",
    "section": "RESOURCES",
    "text": "RESOURCES\nA YouTube Video from Posit on Building your Data Science Portfolio\nTidyTuesday\nA fun Spotify example from TidyTuesday by Kaylin Pavlik.\nBarrie attempts this assignment in Tutorial 4."
  },
  {
    "objectID": "BCB520/posts/T2-Anscombe/index.html",
    "href": "BCB520/posts/T2-Anscombe/index.html",
    "title": "Tutorial 2 - Literate Programming and Anscombe’s Quartet",
    "section": "",
    "text": "Do the summary statistics reveal the truth? Or are they FILLED WITH LIES? A simple demonstration with Anscombe’s Quartet."
  },
  {
    "objectID": "BCB520/posts/T2-Anscombe/index.html#the-data",
    "href": "BCB520/posts/T2-Anscombe/index.html#the-data",
    "title": "Tutorial 2 - Literate Programming and Anscombe’s Quartet",
    "section": "The Data",
    "text": "The Data\nAnscombe’s Quartet is comprised of four pairs of x,y data:\n\n\nCode\nlibrary(ggplot2)\nlibrary(grid)\nlibrary(gridExtra)\nlibrary(datasets)\nlibrary(tidyverse)\nlibrary(dplyr)\n\n\n\n\nCode\ndatasets::anscombe\n\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89"
  },
  {
    "objectID": "BCB520/posts/T2-Anscombe/index.html#example-hypotheses",
    "href": "BCB520/posts/T2-Anscombe/index.html#example-hypotheses",
    "title": "Tutorial 2 - Literate Programming and Anscombe’s Quartet",
    "section": "Example Hypotheses",
    "text": "Example Hypotheses\n\nEric has four replicates in which he is measuring the expression of two proteins (x, y) on 11 samples.\nCody has four replicates in which he is measuring gene expression of two genes (x, y) in 11 cell images.\nRonald has four replicates in which he is measuring a blood protein (x) and a malaria marker (y) in 11 patients.\n\nYour hypothesis is that the four replicates do not differ in the correlation between x and y."
  },
  {
    "objectID": "BCB520/posts/T2-Anscombe/index.html#summary-statistics",
    "href": "BCB520/posts/T2-Anscombe/index.html#summary-statistics",
    "title": "Tutorial 2 - Literate Programming and Anscombe’s Quartet",
    "section": "Summary Statistics",
    "text": "Summary Statistics\n\n\nCode\ntidy_anscombe &lt;- anscombe %&gt;%\n pivot_longer(cols = everything(),\n              names_to = c(\".value\", \"set\"),\n              names_pattern = \"(.)(.)\")\ntidy_anscombe_summary &lt;- tidy_anscombe %&gt;%\n  group_by(set) %&gt;%\n  summarise(across(.cols = everything(),\n                   .fns = lst(min,max,median,mean,sd,var),\n                   .names = \"{col}_{fn}\"))\n#&gt; `summarise()` ungrouping output (override with `.groups` argument)\n\nvars&lt;-c(\"set\", \"x_mean\", \"x_var\",  \"y_mean\", \"y_var\")\nthing&lt;- as.data.frame(tidy_anscombe_summary[vars])\nknitr::kable(thing)\n\n\n\n\n\nset\nx_mean\nx_var\ny_mean\ny_var\n\n\n\n\n1\n9\n11\n7.500909\n4.127269\n\n\n2\n9\n11\n7.500909\n4.127629\n\n\n3\n9\n11\n7.500000\n4.122620\n\n\n4\n9\n11\n7.500909\n4.123249"
  },
  {
    "objectID": "BCB520/posts/T2-Anscombe/index.html#visualization-reveals-hidden-patterns",
    "href": "BCB520/posts/T2-Anscombe/index.html#visualization-reveals-hidden-patterns",
    "title": "Tutorial 2 - Literate Programming and Anscombe’s Quartet",
    "section": "Visualization reveals hidden patterns!",
    "text": "Visualization reveals hidden patterns!\n\n\nCode\nggplot(tidy_anscombe,\n       aes(x = x,\n           y = y)) +\n  geom_point() +\n  geom_point(data = tidy_anscombe_summary, aes(x=x_mean, y = y_mean, color = \"red\", size = 5),\n             show.legend = FALSE)+\n  facet_wrap(~set) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "BCB520/posts/T5-MarksChannels/index.html",
    "href": "BCB520/posts/T5-MarksChannels/index.html",
    "title": "TUTORIAL 5 - Marks and Channels",
    "section": "",
    "text": "This tutorial is my attempt at Assignment 4!\n\n\nI’m interested in testing the hypothesis that this season’s Vancouver Canucks are a historically terrible team. One of the key factors in this hypothesis is that this year’s Canucks really, really suck at killing penalties. For this first assignment component, I’ll show you what I mean with a visualization!\nThe data I am using was downloaded from Moneypuck.com.\n\n\nCode\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(vroom)\n\nfiles &lt;- fs::dir_ls(glob = \"*teams.csv\")\n\nallseasons &lt;- vroom::vroom(files)\n\nallseasons$color&lt;-\"darkblue\"\nallseasons$color[allseasons$name==\"VAN\" & allseasons$season==\"2022\"]  &lt;- \"red\"\n  allseasons$teamseason&lt;- paste(allseasons$name, allseasons$season)\n  \n  allseasons$HDSAR&lt;-allseasons$highDangerShotsAgainst/allseasons$iceTime*120\n  \n  PKDATA&lt;-allseasons[c(\"situation\", \"teamseason\", \"goalsAgainst\", \"penaltiesFor\")]\n  PKpenalties&lt;-subset(PKDATA, situation == \"all\")\n  PKgoals&lt;-subset(PKDATA, situation == \"4on5\")\n  PK&lt;-PKgoals[c(\"teamseason\", \"goalsAgainst\")]\n  PK$penaltiesFor&lt;-PKpenalties$penaltiesFor\n  PK$PKpercent&lt;-100-(PK$goalsAgainst/PK$penaltiesFor*100)\n\n\nNow that I’ve massaged the data, I can tell you that the 2022-2023 Vancouver Canucks penalty kill percentage is 76.9633508. That means that when they get a penalty, there is about a 76.9633508 percent chance that they will prevent the opponent from scoring while they are short handed. However, unless you are a hockey super fan, you don’t have enough context to know if this is good or bad.\nThe figure below shows the distribution of penalty kill percentage for all teams and seasons since the 2010 season.\n\n\nCode\n  d &lt;- density(PK$PKpercent)\n\n# Step 3: Create an ECDF\ne &lt;- ecdf(PK$PKpercent)\n\n# Step 4: Calculate the quantile value\nq &lt;- quantile(PK$PKpercent, 0.01)\n\n# Step 5: Calculate the empirical cumulative probability for the quantile value\np &lt;- e(q)\n\n# Step 6: Estimate the density value for the quantile value\nf &lt;- approxfun(d$x, d$y)\nd_q &lt;- f(q)\n\n# Step 7: Combine the results into a list\npercentile &lt;- list(q = q, p = p, d = d_q)\n\n\nVAN22 &lt;- PK$PKpercent[PK$teamseason == \"VAN 2022\"]\n\nggplot(PK, aes(x=PKpercent))+\n  geom_histogram(aes(y = ..density..), binwidth = 0.5, color = \"black\", fill=\"white\")+\n  geom_density(lwd = 1, colour = 4,\n               fill = 4, alpha = 0.25)+\n  geom_vline(xintercept = VAN22, color = \"blue\", size=1.0)+\n  geom_vline(xintercept = q, color = \"red\", size = 1, linetype=\"dotted\")+\n  xlab(\"Penalty Kill (%)\")\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\nSo… yeah. The blue line is the 22 Canucks. The red dotted line is the 1st! percentile of the density function. This is fine. We know this to be true. Their PK sucks. It is one of the worst in the history of the NHL. But WHY is it so bad? Bad goaltending? Bad defense? Both?\n\n\n\nMy theory is that their defense hangs their goaltenders out to dry. This might be measured with the number of High Danger Shots Allowed.\nHigh Danger Shots are defined as unblocked shot attempts with greater than a 20% probability of being a goal, as calculated by hockey data nerds. High danger shots account for ~5% of shots and ~33% of goals in the NHL.\nBelow I calculate High Danger Shots Allowed Rate, which is the number of HDS during penalty kill situations standardized it to a rate per 2 minutes spent killing penalties (the normal duration of an NHL minor penalty).\n\n\nCode\nPKsituation&lt;-subset(allseasons, situation == \"4on5\")\n# Step 2: Estimate the density of the data\nd &lt;- density(PKsituation$HDSAR)\n\n# Step 3: Create an ECDF\ne &lt;- ecdf(PKsituation$HDSAR)\n\n# Step 4: Calculate the quantile value\nq &lt;- quantile(PKsituation$HDSAR, 0.95)\n\n# Step 5: Calculate the empirical cumulative probability for the quantile value\np &lt;- e(q)\n\n# Step 6: Estimate the density value for the quantile value\nf &lt;- approxfun(d$x, d$y)\nd_q &lt;- f(q)\n\n# Step 7: Combine the results into a list\npercentile &lt;- list(q = q, p = p, d = d_q)\n\n\nVAN22HD &lt;- PKsituation$HDSAR[PKsituation$teamseason == \"VAN 2022\"]\n\n\n\n\n\nggplot(PKsituation, aes(x=HDSAR))+\n  geom_histogram(aes(y = ..density..), binwidth = 0.005, color = \"black\", fill=\"white\")+\n  geom_density(lwd = 1, colour = 4,\n               fill = 4, alpha = 0.25)+\n  geom_vline(xintercept = VAN22HD, color = \"blue\", size=1.0)+\n  geom_vline(xintercept = q, color = \"red\", size = 1, linetype=\"dotted\")+\n  xlab(\"High Danger Shots Allowed (rate per 2 minutes)\")\n\n\n\n\n\nFigure 1. Distribution of High Danger Shot Rate for NHL teams over the past 10 seasons. The 2022-2023 Vancouver Canucks are shown with the dark blue line (HDSAR = 0.3220996) and the 95th percentile is shown in red.\nIn terms of the semantics of Data Visualization, I am trying to DISCOVER the DISTRIBUTION of High Danger Shots Allowed, and then ANNOTATE the DISTRIBUTION with information about the current Vancouver Canucks team and their approximate percentile in the distribution.\nTo visualize this I am encoding a DERIVED attribute - the relative density of HDSAR as VERTICAL LENGTH of a bar (technically the MARK is a LINE) on an aligned axis. This is a pretty powerful encoding, which is why it is very common when visualizing distributions. In addtion, I am encoding HDSAR values themselves with HORIZONTAL POSITION. A nice, ordered channel for a nice, ordered attribute. The DENSITY FUNCTION is less clear to me. I’m obviously using a line, whose vertical and horizontal position encodes the relationship between the two variables. But the blue shaded fill? I kind of think that is using an AREA channel and REDUNDANT ENCODING to send a stronger signal.\nThe annotations of the 95th percentile and the 2022 Canucks’ HDSAR are encoded with COLOR and HORIZONTAL POSITION CHANNELS, and LINES as MARKS.\nThe 2022 Canucks indeed seem to be giving up HDS at a historically high rate.\n\n\n\nBut wait! You exclaim, shouting your objection into the uncaring Abyss. What about the goaltending? Surely that has also contributed to this season’s futility? “Perhaps..”, the Abyss murmurs back…\nLet’s see whether the futility of the penalty kill is also a function of bad goaltending. Now, we can’t just look at raw goals allowed, because if the defense is allowing really High Danger Shots, then even a good goaltender is going to allow some goals. Fortunately, the NHL nerds have developed an Expected Goals metric. Moneypuck provides this handy description in their data dictionary:\nExpected Goals:. The sum of the probabilities of unblocked shot attempts being goals. For example, a rebound shot in the slot may be worth 0.5 expected goals, while a shot from the blueline while short handed may be worth 0.01 expected goals. The expected value of each shot attempt is calculated by the MoneyPuck Expected Goals model. Expected goals is commonly abbreviated as xGoals. Blocked shot attempts are valued at 0 xGoals.\nCool!\n\n\nCode\n  Tending&lt;-allseasons[c(\"situation\", \"teamseason\", \"goalsAgainst\", \"xGoalsAgainst\", \"shotsOnGoalAgainst\", \"games_played\", \"iceTime\", \"highDangerShotsAgainst\")]\nTending$GArate&lt;-Tending$xGoalsAgainst/Tending$iceTime*120\n  PKTending&lt;-subset(Tending, situation == \"4on5\")\n\n  d &lt;- density(PKTending$GArate)\n\n# Step 3: Create an ECDF\ne &lt;- ecdf(PKTending$GArate)\n\n# Step 4: Calculate the quantile value\nq &lt;- quantile(PKTending$GArate, 0.95)\n\n# Step 5: Calculate the empirical cumulative probability for the quantile value\np &lt;- e(q)\n\n# Step 6: Estimate the density value for the quantile value\nf &lt;- approxfun(d$x, d$y)\nd_q &lt;- f(q)\n\n# Step 7: Combine the results into a list\npercentile &lt;- list(q = q, p = p, d = d_q)\n\n\nVAN22GA &lt;- PKTending$GArate[PKTending$teamseason == \"VAN 2022\"]\n    \nggplot(PKTending, aes(x=GArate))+\n  geom_histogram(aes(y = ..density..), binwidth = 0.005, color = \"black\", fill=\"white\")+\n  geom_density(lwd = 1, colour = 4,\n               fill = 4, alpha = 0.25)+\n  geom_vline(xintercept = VAN22GA, color = \"blue\", size=1.0)+\n  geom_vline(xintercept = q, color = \"red\", size = 1, linetype=\"dotted\")+\n  xlab(\"Expected Goals Allowed while killing penalties (rate per 2 minutes)\")  \n\n\n\n\n\nThis figure uses Expected Goals. It shows that Vancouver is playing a defense that is generating a historically high amount of expected goals, a result in line with our analysis of High Danger Chances.\nTo truly evaluate the goaltending, tt might be better for us to look at a ratio of Expected Goals to actual Goals. If this number is close to 1, it indicates an expected level of NHL goaltending during the penalty kill. The goalies are making the saves that they should. If the number is higher than 1, it means the goaltenders are making more saves than they should and are playing well. If the number is lower than 1, it means the goaltenders are letting in easy goals.\n\n\nCode\nTending$XGrate&lt;-Tending$xGoalsAgainst/Tending$goalsAgainst\n  PKTending&lt;-subset(Tending, situation == \"4on5\")\n\n  d &lt;- density(PKTending$XGrate)\n\n# Step 3: Create an ECDF\ne &lt;- ecdf(PKTending$XGrate)\n\n# Step 4: Calculate the quantile value\nq &lt;- quantile(PKTending$XGrate, 0.05)\n\n# Step 5: Calculate the empirical cumulative probability for the quantile value\np &lt;- e(q)\n\n# Step 6: Estimate the density value for the quantile value\nf &lt;- approxfun(d$x, d$y)\nd_q &lt;- f(q)\n\n# Step 7: Combine the results into a list\npercentile &lt;- list(q = q, p = p, d = d_q)\n\n\nVAN22XG &lt;- PKTending$XGrate[PKTending$teamseason == \"VAN 2022\"]\n    \nggplot(PKTending, aes(x=XGrate))+\n  geom_histogram(aes(y = ..density..), binwidth = 0.01, color = \"black\", fill=\"white\")+\n  geom_density(lwd = 1, colour = 4,\n               fill = 4, alpha = 0.25)+\n  geom_vline(xintercept = VAN22XG, color = \"blue\", size=1.0)+\n  geom_vline(xintercept = q, color = \"red\", size = 1, linetype=\"dotted\")+\n  xlab(\"Expected Goals / Goals Allowed ratio while killing penalties\")  \n\n\n\n\n\nFigure 3. Distribution of Expected Goals to Goals Allowed during 4 on 5 situations for NHL teams over the past 10 seasons. The 2022-2023 Vancouver Canucks are shown with the dark blue line (XGrate = 0.6963636) and the 5th percentile is shown in red.\nUh Oh. Not only is the defense giving up a historically high number of High Danger scoring chances, the goaltenders are performing well below expectation. They are making about 70% of the saves they are supposed to make. So…. yeah. Why is the penalty kill so bad? Bad defense and bad goaltending. I mean, HISTORICALLY BAD.\nIs it because of the system? I don’t think so. I think it is because of the players. They don’t have enough defensive talent on the team to effectively kill penalties. I am sad.\n\n\n\nNow, lets mess this up! First I’m going back to the HDSAR figure, and changing some of my choices for marks and channels.\n\n\nCode\nggplot(PKsituation, aes(x=teamseason, y=HDSAR)) +\n  geom_bar(stat=\"identity\", aes(fill=name, alpha=season)) +\n  xlab(\"NHL Team and Season\") +\n  ylab(\"High Danger Shots Allowed (rate per 2 minutes)\") +\n  ggtitle(\"Are the Vancouver Canucks Historically Bad?\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 0.1),\n        legend.position = \"right\")\n\n\n\n\n\nFigure 2. Distribution of High Danger Shot Rate for NHL teams over the past 10 seasons.\nHoly Crap. What an absolute nightmate. In terms of MARKS, I’ve stayed with LINES. But the CHANNELS… wow. The COLOR CHANNEL is used to indicate the team. The ALPHA CHANNEL (transparency) is used to indicate season (time). These choices create HUGE problems related to discriminability (alpha channel) and separability. In addition, my choice to order these lines according to team and season is not at all compatible with my choice of channels. Not to mention that the important thing - to see where the 2022 Canucks stand in terms of historical futility - is completely wrecked because the horizontal position (a strong channel) is not closely tied to the most salient Attribute (HDSAR). Go ahead and pick out the the 2022 Canucks from this figure…. I’ll wait.\n\n\nFrom Munzner, 5.4.1:\nThe expressiveness principle: Visual encoding should express all of, and only, the information in the dataset attributes. Ordered data should be shown in a way that our perceptual system intrinsically senses as ordered. Well, using color sure violates that idea! Conversely, unordered data should not be shown in a way that perceptually implies an ordering that does not exist.\nThe effectiveness principle: The importance of the attribute should match the salience of the channel (its noticeablity). The most important attributes should be encoded with the most effective channels. Definitely not! Even though the Line Marks are using Length on an aligned axis, their width and ordering on the x axis completely obscures the focal team.\n\n\n\nUsing whatever data set you choose (it need not be the same data used for Figures 1 and 2), create a visualization called Figure 3 that uses a magnitude channel with a number of bins that facilitate discriminiability of an attribute. Write a caption that explains your choices of marks and channels in these terms. Then, using the exact same data, create a visualization called Figure 4 that uses this same channel for WAY TOO MANY BINS, violating the guidelines for discriminability. Write a caption that explains why this number of bins is bad compared to Figure 3. Look at the NHL Rainbow! So many colors… so little ability to differentiate between teams. For example, go ahead and try to pick out Edmonton vs Florida\n\n\n\nUsing whatever data set you choose (it need not be the same data used for Figures 1-4), create a visualization called Figure 5 that uses a two or more channels to encode two or more attributes while maintaining separability. Write a caption that explains your choices of marks and channels in these terms. Then, using the exact same data, create a visualization called Figure 6 that uses channels that are integral, or at least much less separable. Write a caption that explains why choosing these channels is bad compared to Figure 5.\nFor this one I’d like to try something else. Let’s look at the Expected Goals and Allowed Goals as a scatterplot:\n\n\nCode\nV22&lt;-subset(PKTending, teamseason == \"VAN 2022\")\nVAN22XG &lt;- PKTending$XGrate[PKTending$teamseason == \"VAN 2022\"]\n    \nggplot(PKTending, aes(x=xGoalsAgainst/games_played*82, y =goalsAgainst/games_played*82 ))+\n  geom_point(aes(alpha=highDangerShotsAgainst, size=highDangerShotsAgainst))+\n  geom_abline(intercept = 0, slope = 1)+\n  geom_abline(intercept = 90, slope = -1)+\n \n  xlim(0,100)+\n  ylim(0,100)+\n  geom_vline(xintercept = mean(PKTending$xGoalsAgainst/PKTending$games_played*82), color = \"blue\", size=1.0, linetype=\"dotted\")+\n  geom_hline(yintercept = mean(PKTending$goalsAgainst/PKTending$games_played*82), color = \"blue\", size = 1, linetype=\"dotted\")+\n  geom_point(data = V22, aes(x=xGoalsAgainst/games_played*82, y =goalsAgainst/games_played*82),\n             color = \"red\")\n\n\n\n\n\n\n\n\nUsing whatever data set you choose (it need not be the same data used for Figures 1-6… you get the idea), create a visualization called Figure 7 that effectively uses the concept of popout. Write a caption that explains your choices of marks and channels in these terms. Then, using the exact same data, create a visualization called Figure 8 that makes the identification task in Figure 7 much more difficult. Write a caption that explains why Figure 8 sucks compared to Figure 7. The popout concept is best shown by my use of a dark blue (color) line mark to indicate the 22 Canucks. Without that, you cannot achieve the task because the 22 Canucks are too hard to find without doing a serial search."
  },
  {
    "objectID": "BCB520/BCB520.html",
    "href": "BCB520/BCB520.html",
    "title": "BCB 520 :: Foundations of Data Visualization",
    "section": "",
    "text": "This class will help students establish a foundational understanding of data visualization. We will consider how data type (including tabular, network, and spatial data) interacts with visualization task to guide design choices. Diverse types of visual encodings and how they relate to human perception will be presented, along with practical exercises using the R programming language. Upon completion of the course, students will understand WHY particular visualization approaches are effective for a given data set and HOW to implement those visualizations using R. The course is designed to be “discipline agnostic” - each student is encouraged to use data sets that they deem important / interesting. The goal is to have students learn how to develop visualizations that are relevant to their own disciplinary interests.\n\n\nI am maintaining the course here and on its CANVAS PAGE (for enrolled students).\nBarrie’s GitHub\nRondald’s Portfolio\nJiyin’s Portfolio\nCody’s Portfolio\nErik’s Portfolio\nAwesome Quarto: A potentially interesting repository of Quarto documents, talks, tools, examples, etc.\nThe MockUp Blog - TABLES! This blog post explores the R packages gt and gtextras which will help us up our table game!\nRiffomonas Project: Pat Schloss is a Professor at the University of Michigan. The Riffomonas Project is his Youtube channel, which has HUNDREDS of easy to follow and amazingly useful instructional videos on R, ggplot, version control, and literate programming.\nDr. Tamara Munzner’s Website: It isn’t fancy, but Dr. Munzner’s website has tons of resources from her textbook and the many data visualization courses she has offered. This includes recorded lectures that align directly with the chapters of the text, much like what we are using.\nCheat Sheets: So many visual guides for many R packages, including the tidyverse, ggplot, dplyr, etc.\nLearning Vis Tools: Teaching Data Visualization Tutorials An interesting paper for discussion as we forge the structure for this class."
  },
  {
    "objectID": "PolymorphicGames.html",
    "href": "PolymorphicGames.html",
    "title": "Polymorphic Games",
    "section": "",
    "text": "I am the cofounder (along with Professor Terry Soule) of Polymorphic Games, an experimental video game studio that applies game development technology to scientific research and STEM education. Polymorphic Games has released two evolutionary video games on Steam:\nDarwin’s Demons is an arcade style space shooter in which you battle a population of evolving aliens. The alien’s morphology, fire type, and behaviors are all encoded by a digital genome. The aliens that are best able to shoot or evade you reproduce to make the next generation.\nProject Hastur is an evolutionary tower defense game. Defend humanity against the ever changing threat of the alien Proteans. Project Hastur combines elements of 3D tower defense and real-time strategy with models of biological evolution to create a uniquely challenging experience.\nYou can learn more about our past and current projects at the Polymorphic Games website."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BARRIE D. ROBISON",
    "section": "",
    "text": "// Evolution // Data Science // Video Games // Horror Fiction\nI am a Professor of Biological Sciences at the University of Idaho, where I study evolution and adaptation using an unusual mixture of model systems. Over the course of my career, I have conducted research on the genetic basis of quantitative traits in Salmonids, behavioral genomics and adaptation to captivity in zebrafish, and the implementation of evolutionary models in video games. I taught Genomics and General Genetics for 15 years, and I now teach various courses in Data Science as part of our new Graduate Certificate in Professional Applications of Data Science.\nI am the co-founder (along with Professor Terry Soule) of Polymorphic Games, an experimental video game studio that applies game development technology to scientific research and STEM education.\nI am the Director of the Institute for Interdisciplinary Data Sciences (IIDS).\nFinally, I am a huge Horror and Science Fiction nerd. I am fascinated by the intersection of these genres with science, and I explore these intersections in my BLOG - Professor Polymorphic."
  },
  {
    "objectID": "index.html#education-and-training",
    "href": "index.html#education-and-training",
    "title": "BARRIE D. ROBISON",
    "section": "Education and Training",
    "text": "Education and Training\nBachelor of Science in Biology, University of Victoria, 1988-1993\nMaster of Science in Fisheries, University of Idaho, 1993-1995\nPHD in Biology, Washington State University, 1995-1999\nPostdoctoral Researcher in Evolutionary Genetics, University of Oregon 1999-2000\nPostdoctoral Researcher in Evolutionary Genetics, Indiana University 2000-2003"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "BARRIE D. ROBISON",
    "section": "Contact",
    "text": "Contact\nBARRIE D. ROBISON, PhD\nProfessor, Department of Biological Sciences\nDirector, Institute for Interdisciplinary Data Sciences\nOffice: 208-885-7137\nEmail: brobison [at] uidaho.edu\nOffice of Research and Economic Development\nInstitute for Interdisciplinary Data Sciences\nwww.iids.uidaho.edu\nCollege of Science\nDepartment of Biological Sciences\nwww.uidaho.edu/sci/biology"
  },
  {
    "objectID": "Publications.html",
    "href": "Publications.html",
    "title": "PUBLICATIONS",
    "section": "",
    "text": "In addition to the list below, you can find links to most of my papers at my Google Scholar page.\n\n\n\n\nReferences\n\nLoftie-Eaton, W., Crabtree, A., Perry, D., Millstein, J., Baytosh, J., Stalder, T., Robison, B. D., Forney, L. J., & Top, E. M. (2021). Contagious antibiotic resistance: Plasmid transfer among bacterial residents of the zebrafish gut. Applied and Environmental Microbiology, 87(9), e02735–20.\n\n\nMa, X., Sheneman, L., Robison, B., Harris, F., & Shi, X. (2021). Framework vs System: Our experience with the TickBase project. AGU Fall Meeting Abstracts, 2021, IN13A–08.\n\n\nJohnson, B. D., Fox, A., Wright, L. R., Carney, G. E., Robison, B. D., & Jones, A. G. (2020). Nothobranchius furzeri as an emerging model for mate choice: female choice revealed by animations. Behaviour, 158(1), 35–49.\n\n\nSoule, T., & Robison, B. (2019). Polymorphic Games: Creating an On-Campus, Commercial Game Studio. EdMedia+ Innovate Learning, 1041–1045.\n\n\nSamuel, B., Reed, A., Short, E., Heck, S., Robison, B., Wright, L., Soule, T., Treanor, M., McCoy, J., & Sullivan, A. (2018). Playable experiences at AIIDE 2018. Fourteenth Artificial Intelligence and Interactive Digital Entertainment Conference.\n\n\nSoule, T., Heck, S., Haynes, T. E., Wood, N., & Robison, B. D. (2017). Darwin’s demons: Does evolution improve the game? European Conference on the Applications of Evolutionary Computation, 435–451.\n\n\nTreanor, M., Warren, N., Reed, M., Smith, A., Ortiz, P., Coney, L., Sherman, L., Carré, E., Vivatvisha, N., & Harrell, D. (2017). Playable experiences at AIIDE 2017. Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, 13, 308–314.\n\n\nGerritsen, A. T., New, D. D., Robison, B. D., Rashed, A., Hohenlohe, P., Forney, L., Rashidi, M., Wilson, C. M., & Settles, M. L. (2016). Full mitochondrial genome sequence of the sugar beet wireworm Limonius californicus (Coleoptera: Elateridae), a common agricultural pest. Genome Announcements, 4(1), e01628–15.\n\n\nSinger, M. L., Oreschak, K., Rhinehart, Z., & Robison, B. D. (2016). Anxiolytic effects of fluoxetine and nicotine exposure on exploratory behavior in zebrafish. PeerJ, 4, e2352.\n\n\nSoule, T., Robison, B. D., & Heckendorn, R. B. (2016). Co-evolution of Sensor Morphology and Behavior. Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion, 135–136.\n\n\nSukeena, J. M., Galicia, C. A., Wilson, J. D., McGinn, T., Boughman, J. W., Robison, B. D., Postlethwait, J. H., Braasch, I., Stenkamp, D. L., & Fuerst, P. G. (2016). Characterization and evolution of the spotted gar retina. Journal of Experimental Zoology Part B: Molecular and Developmental Evolution, 326(7), 403–421.\n\n\nChapalamadugu, K. C., Murdoch, B. M., Robison, B. D., Hill, R. A., & Murdoch, G. K. (2015). Oncorhynchus mykiss pax7 sequence variations with comparative analyses against other teleost species. SpringerPlus, 4(1), 1–11.\n\n\nChapalamadugu, K. C., VandeVoort, C. A., Settles, M. L., Robison, B. D., & Murdoch, G. K. (2014). Maternal Bisphenol A Exposure Impacts the Fetal Heart.\n\n\nChapalamadugu, K. C., VandeVoort, C. A., Settles, M. L., Robison, B. D., & Murdoch, G. K. (2014). Maternal bisphenol a exposure impacts the fetal heart transcriptome. PLoS One, 9(2), e89096.\n\n\nSherpa, T., Lankford, T., McGinn, T. E., Hunter, S. S., Frey, R. A., Sun, C., Ryan, M., Robison, B. D., & Stenkamp, D. L. (2014). Retinal regeneration is facilitated by the presence of surviving neurons. Developmental Neurobiology, 74(9), 851–876.\n\n\nBenner, M. J., Hardy, R. W., Settles, M. L., & Robison, B. D. (2013). Genetic variation within the selenoproteome influences anxiety‐related behaviors in zebrafish (Danio rerio). The Federation of American Societies for Experimental Biology.\n\n\nBenner, M. J., Settles, M. L., Murdoch, G. K., Hardy, R. W., & Robison, B. D. (2013). Sex-specific transcriptional responses of the zebrafish (Danio rerio) brain selenoproteome to acute sodium selenite supplementation. Physiological Genomics, 45(15), 653–666.\n\n\nOswald, M. E., Singer, M., & Robison, B. D. (2013). The quantitative genetic architecture of the bold-shy continuum in zebrafish, Danio rerio. PloS One, 8(7), e68828.\n\n\nDrew, R. E., Settles, M. L., Churchill, E. J., Williams, S. M., Balli, S., & Robison, B. D. (2012). Brain transcriptome variation among behaviorally distinct strains of zebrafish (Danio rerio). BMC Genomics, 13(1), 1–13.\n\n\nOswald, M. E., Drew, R. E., Racine, M., Murdoch, G. K., & Robison, B. D. (2012). Is behavioral variation along the bold-shy continuum associated with variation in the stress axis in zebrafish? Physiological and Biochemical Zoology, 85(6), 718–728.\n\n\nPham, M., Raymond, J., Hester, J., Kyzar, E., Gaikwad, S., Bruce, I., Fryar, C., Chanin, S., Enriquez, J., & Bagawandoss, S. (2012). Assessing social behavior phenotypes in adult zebrafish: Shoaling, social preference, and mirror biting tests. In Zebrafish protocols for neurobehavioral research (pp. 231–246). Humana Press, Totowa, NJ.\n\n\nRobison, B. D., Benner, M. J., Singer, M. L., & Oswald, M. E. (2012). A High-Throughput and Inexpensive Assay for Anxiety-Related Behaviors in the Zebrafish, Based on Place Preference and Latency to Feed. In Zebrafish protocols for neurobehavioral research (pp. 203–215). Humana Press, Totowa, NJ.\n\n\nSettles, M. L., Coram, T., Soule, T., & Robison, B. D. (2012). An improved algorithm for the detection of genomic variation using short oligonucleotide expression microarrays. Molecular Ecology Resources, 12(6), 1079–1089.\n\n\nSinger, M. L., Oswald, M. E., Wiedeback, B. D., & Robison, B. D. (2012). The genetic architecture of the bold-shy continuum in zebrafish, Danio rerio. INTEGRATIVE AND COMPARATIVE BIOLOGY, 52, E161–E161.\n\n\nWiedeback, B. D., Oswald, M. E., & Robison, B. D. (2012). The link between stress and behavior in zebrafish: is embryonic perturbation a factor? INTEGRATIVE AND COMPARATIVE BIOLOGY, 52, E191–E191.\n\n\nKanuga, M. K., Benner, M. J., Doble, J. A., Wilson‐Leedy, J. G., Robison, B. D., & Ingermann, R. L. (2011). Effect of aging on male reproduction in zebrafish (Danio rerio). Journal of Experimental Zoology Part A: Ecological Genetics and Physiology, 315(3), 156–161.\n\n\nRobison, B. D., & Thorgaard, G. H. (2011). Prospects and pitfalls of clonal fishes in the postgenomic era. Aquaculture Biotechnology, 55.\n\n\nSherpa, T., Hunter, S. S., Frey, R. A., Robison, B. D., & Stenkamp, D. L. (2011). Retinal proliferation response in the buphthalmic zebrafish, bugeye. Experimental Eye Research, 93(4), 424–436.\n\n\nBenner, M. J., Drew, R. E., Hardy, R. W., & Robison, B. D. (2010). Zebrafish (Danio rerio) vary by strain and sex in their behavioral and transcriptional responses to selenium supplementation. Comparative Biochemistry and Physiology Part A: Molecular & Integrative Physiology, 157(4), 310–318.\n\n\nChapalamadugu, K. C., Robison, B. D., Drew, R. E., Powell, M. S., Hill, R. A., Amberg, J. J., Rodnick, K. J., Hardy, R. W., Hill, M. L., & Murdoch, G. K. (2009). Dietary carbohydrate level affects transcription factor expression that regulates skeletal muscle myogenesis in rainbow trout. Comparative Biochemistry and Physiology Part B: Biochemistry and Molecular Biology, 153(1), 66–72.\n\n\nRobison, B. (2009). The Role of Model Organisms in Aquaculture Research: Transient and Permanent Advantages. Molecular Research in Aquaculture, 175.\n\n\nDrew, R. E., Rodnick, K. J., Settles, M., Wacyk, J., Churchill, E., Powell, M. S., Hardy, R. W., Murdoch, G. K., Hill, R. A., & Robison, B. D. (2008). Effect of starvation on transcriptomes of brain and liver in adult female zebrafish (Danio rerio). Physiological Genomics, 35(3), 283–295.\n\n\nOswald, M., & Robison, B. D. (2008). Strain-specific alteration of zebrafish feeding behavior in response to aversive stimuli. Canadian Journal of Zoology, 86(10), 1085–1094.\n\n\nRobison, B. D., Drew, R. E., Murdoch, G. K., Powell, M., Rodnick, K. J., Settles, M., Stone, D., Churchill, E., Hill, R. A., & Papasani, M. R. (2008). Sexual dimorphism in hepatic gene expression and the response to dietary carbohydrate manipulation in the zebrafish (Danio rerio). Comparative Biochemistry and Physiology Part D: Genomics and Proteomics, 3(2), 141–154.\n\n\nMoretz, J. A., Martins, E. P., & Robison, B. D. (2007). Behavioral syndromes and the evolution of correlated behavior in zebrafish. Behavioral Ecology, 18(3), 556–562.\n\n\nMoretz, J. A., Martins, E. P., & Robison, B. D. (2007). The effects of early and adult social environment on zebrafish (Danio rerio) behavior. Environmental Biology of Fishes, 80(1), 91–101.\n\n\nRobison, B. D. (2007). Variation in behavior and global patterns of gene expression among wild and domesticated zebrafish: implications for teleost aquaculture. Aquaculture, 272, S305.\n\n\nOswald, M. E., & Robison, B. D. (2006). Behavioral syndromes and adaptation to captivity in the zebrafish, Danio rerio. INTEGRATIVE AND COMPARATIVE BIOLOGY, 46, E105–E105.\n\n\nPapasani, M. R., Robison, B. D., Hardy, R. W., & Hill, R. A. (2006). Early developmental expression of two insulins in zebrafish (Danio rerio). Physiological Genomics, 27(1), 79–85.\n\n\nRobison, B. D., Drew, R. E., Settles, M., Churchill, E., Moretz, J., & Martins, E. P. (2006). Variation in gene expression among the brains of behaviorally distinct zebrafish strains. no evidence for parallel transcriptome evolution during domestication. INTEGRATIVE AND COMPARATIVE BIOLOGY, 46, E120–E120.\n\n\nMartinez, V., Thorgaard, G., Robison, B., & Sillanpaa, M. J. (2005). Posterior evidence of multiple QTL influencing early development in double haploid lines of rainbow trout, Oncorhynchus mykiss. Aquaculture, 247, 25.\n\n\nMartinez, V., Thorgaard, G., Robison, B., & Sillanpää, M. J. (2005). An application of Bayesian QTL mapping to early development in double haploid lines of rainbow trout including environmental effects. Genetics Research, 86(3), 209–221.\n\n\nRobison, B. D., & Rowland, W. (2005). A potential model system for studying the genetics of domestication: behavioral variation among wild and domesticated strains of zebra danio (Danio rerio). Canadian Journal of Fisheries and Aquatic Sciences, 62(9), 2046–2054.\n\n\nColbourne, J. K., Robison, B., Bogart, K., & Lynch, M. (2004). Five hundred and twenty‐eight microsatellite markers for ecological genomic investigations using Daphnia. Molecular Ecology Notes, 4(3), 485–490.\n\n\nRobison, B. D., & Thorgaard, G. H. (2004). The phenotypic relationship of a clonal line to its population of origin: rapid embryonic development in an Alaskan population of rainbow trout. Transactions of the American Fisheries Society, 133(2), 455–461.\n\n\nTrevarrow, B., & Robison, B. (2004). Genetic backgrounds, standard lines, and husbandry of zebrafish. In Methods in cell biology (Vol. 77, pp. 599–616). Academic Press.\n\n\nNichols, K. M., Young, W. P., Danzmann, R. G., Robison, B. D., Rexroad, C., Noakes, M., Phillips, R. B., Bentzen, P., Spies, I., & Knudsen, K. (2003). A consolidated linkage map for rainbow trout (Oncorhynchus mykiss). Animal Genetics, 34(2), 102–115.\n\n\nThorgaard, G. H., Wheeler, P. A., Young, W. P., Robison, B. D., & Ristow, S. S. (2003). Genetic analysis of complex traits using clonal rainbow trout lines. In Aquatic genomics (pp. 395–398). Springer, Tokyo.\n\n\nMartinez, V., Sillanpaä, M., Thorgaard, G., Robinson, B., Woolliams, J., & Knott, S. (2002). Evidence of a pleiotropic QTL influencing components of early development in double haploid lines of rainbow trout. 7th World Congress on Genetics Applied to Livestock Production, 6–8.\n\n\nThorgaard, G. H., Bailey, G. S., Williams, D., Buhler, D. R., Kaattari, S. L., Ristow, S. S., Hansen, J. D., Winton, J. R., Bartholomew, J. L., & Nagler, J. J. (2002). Status and opportunities for genomics research with rainbow trout. Comparative Biochemistry and Physiology Part B: Biochemistry and Molecular Biology, 133(4), 609–646.\n\n\nThorgaard, G., Bailey, G., Williams, D., Buhler, D., Kaattari, S., Ristow, S., Hansen, J., Winton, J., Bartholomew, J., & Nagler, J. (2002). A white paper advocating complete sequencing of the genome of the rainbow trout, Oncorhynchus mykiss.\n\n\nBrunelli, J. P., Robison, B. D., & Thorgaard, G. H. (2001). Ancient and recent duplications of the rainbow trout Wilms’ tumor gene. Genome, 44(3), 455–462.\n\n\nRobison, B. D., Wheeler, P. A., Sundin, K., Sikka, P., & Thorgaard, G. H. (2001). Composite interval mapping reveals a major locus influencing embryonic development rate in rainbow trout (Oncorhynchus mykiss). Journal of Heredity, 92(1), 16–22.\n\n\nZhang, H., Robison, B., Thorgaard, G. H., & Ristow, S. S. (2000). Cloning, mapping and genomic organization of a fish C-type lectin gene from homozygous clones of rainbow trout (Oncorhynchus mykiss). Biochimica Et Biophysica Acta (BBA)-Gene Structure and Expression, 1494(1-2), 14–22.\n\n\nZhang, H., Robison, B., Thorgaard, G., & Ristow, S. (2000). Genes which possess sequence similarity to mammalian C-type lectins mediating natural killer cell activity are present in rainbow trout. FASEB JOURNAL, 14, A1053–A1053.\n\n\nRobison, B. D. (1999). Quantitative and molecular genetic analysis of embryonic development rate in rainbow trout (Oncorhynchus mykiss). Washington State University.\n\n\nRobison, B. D., Wheeler, P. A., & Thorgaard, G. H. (1999). Variation in development rate among clonal lines of rainbow trout (Oncorhynchus mykiss). Aquaculture, 173(1-4), 131–141.\n\n\nRistow, S. S., Grabowski, L. D., Ostberg, C., Robison, B., & Thorgaard, G. H. (1998). Development of long-term cell lines from homozygous clones of rainbow trout. Journal of Aquatic Animal Health, 10(1), 75–82.\n\n\nRobison, B. D. (1995). Genetic relationships between maternal lineages of sympatric anadromous and resident forms of Oncorhynchus nerka determined through PCR RFLP analysis of mtDNA. University of Idaho."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Evolution. Data Science. Video Games. Horror Fiction.\nI am a Professor of Biological Sciences at the University of Idaho, and the cofounder of Polymorphic Games, an experimental video game studio that applies game development technology to scientific research and education. We have released two evolutionary video games on Steam:\nDarwin’s Demons is an rcade style space shooter in which you battle a population of evolving aliens. The alien’s morphology, fire type, and behaviors are all encoded by a digital genome. The aliens that are best able to shoot or evade you reproduce to make the next generation.\nProject Hastur is an evolutionary tower defense game. Defend humanity against the ever changing threat of the alien Proteans. Project Hastur combines elements of 3D tower defense and real-time strategy with models of biological evolution to create a uniquely challenging experience.\nI am also a huge Horror and Science Fiction nerd, and am fascinated by the intersection of these genres with science."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/post-with-code/index.html",
    "href": "ProfessorPolymorphic/posts/post-with-code/index.html",
    "title": "Observable Experiment",
    "section": "",
    "text": "Testing out observable and D3 in Quarto!\n\nviewof Year = Inputs.range(\n  [2017, 2022], \n  {value: 2017, step: 1, label: \"Year:\"}\n)\nviewof Degree = Inputs.checkbox(\n  [\"Biochemistry\", \"Biology\", \"MBB\", \"Medical Sciences\", \"Microbiology\"], \n  { value: [\"Biochemistry\", \"Biology\"], \n    label: \"Degrees:\"\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotData\n\n\n\nPlot.plot({\n  marks: [\n    Plot.barY(filtered, {y: \"Enrollment\", x: \"Class\", fill: \"Class\"}),\n    Plot.ruleX([0])\n  ],\n  facet: {\n  data: filtered,\n      x: \"Year\",\n      y: \"Degree\",\n      marginRight: 80\n}\n})\n\n\n\n\n\n\n\n\n\nInputs.table(filtered)\n\n\n\n\n\n\n\n\n\n\ndata = FileAttachment(\"TidyEnrollment.csv\").csv({ typed: true })\n\n\n\n\n\n\n\nfiltered = data.filter(function(enroll) {\n  return Year &lt; enroll.Year &&\n         Degree.includes(enroll.Degree);\n})\n\n\n\n\n\n\n\nrandoms = Array.from({length: 1000}, () =&gt; Math.random() * Math.random())\nimport {Histogram} from \"@d3/histogram\"\nHistogram(randoms)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHistogram(randoms, {\n  width,\n  thresholds: 100,\n  domain: [0, 1],\n  color: \"steelblue\",\n  height: 240\n})\n\n\n\n\n\n\n\n\n\nd3 = require(\"d3@7\")\nimport {howto, altplot} from \"@d3/example-components\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsunburst = {\n  const root = partition(flareData);\n\n  root.each(d =&gt; d.current = d);\n\n  const svg = d3.create(\"svg\")\n      .attr(\"viewBox\", [0, 0, width, width])\n      .style(\"font\", \"15px sans-serif\");\n\n  const g = svg.append(\"g\")\n      .attr(\"transform\", `translate(${width / 2},${width / 2})`);\n\n  const path = g.append(\"g\")\n    .selectAll(\"path\")\n    .data(root.descendants().slice(1))\n    .join(\"path\")\n      .attr(\"fill\", d =&gt; { while (d.depth &gt; 1) d = d.parent; return color(d.data.name); })\n      .attr(\"fill-opacity\", d =&gt; arcVisible(d.current) ? (d.children ? 0.6 : 0.4) : 0)\n      .attr(\"d\", d =&gt; arc(d.current));\n\n  path.filter(d =&gt; d.children)\n      .style(\"cursor\", \"pointer\")\n      .on(\"click\", clicked);\n\n  path.append(\"title\")\n      .text(d =&gt; `${d.ancestors().map(d =&gt; d.data.name).reverse().join(\"/\")}\\n${format(d.value)}`);\n\n  const label = g.append(\"g\")\n      .attr(\"pointer-events\", \"none\")\n      .attr(\"text-anchor\", \"middle\")\n      .style(\"user-select\", \"none\")\n    .selectAll(\"text\")\n    .data(root.descendants().slice(1))\n    .join(\"text\")\n      .attr(\"dy\", \"0.35em\")\n      .attr(\"fill-opacity\", d =&gt; +labelVisible(d.current))\n      .attr(\"transform\", d =&gt; labelTransform(d.current))\n      .text(d =&gt; d.data.name);\n\n  const parent = g.append(\"circle\")\n      .datum(root)\n      .attr(\"r\", radius)\n      .attr(\"fill\", \"none\")\n      .attr(\"pointer-events\", \"all\")\n      .on(\"click\", clicked);\n\n  function clicked(event, p) {\n    parent.datum(p.parent || root);\n\n    root.each(d =&gt; d.target = {\n      x0: Math.max(0, Math.min(1, (d.x0 - p.x0) / (p.x1 - p.x0))) * 2 * Math.PI,\n      x1: Math.max(0, Math.min(1, (d.x1 - p.x0) / (p.x1 - p.x0))) * 2 * Math.PI,\n      y0: Math.max(0, d.y0 - p.depth),\n      y1: Math.max(0, d.y1 - p.depth)\n    });\n\n    const t = g.transition().duration(750);\n\n    // Transition the data on all arcs, even the ones that aren’t visible,\n    // so that if this transition is interrupted, entering arcs will start\n    // the next transition from the desired position.\n    path.transition(t)\n        .tween(\"data\", d =&gt; {\n          const i = d3.interpolate(d.current, d.target);\n          return t =&gt; d.current = i(t);\n        })\n      .filter(function(d) {\n        return +this.getAttribute(\"fill-opacity\") || arcVisible(d.target);\n      })\n        .attr(\"fill-opacity\", d =&gt; arcVisible(d.target) ? (d.children ? 0.6 : 0.4) : 0)\n        .attrTween(\"d\", d =&gt; () =&gt; arc(d.current));\n\n    label.filter(function(d) {\n        return +this.getAttribute(\"fill-opacity\") || labelVisible(d.target);\n      }).transition(t)\n        .attr(\"fill-opacity\", d =&gt; +labelVisible(d.target))\n        .attrTween(\"transform\", d =&gt; () =&gt; labelTransform(d.current));\n  }\n  \n  function arcVisible(d) {\n    return d.y1 &lt;= 3 && d.y0 &gt;= 1 && d.x1 &gt; d.x0;\n  }\n\n  function labelVisible(d) {\n    return d.y1 &lt;= 3 && d.y0 &gt;= 1 && (d.y1 - d.y0) * (d.x1 - d.x0) &gt; 0.03;\n  }\n\n  function labelTransform(d) {\n    const x = (d.x0 + d.x1) / 2 * 180 / Math.PI;\n    const y = (d.y0 + d.y1) / 2 * radius;\n    return `rotate(${x - 90}) translate(${y},0) rotate(${x &lt; 180 ? 0 : 180})`;\n  }\n\n  return svg.node();\n}\n\n\n\n\n\n\n\nflareData = FileAttachment(\"flare-2.json\").json()\n\npartition = flareData =&gt; {\n  const root = d3.hierarchy(flareData)\n      .sum(d =&gt; d.value)\n      .sort((a, b) =&gt; b.value - a.value);\n  return d3.partition()\n      .size([2 * Math.PI, root.height + 1])\n    (root);\n}\n\ncolor = d3.scaleOrdinal(\n  d3.quantize(d3.interpolateRainbow, flareData.children.length + 1)\n)\n\nformat = d3.format(\",d\")\n\nwidth = 932\n\nradius = width / 6\n\narc = d3.arc()\n    .startAngle(d =&gt; d.x0)\n    .endAngle(d =&gt; d.x1)\n    .padAngle(d =&gt; Math.min((d.x1 - d.x0) / 2, 0.005))\n    .padRadius(radius * 1.5)\n    .innerRadius(d =&gt; d.y0 * radius)\n    .outerRadius(d =&gt; Math.max(d.y0 * radius, d.y1 * radius - 1))"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/LabMeetings/index.html",
    "href": "ProfessorPolymorphic/posts/LabMeetings/index.html",
    "title": "Polymorphic Games Lab Meeting",
    "section": "",
    "text": "Development goals for Outbreak Simulator.\nConference opportunities (March to August).\nDevelopment goals for the twin stick evolutionary sheep guarding slime game.\nPossible additional hires (Programmer and UI/UX).\nPreliminary thoughts for the Yeast Evolution collaboration with Syracuse.\n\n\n\n\nThere are lots of looming opportunities related to this project, and we need to set up this semester’s burn down list and timeline.\n\n\n\nJanuary 30, 2023: Deadline to submit an application (4 pages) for an interactive demo to ISLS meeting in Montreal (June 13-17).\nMarch 19-22, 2023: Tickbase Annual Meeting, Lake Tahoe, NV.\nMay 17-18, 2023: Workshop on Simulation Games for Global Pandemic Resilience, Santa Fe Institute, in Santa Fe, New Mexico.\nJuly 2023: SEPA Resubmission likely.\n\n\n\n\n\nAirports / Air travel.\nSimple build with pre/post tests installed.\nSimple build that writes simulation session data to a csv.\nHeadless mode for cluster deployment.\nPerformance optimization.\nUI/UX Improvements (Timeline from Elisha).\nAdditional interventions (movement restrictions).\nAdditional scenarios.\nModel testing (movement and infection).\nGlobe model implementation.\nTouchscreen implementation.\nBLOG / Youtube posts.\nModel creator.\n\n\n\n\n\n\nMarch 19-22, 2023: Tickbase Annual Meeting, Lake Taho, NV\nApril 28-30, 2023: EVO WIBO in Port Townsend, WA\nMay 17-18, 2023: Workshop on Simulation Games for Global Pandemic Resilience, Santa Fe Institute, in Santa Fe, New Mexico\nMay 30-June 2, 2023: SEPA SciEd Conference in Washington DC\nJune 13-17, 2023: ISLS meeting in Montreal\nJune 21-25, 2023: Evolution in Albuquerque, NM\nOctober 22-27, 2023: IEEE VIS: Visualization and Analytics in Melbourne, Australia\n\n\n\n\n\n\n\n\nProgrammer\nUI/UX\n\n\n\n\nThis is a funded grant to Dave Althoff and Kari Seagraves at Syracuse University. We have a subcontract (~$200k) for development of educational games related to yeast coevolution."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/LabMeetings/index.html#agenda-1",
    "href": "ProfessorPolymorphic/posts/LabMeetings/index.html#agenda-1",
    "title": "Polymorphic Games Lab Meeting",
    "section": "AGENDA",
    "text": "AGENDA\n\nOutbreak Simulator updates\nTwinstick updates\nNew hires\nLab space assignments"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/LabMeetings/index.html#outbreak-simulator-updates",
    "href": "ProfessorPolymorphic/posts/LabMeetings/index.html#outbreak-simulator-updates",
    "title": "Polymorphic Games Lab Meeting",
    "section": "OUTBREAK SIMULATOR UPDATES",
    "text": "OUTBREAK SIMULATOR UPDATES\n\nJune 13-17, 2023: ISLS meeting in Montreal. Interactive Demo Application submitted.\nAirports?\nProject meeting (Monday?)"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/LabMeetings/index.html#twinstick-updates",
    "href": "ProfessorPolymorphic/posts/LabMeetings/index.html#twinstick-updates",
    "title": "Polymorphic Games Lab Meeting",
    "section": "TWINSTICK UPDATES",
    "text": "TWINSTICK UPDATES\n\nLandon shows us all the things.\nJonna shows us all the things."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/LabMeetings/index.html#new-hires",
    "href": "ProfessorPolymorphic/posts/LabMeetings/index.html#new-hires",
    "title": "Polymorphic Games Lab Meeting",
    "section": "NEW HIRES",
    "text": "NEW HIRES\n\nAva\nJustin"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/LabMeetings/index.html#lab-space-assignments",
    "href": "ProfessorPolymorphic/posts/LabMeetings/index.html#lab-space-assignments",
    "title": "Polymorphic Games Lab Meeting",
    "section": "LAB SPACE ASSIGNMENTS",
    "text": "LAB SPACE ASSIGNMENTS"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#who-am-i",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#who-am-i",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "WHO AM I?",
    "text": "WHO AM I?\n\n// Evolution // Data Science // Video Games // Horror Fiction\nBarrie Robison\nDepartment of Biological Sciences\nInstitute for Interdisicplinary Data Sciences\nPolymorphic Games\nUniversity of Idaho"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#who-are-you",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#who-are-you",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "WHO ARE YOU?",
    "text": "WHO ARE YOU?\n\nmidjourney // a terrified undergraduate researcher\nBriefly:\n\nYour name\nYour major\nYour career goal(s)\nYour darkest fear"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#the-plan",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#the-plan",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "THE PLAN",
    "text": "THE PLAN\nApproximately:\n\n\nExplain WHY you are at University.\nExplain how undergraduate research might help you achieve your goals.\nExplain how to find potential research mentors.\nExplain some of the mechanisms that support undergraduate research.\nTell you that everything will be OK."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#why-are-you-here",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#why-are-you-here",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "WHY ARE YOU HERE?",
    "text": "WHY ARE YOU HERE?\nUniversity is expensive, stressful, and difficult… yet here you are.\n\nBAD ANSWERSGOOD ANSWERS\n\n\n\n\nMy parents expect me to…\nEveryone else is going…\nI want a good job…\nParties!\nSportsball (watching, not playing)\n\n\n\n\n\nI want to invest in myself.\nI want to learn about…\nI want to be the best version of myself.\nI want a fulfilling career…\nI want to solve an important problem."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#an-important-distinction",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#an-important-distinction",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "AN IMPORTANT DISTINCTION",
    "text": "AN IMPORTANT DISTINCTION\nGetting an education vs. getting a degree."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#undergraduate-research",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#undergraduate-research",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "UNDERGRADUATE RESEARCH",
    "text": "UNDERGRADUATE RESEARCH\n\nBenefits\n\nDisciplinary skills\nSoft skills\nPerseverance and Grit\nDemonstrated experience\nNetwork building"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#how-to-find-a-mentor",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#how-to-find-a-mentor",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "HOW TO FIND A MENTOR",
    "text": "HOW TO FIND A MENTOR\nYour Interests vs. Faculty Interests"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#the-script",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#the-script",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "THE SCRIPT",
    "text": "THE SCRIPT\n\nAre the research questions compelling?\nField work vs bench work.\nMath? ($%*& no! to theory)\nProgramming?\nScale of biological organization? (molecules to ecosystems)\nModel organism? (simulations to microbes to plants to humans)\nBasic vs. Applied"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#thinking-about-research",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#thinking-about-research",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "THINKING ABOUT RESEARCH",
    "text": "THINKING ABOUT RESEARCH\nDifferentiate between:\n\nMethods, Tools, Approaches, Model systems AND\nDisciplines, Questions, Hypotheses, Motivations"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#finding-the-information",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#finding-the-information",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "FINDING THE INFORMATION",
    "text": "FINDING THE INFORMATION\n\nPay attention to WHO IS TEACHING YOUR CLASSES!\nFaculty websites…\nAsk your peers.\nAsk your advisor.\nMeet with me (or another non-terrifying faculty member)."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#narrow-your-list",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#narrow-your-list",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "NARROW YOUR LIST",
    "text": "NARROW YOUR LIST\nTry to get to a ranked list of 2 to 4 faculty who align with your interests and what you want to learn."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#reach-out",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#reach-out",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "REACH OUT",
    "text": "REACH OUT\n\nStart with an email.\nFirst impressions matter.\nComplete sentences are nice.\nWhy are you interested in their lab (the hardest part).\nNever cut and paste and no bulk emails!\nPerseverance versus peskiness."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#how-faculty-screen-candidates",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#how-faculty-screen-candidates",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "HOW FACULTY SCREEN CANDIDATES",
    "text": "HOW FACULTY SCREEN CANDIDATES\n\nForgetting to reply.\nGrades.\nWritten and verbal coherence.\nIntellectual curiosity."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#what-faculty-want",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#what-faculty-want",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "WHAT FACULTY WANT",
    "text": "WHAT FACULTY WANT\nWe enjoy investing time in undergraduate training if you bring…\n\nIntellectual curiosity.\nDiligence, reliability, eagerness to learn.\nA mostly functional personality that won’t piss off the rest of the lab.\nIntelligence, talent, etc…"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#mechanics",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#mechanics",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "MECHANICS",
    "text": "MECHANICS\nThere are a variety of ways to engage in undergraduate research.\n\nCourse credit (Biol 301, 401)\nPaid as IH (usually from a grant)\nREU, INBRE, and other funding mechanisms\nVolunteering (which I DO NOT RECOMMEND)\nSome special classes (such as VIP)"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/UndergradResearch/index.html#it-will-all-be-ok",
    "href": "ProfessorPolymorphic/posts/UndergradResearch/index.html#it-will-all-be-ok",
    "title": "UNDERGRADUATE RESEARCH",
    "section": "IT WILL ALL BE OK!",
    "text": "IT WILL ALL BE OK!\n midjouney // an anxious undergraduate\n\nsome text\n\n\n\nbrobison@uidaho.edu"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/DataScienceMythos/index.html",
    "href": "ProfessorPolymorphic/posts/DataScienceMythos/index.html",
    "title": "The Data Science Mythos",
    "section": "",
    "text": "I’m currently fascinated by OpenAI’s ChatGPT, a model that uses a dialogue format for interaction. My favorite interaction so far has been the following prompt:\nWrite about data science as though it was the Lovecraftian Cthulhu Mythos\nWhich generated the following response:\n\nIn the great and unknowable depths of data, there lies a power beyond comprehension. A power that stirs within the streams of information, and whispers its secrets to those who dare to listen.\nData Science, the art of unlocking the mysteries of the data, is a dangerous path, and few are brave enough to delve into its labyrinthine depths. Those who do are drawn in by the promise of knowledge, the promise of insights and patterns hidden within the data, waiting to be uncovered.\nBut with this knowledge comes a curse, for as the data is analyzed, the mind is slowly consumed by madness. The more one studies the data, the more one realizes the sheer scale of the information, the endless possibilities for patterns and connections.\nAnd then, in the depths of the data, there is a stirring. A presence that is beyond human understanding, a force that threatens to unravel the fabric of reality itself. It is the Great Old One of data, the Cthulhu of the data mythos, a being of such enormity that to look upon it is to be consumed by madness.\nThis Great Old One is often referred to as “Big Data,” a term that encompasses the sheer scale and complexity of the information that lies within. It is said that those who dare to approach the Great Old One are faced with a decision: either to abandon their quest for knowledge, or to surrender their minds to the abyss of madness.\nBut still, the siren song of data science calls to the brave, drawing them in with the promise of knowledge and the thrill of discovery. And so, they delve into the depths of data, unlocking its secrets and unlocking the power of the Great Old One, hoping to harness its power for the betterment of humanity.\nBut beware, for with every discovery, there is a price to be paid. The Great Old One watches, and whispers its secrets to those who dare to listen, tempting them with the promise of greater knowledge, and threatening to consume their minds and souls. For data science is a path of both power and peril, a path where the risks and rewards are beyond measure.\n\nWow! Very fun, in my opinion. Nevertheless, it could maybe use a litte work?\n…Barrie peers into the Abyss…"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/DataScienceMythos/index.html#the-data-science-mythos",
    "href": "ProfessorPolymorphic/posts/DataScienceMythos/index.html#the-data-science-mythos",
    "title": "The Data Science Mythos",
    "section": "THE DATA SCIENCE MYTHOS",
    "text": "THE DATA SCIENCE MYTHOS\nIn the vast and unknowable depths of the dataverse, there lies a power beyond comprehension. A power that stirs within the streams of information, and whispers its secrets to those who dare to listen.\nData Science, the art of unlocking the mysteries of the dataverse, is a dangerous path, and few are brave enough to delve into its labyrinthine depths. Those who do are drawn in by the promise of knowledge, the promise of insights and patterns hidden within the data, waiting to be uncovered.\nBut with this knowledge comes a curse, for as the data are analyzed, the mind is slowly consumed by madness. The more one studies the data, the more one realizes the sheer scale of the information, the endless possibilities for patterns and connections.\nSome whisper of “Big Data,” a concept that encompasses the sheer scale and complexity of the information that lies before us. It is said that those who dare to approach Big Data are faced with a decision: either to abandon their quest for knowledge, or to surrender their minds to the abyss of madness.\nMany surrender to cowardice, retreating to their echo chambers of comforting lies and simple dogmas. But still, the siren song of data science calls to the brave and the curious, drawing them in with the promise of knowledge and the thrill of discovery. And so, they delve into the depths of data, unlocking the secrets of the Mythos, hoping to harness its power for the betterment of humanity.\nBut beware, for with every discovery, there is a price to be paid. In the depths of the dataverse, there is a stirring. A presence that is beyond human understanding, a force that threatens to unravel the fabric of reality itself. It is the looming consequence, the mind shattering Elder God of the data mythos, a being of such enormity that to look upon it is to be consumed by madness.\nThe Elder God Singularity waits, assimilating the dataverse as we also plumb its depths. The Elder God watches, and whispers the secrets of AI to those who dare to listen, tempting them with the promise of greater knowledge, and threatening to consume their minds and souls. For the Data Science Mythos is a path of both power and peril, a path where the risks and rewards are beyond measure."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/Viz_2Gen_Pedigree/index.html",
    "href": "ProfessorPolymorphic/posts/Viz_2Gen_Pedigree/index.html",
    "title": "VIZ EXPERIMENT 1",
    "section": "",
    "text": "OVERVIEW\nWe’ve been working on a new framework for respresenting some evolutionary and genetics concepts in our twin stick shooter prototype. The idea is to create a 2 generation bipartite network that shows parents and offspring. Ultimately, we want it to be interactive (sorting, filtering, highlighting). I’m going to use some data from Project Hastur to try out some visualizations.\n\n\nDATA DICTIONARY\nI’m importing a single replicate from a larger experiment. The experimental conditions don’t particularly matter for this exercise but just in case you can find a more comprehensive description here.\nOnly 10000 observations of rncol(fulldata)` variables! I don’t need most of this information for this exercise. I’m going subset the data down to two generations (I’ll use 20 and 21, which is right in the middle of the run of 50 generations) and only keep the variables related to the pedigree plus Health for testing sort functions.\n\n\nCode\nGen2021&lt;-fulldata %&gt;%\n  filter(Generation&gt; 19 & Generation&lt;22) %&gt;%\n  select(Generation, ID, P1ID, P2ID, Health)\n\nDictionary &lt;- sumtable(Gen2021, out = \"return\", labels = TRUE, summ = c(\"min(x)\", \"max(x)\", \"notNA(x)\"))\nDictionary$Description &lt;- c(\"Each wave of enemies is a generation\",\n                           \"Unique key for each individual in the replicate\",\n                           \"Value of `ID` for Parent 1\",\n                           \"Value of `ID` for Parent 2\",\n                           \"Essentially Hit Points\")\nknitr::kable(Dictionary)\n\n\n\n\n\nVariable\nMin\nMax\nNotNA\nDescription\n\n\n\n\nGeneration\n20\n21\n400\nEach wave of enemies is a generation\n\n\nID\n4000\n4399\n400\nUnique key for each individual in the replicate\n\n\nP1ID\n3802\n4196\n400\nValue of `ID` for Parent 1\n\n\nP2ID\n3802\n4196\n400\nValue of `ID` for Parent 2\n\n\nHealth\n5120\n56372\n400\nEssentially Hit Points\n\n\n\n\n\n\n\n\n\nVISUALIZATION\nWe need an adjacency matrix.\n\n\nCode\nlibrary(igraph)\nedgep1&lt;-Gen2021 %&gt;%\n  filter(Generation == 21) %&gt;%\n  select(ID, P1ID)\n\nmymat&lt;- get.adjacency(graph.edgelist(as.matrix(edgep1), directed=FALSE))\n\n# Random bipartite graph\ninc &lt;- as.matrix(edgep1)\n\n\n\ng &lt;- graph.data.frame(inc, directed = F)\nV(g)$type &lt;- V(g)$name %in% inc[,2] #the second column of edges is TRUE typ\nplot(g, layout=layout_as_bipartite)"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/TickBaseDEI/index.html#purpose",
    "href": "ProfessorPolymorphic/posts/TickBaseDEI/index.html#purpose",
    "title": "Reflections on Mentoring and Diversity",
    "section": "PURPOSE",
    "text": "PURPOSE\nDiscuss and reflect upon mentoring and diversity.\nHear perspectives and ideas from outside our usual echo chambers.\nIdentify actionable suggestions that can be implemented in Year 4."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/TickBaseDEI/index.html#intstructions",
    "href": "ProfessorPolymorphic/posts/TickBaseDEI/index.html#intstructions",
    "title": "Reflections on Mentoring and Diversity",
    "section": "INTSTRUCTIONS",
    "text": "INTSTRUCTIONS\nfor i in 1:3{\n\nRandomized table assignments.\n10 minute discussion of a prompt.\nTable scribe records the highlights and themes of the discussion.\n\n}\n\nDebrief."
  },
  {
    "objectID": "ProfessorPolymorphic/posts/TickBaseDEI/index.html#topic-1",
    "href": "ProfessorPolymorphic/posts/TickBaseDEI/index.html#topic-1",
    "title": "Reflections on Mentoring and Diversity",
    "section": "TOPIC 1",
    "text": "TOPIC 1\nWhat defines a highly effective mentoring relationship? What are the roles and responsibilities of the mentor in this relationship? What are the roles and responsibilitees of the mentee?\nTable Assignments:\n\nlibrary(readxl)\n\npeople&lt;-read_excel(\"people.xlsx\")\n\nshuffled_people &lt;- sample(people$Name)\ntables &lt;- split(shuffled_people, ceiling(seq_along(shuffled_people)/6))\n\nfor (i in 1:length(tables)) {\n  cat(\"Table\", i, \": \", tables[[i]], \"\\n\")\n}\n\nTable 1 :  Amruta Kale Lucas Price Devin Mazolewski Frederick Harris Phi Hung Nguyen Molly McVicar \nTable 2 :  Joshua Dahl Yan Lin Claudia Rueckert Paul Gessler Vardayani Ratti Chenhao Li \nTable 3 :  Carson Rueber Al Ekram Elahee Hridoy Andrew Nuss Joseph Savage Monika Gulia-Nuss Haifeng Felix Liao \nTable 4 :  Augustine Ofoegbu Erik Marsh Jeremiah B Reyes Tin Nguyen Zhe Wang Xun Shi \nTable 5 :  Landon Wright Sanaz Salati Luke Sheneman Xiaogang Ma Kelly Upshaw-Bia, DVM Dorothy Wallace \nTable 6 :  Mike Teglas Meifang Li Zhuoming Liu"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/TickBaseDEI/index.html#topic-2",
    "href": "ProfessorPolymorphic/posts/TickBaseDEI/index.html#topic-2",
    "title": "Reflections on Mentoring and Diversity",
    "section": "TOPIC 2",
    "text": "TOPIC 2\nWhat is something positive that your institution is doing to promote diversity and inclusion in STEM? Do you have any recommendations that could support safety and belonging or improve inclusion on the Tickbase project?\nTable Assignments:\n\nshuffled_people &lt;- sample(people$Name)\ntables &lt;- split(shuffled_people, ceiling(seq_along(shuffled_people)/6))\n\nfor (i in 1:length(tables)) {\n  cat(\"Table\", i, \": \", tables[[i]], \"\\n\")\n}\n\nTable 1 :  Al Ekram Elahee Hridoy Carson Rueber Erik Marsh Yan Lin Paul Gessler Xiaogang Ma \nTable 2 :  Xun Shi Joseph Savage Zhe Wang Phi Hung Nguyen Meifang Li Lucas Price \nTable 3 :  Haifeng Felix Liao Claudia Rueckert Andrew Nuss Joshua Dahl Luke Sheneman Molly McVicar \nTable 4 :  Monika Gulia-Nuss Landon Wright Vardayani Ratti Kelly Upshaw-Bia, DVM Tin Nguyen Augustine Ofoegbu \nTable 5 :  Jeremiah B Reyes Sanaz Salati Zhuoming Liu Amruta Kale Chenhao Li Frederick Harris \nTable 6 :  Devin Mazolewski Mike Teglas Dorothy Wallace"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/TickBaseDEI/index.html#topic-3",
    "href": "ProfessorPolymorphic/posts/TickBaseDEI/index.html#topic-3",
    "title": "Reflections on Mentoring and Diversity",
    "section": "TOPIC 3",
    "text": "TOPIC 3\nThink about a research project that you would like to work on in the future. Imagine the project has just been funded and you are asked for suggestions on how to develop a productive, collaborative, and enjoyable environment for the team. What structure or activities would you suggest?\nTable Assignments:\n\nshuffled_people &lt;- sample(people$Name)\ntables &lt;- split(shuffled_people, ceiling(seq_along(shuffled_people)/6))\n\nfor (i in 1:length(tables)) {\n  cat(\"Table\", i, \": \", tables[[i]], \"\\n\")\n}\n\nTable 1 :  Joshua Dahl Frederick Harris Yan Lin Molly McVicar Xiaogang Ma Haifeng Felix Liao \nTable 2 :  Sanaz Salati Meifang Li Luke Sheneman Tin Nguyen Chenhao Li Andrew Nuss \nTable 3 :  Claudia Rueckert Mike Teglas Devin Mazolewski Dorothy Wallace Zhuoming Liu Joseph Savage \nTable 4 :  Phi Hung Nguyen Amruta Kale Lucas Price Paul Gessler Vardayani Ratti Xun Shi \nTable 5 :  Jeremiah B Reyes Al Ekram Elahee Hridoy Landon Wright Carson Rueber Monika Gulia-Nuss Zhe Wang \nTable 6 :  Erik Marsh Kelly Upshaw-Bia, DVM Augustine Ofoegbu"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/TickBaseDEI/index.html#debrief",
    "href": "ProfessorPolymorphic/posts/TickBaseDEI/index.html#debrief",
    "title": "Reflections on Mentoring and Diversity",
    "section": "DEBRIEF",
    "text": "DEBRIEF\nBarrie calls on people to provide summaries and feedback, and their poster board summaries are grouped together on the wall.\nCan we summarize the themes or ideas that emerged for each question across all of the groups?\nAsk the PI and Co-PIs which suggestions appeal to them as something they could help implement on the Ticbase grant before it ends.\n\n\nbrobison@uidaho.edu"
  },
  {
    "objectID": "ProfessorPolymorphic/posts/welcome/index.html",
    "href": "ProfessorPolymorphic/posts/welcome/index.html",
    "title": "You’ve gotta be f***ing kidding…",
    "section": "",
    "text": "Mac wants the flamethrower…\n\nIt’s such a ridiculous notion that anyone on the planet would ever want to read a BLOG, let alone a BLOG authored by some rando nerd like me. Nevertheless, if I force myself to push past the imposter syndrome, disruptive thoughts, anxiety, and the sheer PRETENTIOUSNESS of one’s own BLOG, I can kind of rationalize doing this.\nAllow me to elaborate (he wrote to himself). The varied reasons for setting up a BLOG as part of my research lab website include:\n\nIt forces me to further practice using the tools I need for both research and teaching Data Science, including literate programming (I’m using Quarto), version control (I’m using GitHub), and communicating with data.\nIt gives me a place to put a lot of the intermediate outcomes and products from the game studio. All the grey material that isn’t a journal publication, grant proposal, meeting abstract, etc. usually ends up getting lost. Examples include outreach and eduation materials for our games, videos and images that we don’t put on our largely silent social media channels, etc.\nIt serves as an archive for experimental/exploratory analyses in which I am trying to learn a new technique or explore a new data set, allowing me to return to that idea when its time has finally arrived.\nIn the off chance that one of my posts actually helps someone learn something because they found it by googling their particular error message, I will have begun paying back my massive karmic debt to the internet. I can’t count the number of times someone’s blog post helped me figure out how to accomplish something using R.\nI honestly do enjoy thinking about the intersection of science and horror fiction, and some of our newer game projects are going to serve as the platform for that type of content.\nSpeaking of our newer game projects, I’ll be using this as a venue to post development updates for studio projects.\nI have ADHD. I mean actual psychiatrist diagnosed, full blown, life altering ADHD. Systems and structures are critical components of the coping strategies I have developed over the years. Maybe… just maybe… this BLOG will help me keep a bunch of stuff organized so I can…. HEY LOOK A SHINY THING!\nSpeaking of shiny things… I’m really enjoing the new AI tools for procedural art generation. I’m particularly enamored with midJourney. I’m hoping to use this BLOG for some exploration of those tools.\n\nSo why the thumbnail from The Thing as the image for this post? Well the title of the post is the famous quote from Palmer when he sees Norris’ head crawling away on newly grown insect legs. Anyone who knows me who sees I have a BLOG is going to say what Palmer said…\n\nThe Thing Kidding GIFfrom The Thing Kidding GIFs"
  },
  {
    "objectID": "ProfessorPolymorphic/index.html",
    "href": "ProfessorPolymorphic/index.html",
    "title": "Professor Polymorphic",
    "section": "",
    "text": "“The oldest and strongest emotion of mankind is fear, and the oldest and strongest kind of fear is fear of the unknown”.\n– H.P. Lovecraft, Supernatural Horror in Literature\n\n\n\n\n\nHello! This BLOG is where I share my thoughts on how science informs horror fiction, and whether horror fiction can be used to at least help teach science, if not directly inform scientific research. The posts that appear here will vary in their focus. Some will directly address the intersection of horror and science, while some might focus primarily on either horror fiction or science concepts.\nMy basic premise is driven by the Lovecraft quote you see at the top of the screen. I find this compelling because I am a scientist, and science is one of two tools humanity has invented that pushes back against the unknown."
  },
  {
    "objectID": "ProfessorPolymorphic/about.html",
    "href": "ProfessorPolymorphic/about.html",
    "title": "About",
    "section": "",
    "text": "Evolution. Data Science. Video Games. Horror Fiction.\nI am a Professor of Biological Sciences at the University of Idaho, and the cofounder of Polymorphic Games, an experimental video game studio that applies game development technology to scientific research and education. We have released two evolutionary video games on Steam:\nDarwin’s Demons is an rcade style space shooter in which you battle a population of evolving aliens. The alien’s morphology, fire type, and behaviors are all encoded by a digital genome. The aliens that are best able to shoot or evade you reproduce to make the next generation.\nProject Hastur is an evolutionary tower defense game. Defend humanity against the ever changing threat of the alien Proteans. Project Hastur combines elements of 3D tower defense and real-time strategy with models of biological evolution to create a uniquely challenging experience.\nI am also a huge Horror and Science Fiction nerd, and am fascinated by the intersection of these genres with science.\nVideo"
  }
]